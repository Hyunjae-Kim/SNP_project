

[Gene 1] Model 1 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 23049])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23049])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.207 /   test loss : 0.237
iteration : 10/500  -  train loss : 0.009 /   test loss : 0.198
iteration : 20/500  -  train loss : 0.009 /   test loss : 0.194
iteration : 30/500  -  train loss : 0.004 /   test loss : 0.196
iteration : 40/500  -  train loss : 0.01 /   test loss : 0.204
iteration : 50/500  -  train loss : 0.004 /   test loss : 0.194
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.189
iteration : 70/500  -  train loss : 0.001 /   test loss : 0.188
iteration : 80/500  -  train loss : 0.003 /   test loss : 0.184
iteration : 90/500  -  train loss : 0.002 /   test loss : 0.188
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.186
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.184
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.185
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.185
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.189
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.195
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.196
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.195
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.193
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.197
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.193
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.193
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.198
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.199
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.202
iteration : 320/500  -  train loss : 0.0 /   test loss : 0.197
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.204
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.202
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.203
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.201
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.205
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.197
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.198
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.202
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.2
iteration : 420/500  -  train loss : 0.0 /   test loss : 0.204
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.199
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.204
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.206
iteration : 460/500  -  train loss : 0.0 /   test loss : 0.204
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.205
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.202
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.205
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.207

Training complete   //   Running time : 171  ------------


[Gene 1] Model 1 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 23049])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23049])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.231 /   test loss : 0.323
iteration : 10/500  -  train loss : 0.01 /   test loss : 0.306
iteration : 20/500  -  train loss : 0.003 /   test loss : 0.317
iteration : 30/500  -  train loss : 0.003 /   test loss : 0.309
iteration : 40/500  -  train loss : 0.002 /   test loss : 0.311
iteration : 50/500  -  train loss : 0.002 /   test loss : 0.307
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.319
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.31
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.311
iteration : 90/500  -  train loss : 0.001 /   test loss : 0.317
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.311
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.316
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.33
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.31
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.313
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.327
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.32
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.316
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.315
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.321
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.325
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.316
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.33
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.32
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.328
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.33
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.317
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.322
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.322
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.322
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.324
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.316
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.322
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.332
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.321
iteration : 350/500  -  train loss : 0.0 /   test loss : 0.328
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.335
iteration : 370/500  -  train loss : 0.0 /   test loss : 0.328
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.341
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.326
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.332
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.332
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.325
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.335
iteration : 440/500  -  train loss : 0.0 /   test loss : 0.334
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.339
iteration : 460/500  -  train loss : 0.0 /   test loss : 0.334
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.335
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.347
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.331
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.334

Training complete   //   Running time : 169  ------------


[Gene 1] Model 1 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 23049])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23049])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.191 /   test loss : 0.261
iteration : 10/500  -  train loss : 0.008 /   test loss : 0.223
iteration : 20/500  -  train loss : 0.003 /   test loss : 0.227
iteration : 30/500  -  train loss : 0.004 /   test loss : 0.223
iteration : 40/500  -  train loss : 0.003 /   test loss : 0.23
iteration : 50/500  -  train loss : 0.004 /   test loss : 0.231
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.236
iteration : 70/500  -  train loss : 0.001 /   test loss : 0.236
iteration : 80/500  -  train loss : 0.001 /   test loss : 0.234
iteration : 90/500  -  train loss : 0.002 /   test loss : 0.237
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.24
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.238
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.239
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.241
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.242
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.24
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.239
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.244
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.244
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.24
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.242
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.248
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.241
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.242
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.248
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.24
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.242
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.242
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.244
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.241
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.244
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.242
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.246
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.247
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.245
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.247
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.25
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.253
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.25
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.249
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.251
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.249
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.25
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.252
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.253
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.257
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.257
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.252
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.253
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.25
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.251

Training complete   //   Running time : 169  ------------


[Gene 1] Model 1 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 23049])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23049])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.2 /   test loss : 0.484
iteration : 10/500  -  train loss : 0.014 /   test loss : 0.329
iteration : 20/500  -  train loss : 0.004 /   test loss : 0.339
iteration : 30/500  -  train loss : 0.005 /   test loss : 0.344
iteration : 40/500  -  train loss : 0.001 /   test loss : 0.329
iteration : 50/500  -  train loss : 0.002 /   test loss : 0.334
iteration : 60/500  -  train loss : 0.001 /   test loss : 0.332
iteration : 70/500  -  train loss : 0.001 /   test loss : 0.34
iteration : 80/500  -  train loss : 0.001 /   test loss : 0.332
iteration : 90/500  -  train loss : 0.001 /   test loss : 0.342
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.34
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.342
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.342
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.341
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.341
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.344
iteration : 160/500  -  train loss : 0.002 /   test loss : 0.347
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.347
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.349
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.344
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.34
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.342
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.345
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.346
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.348
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.349
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.349
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.352
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.356
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.351
iteration : 300/500  -  train loss : 0.0 /   test loss : 0.352
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.347
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.357
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.355
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.36
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.357
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.352
iteration : 370/500  -  train loss : 0.0 /   test loss : 0.353
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.351
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.353
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.36
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.358
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.36
iteration : 430/500  -  train loss : 0.0 /   test loss : 0.356
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.35
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.361
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.352
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.361
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.354
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.357
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.356

Training complete   //   Running time : 168  ------------


[Gene 1] Model 1 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([120, 23049])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 23049])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.254 /   test loss : 0.269
iteration : 10/500  -  train loss : 0.021 /   test loss : 0.193
iteration : 20/500  -  train loss : 0.007 /   test loss : 0.19
iteration : 30/500  -  train loss : 0.002 /   test loss : 0.195
iteration : 40/500  -  train loss : 0.002 /   test loss : 0.191
iteration : 50/500  -  train loss : 0.002 /   test loss : 0.195
iteration : 60/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.191
iteration : 80/500  -  train loss : 0.001 /   test loss : 0.192
iteration : 90/500  -  train loss : 0.001 /   test loss : 0.19
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.192
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.192
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.192
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.195
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.199
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.198
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.193
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.196
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.196
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.197
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.195
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.195
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.195
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.2
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.195
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.197
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.197
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.198
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.197
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.203
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.199
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.198
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.2
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.198
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.2
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.201
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.202
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.204
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.202
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.202
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.202
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.199
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.2
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.202
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.196
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.2
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.201
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.199
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.199
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.199

Training complete   //   Running time : 167  ------------


[Gene 2] Model 1 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 22930])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22930])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.452 /   test loss : 0.564
iteration : 10/500  -  train loss : 0.024 /   test loss : 0.531
iteration : 20/500  -  train loss : 0.006 /   test loss : 0.567
iteration : 30/500  -  train loss : 0.003 /   test loss : 0.546
iteration : 40/500  -  train loss : 0.004 /   test loss : 0.531
iteration : 50/500  -  train loss : 0.002 /   test loss : 0.543
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.533
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.535
iteration : 80/500  -  train loss : 0.003 /   test loss : 0.54
iteration : 90/500  -  train loss : 0.002 /   test loss : 0.536
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.536
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.526
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.535
iteration : 130/500  -  train loss : 0.003 /   test loss : 0.533
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.53
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.533
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.527
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.526
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.53
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.532
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.534
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.538
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.534
iteration : 230/500  -  train loss : 0.002 /   test loss : 0.535
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.532
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.528
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.532
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.526
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.532
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.53
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.53
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.533
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.526
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.527
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.53
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.526
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.521
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.522
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.535
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.527
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.524
iteration : 410/500  -  train loss : 0.002 /   test loss : 0.53
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.523
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.535
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.532
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.529
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.53
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.528
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.531
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.53
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.524

Training complete   //   Running time : 170  ------------


[Gene 2] Model 1 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 22930])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22930])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.459 /   test loss : 1.202
iteration : 10/500  -  train loss : 0.038 /   test loss : 0.699
iteration : 20/500  -  train loss : 0.004 /   test loss : 0.761
iteration : 30/500  -  train loss : 0.002 /   test loss : 0.766
iteration : 40/500  -  train loss : 0.002 /   test loss : 0.775
iteration : 50/500  -  train loss : 0.002 /   test loss : 0.775
iteration : 60/500  -  train loss : 0.003 /   test loss : 0.789
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.779
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.771
iteration : 90/500  -  train loss : 0.002 /   test loss : 0.781
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.773
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.791
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.775
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.793
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.794
iteration : 150/500  -  train loss : 0.003 /   test loss : 0.813
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.798
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.793
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.79
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.791
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.803
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.797
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.815
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.817
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.809
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.813
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.82
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.823
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.814
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.807
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.822
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.82
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.825
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.833
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.847
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.839
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.821
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.83
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.823
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.833
iteration : 400/500  -  train loss : 0.002 /   test loss : 0.841
iteration : 410/500  -  train loss : 0.002 /   test loss : 0.827
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.853
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.839
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.844
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.838
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.846
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.85
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.857
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.847
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.844

Training complete   //   Running time : 168  ------------


[Gene 2] Model 1 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 22930])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22930])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.527 /   test loss : 0.563
iteration : 10/500  -  train loss : 0.024 /   test loss : 0.444
iteration : 20/500  -  train loss : 0.004 /   test loss : 0.46
iteration : 30/500  -  train loss : 0.003 /   test loss : 0.444
iteration : 40/500  -  train loss : 0.004 /   test loss : 0.454
iteration : 50/500  -  train loss : 0.002 /   test loss : 0.452
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.438
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.457
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.439
iteration : 90/500  -  train loss : 0.002 /   test loss : 0.442
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.449
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.446
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.447
iteration : 130/500  -  train loss : 0.004 /   test loss : 0.454
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.453
iteration : 150/500  -  train loss : 0.003 /   test loss : 0.454
iteration : 160/500  -  train loss : 0.002 /   test loss : 0.452
iteration : 170/500  -  train loss : 0.003 /   test loss : 0.455
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.441
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.457
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.453
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.455
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.449
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.456
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.451
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.45
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.456
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.455
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.446
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.447
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.455
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.453
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.457
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.461
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.46
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.452
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.467
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.462
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.468
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.472
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.469
iteration : 410/500  -  train loss : 0.002 /   test loss : 0.482
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.471
iteration : 430/500  -  train loss : 0.002 /   test loss : 0.472
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.464
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.466
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.467
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.473
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.47
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.465
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.473

Training complete   //   Running time : 167  ------------


[Gene 2] Model 1 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 22930])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22930])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.471 /   test loss : 0.551
iteration : 10/500  -  train loss : 0.019 /   test loss : 0.494
iteration : 20/500  -  train loss : 0.004 /   test loss : 0.456
iteration : 30/500  -  train loss : 0.004 /   test loss : 0.459
iteration : 40/500  -  train loss : 0.003 /   test loss : 0.44
iteration : 50/500  -  train loss : 0.003 /   test loss : 0.463
iteration : 60/500  -  train loss : 0.003 /   test loss : 0.456
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.438
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.445
iteration : 90/500  -  train loss : 0.002 /   test loss : 0.471
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.451
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.445
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.469
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.438
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.438
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.436
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.449
iteration : 170/500  -  train loss : 0.003 /   test loss : 0.432
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.443
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.44
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.45
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.434
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.448
iteration : 230/500  -  train loss : 0.002 /   test loss : 0.423
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.444
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.447
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.436
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.451
iteration : 280/500  -  train loss : 0.002 /   test loss : 0.426
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.449
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.437
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.449
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.434
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.435
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.44
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.448
iteration : 360/500  -  train loss : 0.002 /   test loss : 0.45
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.45
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.442
iteration : 390/500  -  train loss : 0.002 /   test loss : 0.434
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.438
iteration : 410/500  -  train loss : 0.002 /   test loss : 0.44
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.439
iteration : 430/500  -  train loss : 0.003 /   test loss : 0.424
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.434
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.435
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.434
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.433
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.443
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.444
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.438

Training complete   //   Running time : 168  ------------


[Gene 2] Model 1 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([120, 22930])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 22930])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.469 /   test loss : 0.421
iteration : 10/500  -  train loss : 0.026 /   test loss : 0.318
iteration : 20/500  -  train loss : 0.007 /   test loss : 0.328
iteration : 30/500  -  train loss : 0.004 /   test loss : 0.32
iteration : 40/500  -  train loss : 0.003 /   test loss : 0.334
iteration : 50/500  -  train loss : 0.002 /   test loss : 0.332
iteration : 60/500  -  train loss : 0.003 /   test loss : 0.328
iteration : 70/500  -  train loss : 0.005 /   test loss : 0.324
iteration : 80/500  -  train loss : 0.003 /   test loss : 0.322
iteration : 90/500  -  train loss : 0.003 /   test loss : 0.326
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.328
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.329
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.329
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.329
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.332
iteration : 150/500  -  train loss : 0.004 /   test loss : 0.334
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.332
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.335
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.334
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.337
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.34
iteration : 210/500  -  train loss : 0.003 /   test loss : 0.341
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.344
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.345
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.344
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.343
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.347
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.348
iteration : 280/500  -  train loss : 0.002 /   test loss : 0.351
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.348
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.348
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.348
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.352
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.348
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.349
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.35
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.354
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.356
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.36
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.36
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.36
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.361
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.361
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.36
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.358
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.358
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.357
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.358
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.357
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.361
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.357

Training complete   //   Running time : 166  ------------


[Gene 3] Model 1 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 18753])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 18753])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.649 /   test loss : 0.303
iteration : 10/500  -  train loss : 0.064 /   test loss : 0.221
iteration : 20/500  -  train loss : 0.01 /   test loss : 0.257
iteration : 30/500  -  train loss : 0.003 /   test loss : 0.236
iteration : 40/500  -  train loss : 0.002 /   test loss : 0.237
iteration : 50/500  -  train loss : 0.002 /   test loss : 0.24
iteration : 60/500  -  train loss : 0.003 /   test loss : 0.224
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.231
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.226
iteration : 90/500  -  train loss : 0.005 /   test loss : 0.239
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.216
iteration : 110/500  -  train loss : 0.003 /   test loss : 0.209
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.229
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.22
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.214
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.212
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.217
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.207
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.199
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.204
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.212
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.217
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.197
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.21
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.198
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.199
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.211
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.202
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.187
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.196
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.204
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.195
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.195
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.193
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.196
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.187
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.193
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.189
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.184
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.182
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.193
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.18
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.184
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.184
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.195
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.185
iteration : 490/500  -  train loss : 0.002 /   test loss : 0.183
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.192

Training complete   //   Running time : 142  ------------


[Gene 3] Model 1 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 18753])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 18753])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.343 /   test loss : 1.706
iteration : 10/500  -  train loss : 0.022 /   test loss : 1.082
iteration : 20/500  -  train loss : 0.003 /   test loss : 1.028
iteration : 30/500  -  train loss : 0.003 /   test loss : 1.031
iteration : 40/500  -  train loss : 0.002 /   test loss : 1.036
iteration : 50/500  -  train loss : 0.003 /   test loss : 1.027
iteration : 60/500  -  train loss : 0.002 /   test loss : 1.03
iteration : 70/500  -  train loss : 0.003 /   test loss : 1.05
iteration : 80/500  -  train loss : 0.002 /   test loss : 1.052
iteration : 90/500  -  train loss : 0.002 /   test loss : 1.055
iteration : 100/500  -  train loss : 0.001 /   test loss : 1.048
iteration : 110/500  -  train loss : 0.001 /   test loss : 1.058
iteration : 120/500  -  train loss : 0.001 /   test loss : 1.033
iteration : 130/500  -  train loss : 0.001 /   test loss : 1.043
iteration : 140/500  -  train loss : 0.001 /   test loss : 1.049
iteration : 150/500  -  train loss : 0.001 /   test loss : 1.045
iteration : 160/500  -  train loss : 0.001 /   test loss : 1.041
iteration : 170/500  -  train loss : 0.001 /   test loss : 1.04
iteration : 180/500  -  train loss : 0.001 /   test loss : 1.057
iteration : 190/500  -  train loss : 0.001 /   test loss : 1.03
iteration : 200/500  -  train loss : 0.001 /   test loss : 1.023
iteration : 210/500  -  train loss : 0.001 /   test loss : 1.034
iteration : 220/500  -  train loss : 0.001 /   test loss : 1.044
iteration : 230/500  -  train loss : 0.001 /   test loss : 1.045
iteration : 240/500  -  train loss : 0.001 /   test loss : 1.037
iteration : 250/500  -  train loss : 0.001 /   test loss : 1.031
iteration : 260/500  -  train loss : 0.001 /   test loss : 1.019
iteration : 270/500  -  train loss : 0.001 /   test loss : 1.012
iteration : 280/500  -  train loss : 0.001 /   test loss : 1.011
iteration : 290/500  -  train loss : 0.001 /   test loss : 1.013
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.999
iteration : 310/500  -  train loss : 0.001 /   test loss : 1.02
iteration : 320/500  -  train loss : 0.001 /   test loss : 1.007
iteration : 330/500  -  train loss : 0.001 /   test loss : 1.005
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.999
iteration : 350/500  -  train loss : 0.001 /   test loss : 1.013
iteration : 360/500  -  train loss : 0.001 /   test loss : 1.025
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.997
iteration : 380/500  -  train loss : 0.001 /   test loss : 1.028
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.993
iteration : 400/500  -  train loss : 0.001 /   test loss : 1.013
iteration : 410/500  -  train loss : 0.001 /   test loss : 1.028
iteration : 420/500  -  train loss : 0.001 /   test loss : 1.003
iteration : 430/500  -  train loss : 0.0 /   test loss : 1.012
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.995
iteration : 450/500  -  train loss : 0.001 /   test loss : 1.007
iteration : 460/500  -  train loss : 0.001 /   test loss : 1.001
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.994
iteration : 480/500  -  train loss : 0.0 /   test loss : 1.005
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.998
iteration : 500/500  -  train loss : 0.001 /   test loss : 1.022

Training complete   //   Running time : 138  ------------


[Gene 3] Model 1 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 18753])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 18753])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.634 /   test loss : 0.327
iteration : 10/500  -  train loss : 0.064 /   test loss : 0.272
iteration : 20/500  -  train loss : 0.008 /   test loss : 0.261
iteration : 30/500  -  train loss : 0.004 /   test loss : 0.258
iteration : 40/500  -  train loss : 0.003 /   test loss : 0.248
iteration : 50/500  -  train loss : 0.004 /   test loss : 0.258
iteration : 60/500  -  train loss : 0.003 /   test loss : 0.247
iteration : 70/500  -  train loss : 0.003 /   test loss : 0.258
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.257
iteration : 90/500  -  train loss : 0.001 /   test loss : 0.247
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.254
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.249
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.249
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.244
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.246
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.24
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.245
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.244
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.243
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.242
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.245
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.241
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.24
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.236
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.24
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.236
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.242
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.238
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.242
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.237
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.24
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.242
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.244
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.239
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.245
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.24
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.238
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.24
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.242
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.242
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.243
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.242
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.239
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.238
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.242
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.24
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.239
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.236
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.239
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.239
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.236

Training complete   //   Running time : 138  ------------


[Gene 3] Model 1 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 18753])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 18753])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.572 /   test loss : 0.73
iteration : 10/500  -  train loss : 0.054 /   test loss : 0.429
iteration : 20/500  -  train loss : 0.009 /   test loss : 0.42
iteration : 30/500  -  train loss : 0.004 /   test loss : 0.401
iteration : 40/500  -  train loss : 0.003 /   test loss : 0.406
iteration : 50/500  -  train loss : 0.002 /   test loss : 0.409
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.395
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.395
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.388
iteration : 90/500  -  train loss : 0.002 /   test loss : 0.388
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.383
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.384
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.386
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.379
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.367
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.366
iteration : 160/500  -  train loss : 0.002 /   test loss : 0.379
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.36
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.37
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.363
iteration : 200/500  -  train loss : 0.003 /   test loss : 0.364
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.353
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.348
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.345
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.353
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.347
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.345
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.35
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.337
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.339
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.342
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.343
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.342
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.337
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.336
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.341
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.335
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.333
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.332
iteration : 390/500  -  train loss : 0.0 /   test loss : 0.332
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.336
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.329
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.325
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.326
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.329
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.321
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.325
iteration : 470/500  -  train loss : 0.0 /   test loss : 0.326
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.328
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.323
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.324

Training complete   //   Running time : 138  ------------


[Gene 3] Model 1 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([120, 18753])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 18753])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.639 /   test loss : 0.424
iteration : 10/500  -  train loss : 0.062 /   test loss : 0.241
iteration : 20/500  -  train loss : 0.008 /   test loss : 0.233
iteration : 30/500  -  train loss : 0.003 /   test loss : 0.224
iteration : 40/500  -  train loss : 0.002 /   test loss : 0.223
iteration : 50/500  -  train loss : 0.004 /   test loss : 0.22
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.222
iteration : 70/500  -  train loss : 0.004 /   test loss : 0.214
iteration : 80/500  -  train loss : 0.003 /   test loss : 0.211
iteration : 90/500  -  train loss : 0.002 /   test loss : 0.212
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.212
iteration : 110/500  -  train loss : 0.003 /   test loss : 0.216
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.214
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.203
iteration : 140/500  -  train loss : 0.004 /   test loss : 0.224
iteration : 150/500  -  train loss : 0.003 /   test loss : 0.209
iteration : 160/500  -  train loss : 0.002 /   test loss : 0.213
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.214
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.218
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.211
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.211
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.209
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.215
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.214
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.211
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.214
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.216
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.216
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.218
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.218
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.219
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.224
iteration : 320/500  -  train loss : 0.002 /   test loss : 0.22
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.22
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.22
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.216
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.224
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.224
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.225
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.226
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.222
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.218
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.225
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.221
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.22
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.221
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.219
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.226
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.225
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.229
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.225

Training complete   //   Running time : 136  ------------


[Gene 4] Model 1 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 23718])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23718])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.531 /   test loss : 0.31
iteration : 10/500  -  train loss : 0.039 /   test loss : 0.295
iteration : 20/500  -  train loss : 0.009 /   test loss : 0.326
iteration : 30/500  -  train loss : 0.011 /   test loss : 0.312
iteration : 40/500  -  train loss : 0.004 /   test loss : 0.32
iteration : 50/500  -  train loss : 0.002 /   test loss : 0.306
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.303
iteration : 70/500  -  train loss : 0.007 /   test loss : 0.296
iteration : 80/500  -  train loss : 0.003 /   test loss : 0.299
iteration : 90/500  -  train loss : 0.003 /   test loss : 0.29
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.29
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.29
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.296
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.292
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.296
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.285
iteration : 160/500  -  train loss : 0.002 /   test loss : 0.283
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.289
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.286
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.28
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.283
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.281
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.282
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.277
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.281
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.283
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.284
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.278
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.275
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.276
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.276
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.274
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.272
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.27
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.273
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.271
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.27
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.267
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.268
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.266
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.266
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.266
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.264
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.266
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.272
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.269
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.269
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.268
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.265
iteration : 490/500  -  train loss : 0.002 /   test loss : 0.272
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.265

Training complete   //   Running time : 182  ------------


[Gene 4] Model 1 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 23718])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23718])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.383 /   test loss : 0.958
iteration : 10/500  -  train loss : 0.043 /   test loss : 0.926
iteration : 20/500  -  train loss : 0.003 /   test loss : 0.915
iteration : 30/500  -  train loss : 0.004 /   test loss : 0.922
iteration : 40/500  -  train loss : 0.003 /   test loss : 0.929
iteration : 50/500  -  train loss : 0.004 /   test loss : 0.938
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.906
iteration : 70/500  -  train loss : 0.003 /   test loss : 0.908
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.9
iteration : 90/500  -  train loss : 0.002 /   test loss : 0.914
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.907
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.912
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.904
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.904
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.915
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.91
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.906
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.912
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.908
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.899
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.901
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.899
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.9
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.896
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.898
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.898
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.903
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.892
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.901
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.891
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.893
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.89
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.895
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.897
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.895
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.898
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.903
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.904
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.898
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.895
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.89
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.89
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.893
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.9
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.899
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.895
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.894
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.895
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.898
iteration : 490/500  -  train loss : 0.002 /   test loss : 0.883
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.9

Training complete   //   Running time : 174  ------------


[Gene 4] Model 1 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 23718])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23718])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.532 /   test loss : 0.645
iteration : 10/500  -  train loss : 0.055 /   test loss : 0.438
iteration : 20/500  -  train loss : 0.005 /   test loss : 0.456
iteration : 30/500  -  train loss : 0.002 /   test loss : 0.467
iteration : 40/500  -  train loss : 0.002 /   test loss : 0.458
iteration : 50/500  -  train loss : 0.003 /   test loss : 0.453
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.476
iteration : 70/500  -  train loss : 0.001 /   test loss : 0.469
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.463
iteration : 90/500  -  train loss : 0.002 /   test loss : 0.454
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.457
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.457
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.459
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.467
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.454
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.464
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.458
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.46
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.463
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.459
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.451
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.458
iteration : 220/500  -  train loss : 0.002 /   test loss : 0.449
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.462
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.457
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.457
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.457
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.459
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.46
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.461
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.471
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.46
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.462
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.464
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.461
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.455
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.463
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.463
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.461
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.469
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.467
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.459
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.463
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.461
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.454
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.462
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.463
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.456
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.455
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.463
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.455

Training complete   //   Running time : 174  ------------


[Gene 4] Model 1 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 23718])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23718])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.482 /   test loss : 0.898
iteration : 10/500  -  train loss : 0.037 /   test loss : 0.723
iteration : 20/500  -  train loss : 0.003 /   test loss : 0.729
iteration : 30/500  -  train loss : 0.002 /   test loss : 0.725
iteration : 40/500  -  train loss : 0.002 /   test loss : 0.735
iteration : 50/500  -  train loss : 0.002 /   test loss : 0.727
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.727
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.732
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.739
iteration : 90/500  -  train loss : 0.001 /   test loss : 0.725
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.743
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.738
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.733
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.738
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.73
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.747
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.742
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.739
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.74
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.745
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.755
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.756
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.745
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.756
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.766
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.765
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.754
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.767
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.754
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.746
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.769
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.759
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.765
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.767
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.764
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.759
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.76
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.763
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.768
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.779
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.77
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.765
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.774
iteration : 430/500  -  train loss : 0.0 /   test loss : 0.773
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.773
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.776
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.78
iteration : 470/500  -  train loss : 0.0 /   test loss : 0.773
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.768
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.772
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.78

Training complete   //   Running time : 173  ------------


[Gene 4] Model 1 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([120, 23718])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 23718])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.517 /   test loss : 0.328
iteration : 10/500  -  train loss : 0.032 /   test loss : 0.255
iteration : 20/500  -  train loss : 0.004 /   test loss : 0.282
iteration : 30/500  -  train loss : 0.003 /   test loss : 0.282
iteration : 40/500  -  train loss : 0.003 /   test loss : 0.288
iteration : 50/500  -  train loss : 0.004 /   test loss : 0.285
iteration : 60/500  -  train loss : 0.004 /   test loss : 0.27
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.274
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.289
iteration : 90/500  -  train loss : 0.002 /   test loss : 0.288
iteration : 100/500  -  train loss : 0.003 /   test loss : 0.288
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.278
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.277
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.28
iteration : 140/500  -  train loss : 0.003 /   test loss : 0.289
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.287
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.275
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.279
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.274
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.282
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.276
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.276
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.281
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.279
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.276
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.279
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.278
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.276
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.278
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.28
iteration : 300/500  -  train loss : 0.003 /   test loss : 0.274
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.28
iteration : 320/500  -  train loss : 0.002 /   test loss : 0.28
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.278
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.277
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.279
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.281
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.283
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.275
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.278
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.275
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.278
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.277
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.279
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.281
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.281
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.28
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.278
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.279
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.274
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.277

Training complete   //   Running time : 171  ------------


[Gene 5] Model 1 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 21013])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 21013])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.429 /   test loss : 0.989
iteration : 10/500  -  train loss : 0.088 /   test loss : 0.995
iteration : 20/500  -  train loss : 0.014 /   test loss : 1.05
iteration : 30/500  -  train loss : 0.003 /   test loss : 1.069
iteration : 40/500  -  train loss : 0.007 /   test loss : 1.078
iteration : 50/500  -  train loss : 0.003 /   test loss : 1.064
iteration : 60/500  -  train loss : 0.003 /   test loss : 1.063
iteration : 70/500  -  train loss : 0.002 /   test loss : 1.077
iteration : 80/500  -  train loss : 0.003 /   test loss : 1.064
iteration : 90/500  -  train loss : 0.002 /   test loss : 1.062
iteration : 100/500  -  train loss : 0.003 /   test loss : 1.058
iteration : 110/500  -  train loss : 0.002 /   test loss : 1.047
iteration : 120/500  -  train loss : 0.002 /   test loss : 1.061
iteration : 130/500  -  train loss : 0.001 /   test loss : 1.058
iteration : 140/500  -  train loss : 0.001 /   test loss : 1.056
iteration : 150/500  -  train loss : 0.001 /   test loss : 1.055
iteration : 160/500  -  train loss : 0.001 /   test loss : 1.056
iteration : 170/500  -  train loss : 0.001 /   test loss : 1.056
iteration : 180/500  -  train loss : 0.001 /   test loss : 1.061
iteration : 190/500  -  train loss : 0.001 /   test loss : 1.062
iteration : 200/500  -  train loss : 0.002 /   test loss : 1.063
iteration : 210/500  -  train loss : 0.001 /   test loss : 1.066
iteration : 220/500  -  train loss : 0.001 /   test loss : 1.061
iteration : 230/500  -  train loss : 0.001 /   test loss : 1.064
iteration : 240/500  -  train loss : 0.001 /   test loss : 1.045
iteration : 250/500  -  train loss : 0.001 /   test loss : 1.048
iteration : 260/500  -  train loss : 0.001 /   test loss : 1.067
iteration : 270/500  -  train loss : 0.001 /   test loss : 1.043
iteration : 280/500  -  train loss : 0.001 /   test loss : 1.058
iteration : 290/500  -  train loss : 0.001 /   test loss : 1.053
iteration : 300/500  -  train loss : 0.001 /   test loss : 1.045
iteration : 310/500  -  train loss : 0.001 /   test loss : 1.055
iteration : 320/500  -  train loss : 0.001 /   test loss : 1.047
iteration : 330/500  -  train loss : 0.001 /   test loss : 1.038
iteration : 340/500  -  train loss : 0.001 /   test loss : 1.047
iteration : 350/500  -  train loss : 0.001 /   test loss : 1.053
iteration : 360/500  -  train loss : 0.001 /   test loss : 1.049
iteration : 370/500  -  train loss : 0.001 /   test loss : 1.044
iteration : 380/500  -  train loss : 0.001 /   test loss : 1.057
iteration : 390/500  -  train loss : 0.001 /   test loss : 1.036
iteration : 400/500  -  train loss : 0.001 /   test loss : 1.039
iteration : 410/500  -  train loss : 0.001 /   test loss : 1.045
iteration : 420/500  -  train loss : 0.001 /   test loss : 1.044
iteration : 430/500  -  train loss : 0.001 /   test loss : 1.026
iteration : 440/500  -  train loss : 0.001 /   test loss : 1.046
iteration : 450/500  -  train loss : 0.001 /   test loss : 1.042
iteration : 460/500  -  train loss : 0.001 /   test loss : 1.043
iteration : 470/500  -  train loss : 0.001 /   test loss : 1.053
iteration : 480/500  -  train loss : 0.001 /   test loss : 1.044
iteration : 490/500  -  train loss : 0.001 /   test loss : 1.047
iteration : 500/500  -  train loss : 0.001 /   test loss : 1.048

Training complete   //   Running time : 155  ------------


[Gene 5] Model 1 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 21013])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 21013])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.589 /   test loss : 0.187
iteration : 10/500  -  train loss : 0.144 /   test loss : 0.293
iteration : 20/500  -  train loss : 0.025 /   test loss : 0.416
iteration : 30/500  -  train loss : 0.005 /   test loss : 0.426
iteration : 40/500  -  train loss : 0.007 /   test loss : 0.417
iteration : 50/500  -  train loss : 0.005 /   test loss : 0.438
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.416
iteration : 70/500  -  train loss : 0.004 /   test loss : 0.434
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.404
iteration : 90/500  -  train loss : 0.002 /   test loss : 0.394
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.39
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.386
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.412
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.379
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.368
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.356
iteration : 160/500  -  train loss : 0.004 /   test loss : 0.402
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.339
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.372
iteration : 190/500  -  train loss : 0.004 /   test loss : 0.336
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.354
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.332
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.337
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.332
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.321
iteration : 250/500  -  train loss : 0.004 /   test loss : 0.352
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.319
iteration : 270/500  -  train loss : 0.003 /   test loss : 0.335
iteration : 280/500  -  train loss : 0.002 /   test loss : 0.307
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.316
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.317
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.316
iteration : 320/500  -  train loss : 0.002 /   test loss : 0.323
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.312
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.302
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.305
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.319
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.314
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.306
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.301
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.302
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.305
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.292
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.298
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.286
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.293
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.286
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.282
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.288
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.297
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.282

Training complete   //   Running time : 156  ------------


[Gene 5] Model 1 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 21013])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 21013])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.577 /   test loss : 0.351
iteration : 10/500  -  train loss : 0.168 /   test loss : 0.364
iteration : 20/500  -  train loss : 0.036 /   test loss : 0.394
iteration : 30/500  -  train loss : 0.007 /   test loss : 0.409
iteration : 40/500  -  train loss : 0.003 /   test loss : 0.41
iteration : 50/500  -  train loss : 0.005 /   test loss : 0.426
iteration : 60/500  -  train loss : 0.003 /   test loss : 0.414
iteration : 70/500  -  train loss : 0.004 /   test loss : 0.41
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.404
iteration : 90/500  -  train loss : 0.002 /   test loss : 0.409
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.405
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.403
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.402
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.399
iteration : 140/500  -  train loss : 0.003 /   test loss : 0.393
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.387
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.408
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.392
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.399
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.394
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.396
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.38
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.382
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.378
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.378
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.38
iteration : 260/500  -  train loss : 0.003 /   test loss : 0.368
iteration : 270/500  -  train loss : 0.003 /   test loss : 0.375
iteration : 280/500  -  train loss : 0.003 /   test loss : 0.371
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.376
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.382
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.365
iteration : 320/500  -  train loss : 0.003 /   test loss : 0.365
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.374
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.371
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.371
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.364
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.364
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.367
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.364
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.362
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.365
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.357
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.358
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.36
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.357
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.347
iteration : 470/500  -  train loss : 0.002 /   test loss : 0.346
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.349
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.343
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.347

Training complete   //   Running time : 157  ------------


[Gene 5] Model 1 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 21013])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 21013])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.635 /   test loss : 0.315
iteration : 10/500  -  train loss : 0.168 /   test loss : 0.237
iteration : 20/500  -  train loss : 0.035 /   test loss : 0.262
iteration : 30/500  -  train loss : 0.006 /   test loss : 0.276
iteration : 40/500  -  train loss : 0.004 /   test loss : 0.273
iteration : 50/500  -  train loss : 0.006 /   test loss : 0.264
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.28
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.294
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.285
iteration : 90/500  -  train loss : 0.002 /   test loss : 0.272
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.271
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.267
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.282
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.278
iteration : 140/500  -  train loss : 0.003 /   test loss : 0.259
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.268
iteration : 160/500  -  train loss : 0.002 /   test loss : 0.288
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.265
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.269
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.251
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.275
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.255
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.274
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.26
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.255
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.282
iteration : 260/500  -  train loss : 0.003 /   test loss : 0.246
iteration : 270/500  -  train loss : 0.003 /   test loss : 0.284
iteration : 280/500  -  train loss : 0.003 /   test loss : 0.24
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.246
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.262
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.245
iteration : 320/500  -  train loss : 0.003 /   test loss : 0.277
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.256
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.259
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.262
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.262
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.242
iteration : 380/500  -  train loss : 0.002 /   test loss : 0.261
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.253
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.258
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.267
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.247
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.267
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.244
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.258
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.259
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.243
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.251
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.255
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.258

Training complete   //   Running time : 158  ------------


[Gene 5] Model 1 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([120, 21013])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 21013])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.372 /   test loss : 1.226
iteration : 10/500  -  train loss : 0.08 /   test loss : 1.232
iteration : 20/500  -  train loss : 0.008 /   test loss : 1.258
iteration : 30/500  -  train loss : 0.002 /   test loss : 1.296
iteration : 40/500  -  train loss : 0.002 /   test loss : 1.302
iteration : 50/500  -  train loss : 0.005 /   test loss : 1.311
iteration : 60/500  -  train loss : 0.003 /   test loss : 1.302
iteration : 70/500  -  train loss : 0.003 /   test loss : 1.271
iteration : 80/500  -  train loss : 0.003 /   test loss : 1.296
iteration : 90/500  -  train loss : 0.002 /   test loss : 1.253
iteration : 100/500  -  train loss : 0.002 /   test loss : 1.27
iteration : 110/500  -  train loss : 0.002 /   test loss : 1.242
iteration : 120/500  -  train loss : 0.002 /   test loss : 1.242
iteration : 130/500  -  train loss : 0.001 /   test loss : 1.246
iteration : 140/500  -  train loss : 0.002 /   test loss : 1.257
iteration : 150/500  -  train loss : 0.002 /   test loss : 1.273
iteration : 160/500  -  train loss : 0.002 /   test loss : 1.236
iteration : 170/500  -  train loss : 0.001 /   test loss : 1.246
iteration : 180/500  -  train loss : 0.002 /   test loss : 1.244
iteration : 190/500  -  train loss : 0.001 /   test loss : 1.239
iteration : 200/500  -  train loss : 0.001 /   test loss : 1.241
iteration : 210/500  -  train loss : 0.001 /   test loss : 1.242
iteration : 220/500  -  train loss : 0.002 /   test loss : 1.218
iteration : 230/500  -  train loss : 0.001 /   test loss : 1.239
iteration : 240/500  -  train loss : 0.001 /   test loss : 1.236
iteration : 250/500  -  train loss : 0.001 /   test loss : 1.238
iteration : 260/500  -  train loss : 0.001 /   test loss : 1.233
iteration : 270/500  -  train loss : 0.001 /   test loss : 1.222
iteration : 280/500  -  train loss : 0.001 /   test loss : 1.23
iteration : 290/500  -  train loss : 0.001 /   test loss : 1.249
iteration : 300/500  -  train loss : 0.002 /   test loss : 1.222
iteration : 310/500  -  train loss : 0.001 /   test loss : 1.241
iteration : 320/500  -  train loss : 0.001 /   test loss : 1.229
iteration : 330/500  -  train loss : 0.001 /   test loss : 1.235
iteration : 340/500  -  train loss : 0.001 /   test loss : 1.229
iteration : 350/500  -  train loss : 0.001 /   test loss : 1.237
iteration : 360/500  -  train loss : 0.001 /   test loss : 1.221
iteration : 370/500  -  train loss : 0.001 /   test loss : 1.228
iteration : 380/500  -  train loss : 0.001 /   test loss : 1.227
iteration : 390/500  -  train loss : 0.002 /   test loss : 1.216
iteration : 400/500  -  train loss : 0.001 /   test loss : 1.217
iteration : 410/500  -  train loss : 0.001 /   test loss : 1.225
iteration : 420/500  -  train loss : 0.001 /   test loss : 1.22
iteration : 430/500  -  train loss : 0.001 /   test loss : 1.237
iteration : 440/500  -  train loss : 0.001 /   test loss : 1.214
iteration : 450/500  -  train loss : 0.001 /   test loss : 1.235
iteration : 460/500  -  train loss : 0.001 /   test loss : 1.227
iteration : 470/500  -  train loss : 0.001 /   test loss : 1.223
iteration : 480/500  -  train loss : 0.001 /   test loss : 1.228
iteration : 490/500  -  train loss : 0.001 /   test loss : 1.237
iteration : 500/500  -  train loss : 0.001 /   test loss : 1.21

Training complete   //   Running time : 155  ------------


[Gene 6] Model 1 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 27389])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 27389])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.823 /   test loss : 1.744
iteration : 10/500  -  train loss : 0.038 /   test loss : 1.119
iteration : 20/500  -  train loss : 0.006 /   test loss : 1.125
iteration : 30/500  -  train loss : 0.008 /   test loss : 1.103
iteration : 40/500  -  train loss : 0.005 /   test loss : 1.125
iteration : 50/500  -  train loss : 0.005 /   test loss : 1.118
iteration : 60/500  -  train loss : 0.003 /   test loss : 1.126
iteration : 70/500  -  train loss : 0.003 /   test loss : 1.134
iteration : 80/500  -  train loss : 0.003 /   test loss : 1.13
iteration : 90/500  -  train loss : 0.003 /   test loss : 1.14
iteration : 100/500  -  train loss : 0.004 /   test loss : 1.147
iteration : 110/500  -  train loss : 0.003 /   test loss : 1.145
iteration : 120/500  -  train loss : 0.004 /   test loss : 1.124
iteration : 130/500  -  train loss : 0.003 /   test loss : 1.144
iteration : 140/500  -  train loss : 0.002 /   test loss : 1.141
iteration : 150/500  -  train loss : 0.002 /   test loss : 1.14
iteration : 160/500  -  train loss : 0.002 /   test loss : 1.143
iteration : 170/500  -  train loss : 0.002 /   test loss : 1.139
iteration : 180/500  -  train loss : 0.001 /   test loss : 1.147
iteration : 190/500  -  train loss : 0.001 /   test loss : 1.147
iteration : 200/500  -  train loss : 0.002 /   test loss : 1.154
iteration : 210/500  -  train loss : 0.002 /   test loss : 1.141
iteration : 220/500  -  train loss : 0.002 /   test loss : 1.154
iteration : 230/500  -  train loss : 0.001 /   test loss : 1.164
iteration : 240/500  -  train loss : 0.002 /   test loss : 1.161
iteration : 250/500  -  train loss : 0.001 /   test loss : 1.158
iteration : 260/500  -  train loss : 0.002 /   test loss : 1.143
iteration : 270/500  -  train loss : 0.001 /   test loss : 1.156
iteration : 280/500  -  train loss : 0.002 /   test loss : 1.151
iteration : 290/500  -  train loss : 0.001 /   test loss : 1.147
iteration : 300/500  -  train loss : 0.001 /   test loss : 1.172
iteration : 310/500  -  train loss : 0.002 /   test loss : 1.171
iteration : 320/500  -  train loss : 0.003 /   test loss : 1.168
iteration : 330/500  -  train loss : 0.002 /   test loss : 1.16
iteration : 340/500  -  train loss : 0.002 /   test loss : 1.169
iteration : 350/500  -  train loss : 0.002 /   test loss : 1.173
iteration : 360/500  -  train loss : 0.002 /   test loss : 1.169
iteration : 370/500  -  train loss : 0.002 /   test loss : 1.153
iteration : 380/500  -  train loss : 0.001 /   test loss : 1.177
iteration : 390/500  -  train loss : 0.001 /   test loss : 1.157
iteration : 400/500  -  train loss : 0.002 /   test loss : 1.155
iteration : 410/500  -  train loss : 0.001 /   test loss : 1.183
iteration : 420/500  -  train loss : 0.001 /   test loss : 1.172
iteration : 430/500  -  train loss : 0.002 /   test loss : 1.183
iteration : 440/500  -  train loss : 0.002 /   test loss : 1.155
iteration : 450/500  -  train loss : 0.002 /   test loss : 1.187
iteration : 460/500  -  train loss : 0.001 /   test loss : 1.17
iteration : 470/500  -  train loss : 0.001 /   test loss : 1.179
iteration : 480/500  -  train loss : 0.002 /   test loss : 1.184
iteration : 490/500  -  train loss : 0.002 /   test loss : 1.192
iteration : 500/500  -  train loss : 0.002 /   test loss : 1.161

Training complete   //   Running time : 206  ------------


[Gene 6] Model 1 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 27389])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 27389])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 1.004 /   test loss : 0.612
iteration : 10/500  -  train loss : 0.06 /   test loss : 0.418
iteration : 20/500  -  train loss : 0.007 /   test loss : 0.449
iteration : 30/500  -  train loss : 0.017 /   test loss : 0.527
iteration : 40/500  -  train loss : 0.004 /   test loss : 0.468
iteration : 50/500  -  train loss : 0.003 /   test loss : 0.444
iteration : 60/500  -  train loss : 0.004 /   test loss : 0.456
iteration : 70/500  -  train loss : 0.003 /   test loss : 0.436
iteration : 80/500  -  train loss : 0.004 /   test loss : 0.43
iteration : 90/500  -  train loss : 0.004 /   test loss : 0.456
iteration : 100/500  -  train loss : 0.005 /   test loss : 0.425
iteration : 110/500  -  train loss : 0.003 /   test loss : 0.431
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.452
iteration : 130/500  -  train loss : 0.003 /   test loss : 0.448
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.441
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.434
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.448
iteration : 170/500  -  train loss : 0.003 /   test loss : 0.455
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.443
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.431
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.433
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.434
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.432
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.43
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.43
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.431
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.432
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.429
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.433
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.428
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.44
iteration : 310/500  -  train loss : 0.003 /   test loss : 0.422
iteration : 320/500  -  train loss : 0.002 /   test loss : 0.414
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.442
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.432
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.434
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.427
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.435
iteration : 380/500  -  train loss : 0.002 /   test loss : 0.436
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.427
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.431
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.423
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.427
iteration : 430/500  -  train loss : 0.002 /   test loss : 0.413
iteration : 440/500  -  train loss : 0.002 /   test loss : 0.419
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.417
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.424
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.429
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.428
iteration : 490/500  -  train loss : 0.003 /   test loss : 0.438
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.417

Training complete   //   Running time : 204  ------------


[Gene 6] Model 1 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 27389])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 27389])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.804 /   test loss : 1.702
iteration : 10/500  -  train loss : 0.028 /   test loss : 1.166
iteration : 20/500  -  train loss : 0.012 /   test loss : 1.165
iteration : 30/500  -  train loss : 0.007 /   test loss : 1.173
iteration : 40/500  -  train loss : 0.009 /   test loss : 1.178
iteration : 50/500  -  train loss : 0.005 /   test loss : 1.174
iteration : 60/500  -  train loss : 0.003 /   test loss : 1.148
iteration : 70/500  -  train loss : 0.003 /   test loss : 1.177
iteration : 80/500  -  train loss : 0.003 /   test loss : 1.161
iteration : 90/500  -  train loss : 0.003 /   test loss : 1.162
iteration : 100/500  -  train loss : 0.002 /   test loss : 1.179
iteration : 110/500  -  train loss : 0.005 /   test loss : 1.171
iteration : 120/500  -  train loss : 0.003 /   test loss : 1.164
iteration : 130/500  -  train loss : 0.002 /   test loss : 1.171
iteration : 140/500  -  train loss : 0.001 /   test loss : 1.178
iteration : 150/500  -  train loss : 0.003 /   test loss : 1.163
iteration : 160/500  -  train loss : 0.002 /   test loss : 1.165
iteration : 170/500  -  train loss : 0.002 /   test loss : 1.171
iteration : 180/500  -  train loss : 0.001 /   test loss : 1.169
iteration : 190/500  -  train loss : 0.001 /   test loss : 1.177
iteration : 200/500  -  train loss : 0.002 /   test loss : 1.166
iteration : 210/500  -  train loss : 0.001 /   test loss : 1.177
iteration : 220/500  -  train loss : 0.002 /   test loss : 1.16
iteration : 230/500  -  train loss : 0.001 /   test loss : 1.167
iteration : 240/500  -  train loss : 0.001 /   test loss : 1.178
iteration : 250/500  -  train loss : 0.001 /   test loss : 1.161
iteration : 260/500  -  train loss : 0.002 /   test loss : 1.167
iteration : 270/500  -  train loss : 0.001 /   test loss : 1.171
iteration : 280/500  -  train loss : 0.001 /   test loss : 1.175
iteration : 290/500  -  train loss : 0.001 /   test loss : 1.159
iteration : 300/500  -  train loss : 0.001 /   test loss : 1.156
iteration : 310/500  -  train loss : 0.002 /   test loss : 1.18
iteration : 320/500  -  train loss : 0.001 /   test loss : 1.166
iteration : 330/500  -  train loss : 0.001 /   test loss : 1.174
iteration : 340/500  -  train loss : 0.002 /   test loss : 1.176
iteration : 350/500  -  train loss : 0.003 /   test loss : 1.201
iteration : 360/500  -  train loss : 0.001 /   test loss : 1.182
iteration : 370/500  -  train loss : 0.002 /   test loss : 1.173
iteration : 380/500  -  train loss : 0.002 /   test loss : 1.178
iteration : 390/500  -  train loss : 0.001 /   test loss : 1.182
iteration : 400/500  -  train loss : 0.001 /   test loss : 1.184
iteration : 410/500  -  train loss : 0.002 /   test loss : 1.185
iteration : 420/500  -  train loss : 0.001 /   test loss : 1.175
iteration : 430/500  -  train loss : 0.002 /   test loss : 1.182
iteration : 440/500  -  train loss : 0.002 /   test loss : 1.174
iteration : 450/500  -  train loss : 0.001 /   test loss : 1.181
iteration : 460/500  -  train loss : 0.002 /   test loss : 1.173
iteration : 470/500  -  train loss : 0.001 /   test loss : 1.177
iteration : 480/500  -  train loss : 0.001 /   test loss : 1.168
iteration : 490/500  -  train loss : 0.003 /   test loss : 1.205
iteration : 500/500  -  train loss : 0.001 /   test loss : 1.172

Training complete   //   Running time : 205  ------------


[Gene 6] Model 1 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 27389])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 27389])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.87 /   test loss : 1.658
iteration : 10/500  -  train loss : 0.042 /   test loss : 1.167
iteration : 20/500  -  train loss : 0.027 /   test loss : 1.147
iteration : 30/500  -  train loss : 0.014 /   test loss : 1.171
iteration : 40/500  -  train loss : 0.013 /   test loss : 1.191
iteration : 50/500  -  train loss : 0.003 /   test loss : 1.185
iteration : 60/500  -  train loss : 0.003 /   test loss : 1.186
iteration : 70/500  -  train loss : 0.003 /   test loss : 1.195
iteration : 80/500  -  train loss : 0.004 /   test loss : 1.214
iteration : 90/500  -  train loss : 0.002 /   test loss : 1.193
iteration : 100/500  -  train loss : 0.002 /   test loss : 1.204
iteration : 110/500  -  train loss : 0.004 /   test loss : 1.209
iteration : 120/500  -  train loss : 0.002 /   test loss : 1.22
iteration : 130/500  -  train loss : 0.001 /   test loss : 1.23
iteration : 140/500  -  train loss : 0.002 /   test loss : 1.223
iteration : 150/500  -  train loss : 0.001 /   test loss : 1.243
iteration : 160/500  -  train loss : 0.001 /   test loss : 1.24
iteration : 170/500  -  train loss : 0.001 /   test loss : 1.236
iteration : 180/500  -  train loss : 0.001 /   test loss : 1.264
iteration : 190/500  -  train loss : 0.002 /   test loss : 1.247
iteration : 200/500  -  train loss : 0.002 /   test loss : 1.241
iteration : 210/500  -  train loss : 0.001 /   test loss : 1.241
iteration : 220/500  -  train loss : 0.001 /   test loss : 1.244
iteration : 230/500  -  train loss : 0.002 /   test loss : 1.271
iteration : 240/500  -  train loss : 0.001 /   test loss : 1.264
iteration : 250/500  -  train loss : 0.001 /   test loss : 1.268
iteration : 260/500  -  train loss : 0.001 /   test loss : 1.268
iteration : 270/500  -  train loss : 0.001 /   test loss : 1.285
iteration : 280/500  -  train loss : 0.002 /   test loss : 1.256
iteration : 290/500  -  train loss : 0.001 /   test loss : 1.284
iteration : 300/500  -  train loss : 0.002 /   test loss : 1.279
iteration : 310/500  -  train loss : 0.001 /   test loss : 1.289
iteration : 320/500  -  train loss : 0.001 /   test loss : 1.288
iteration : 330/500  -  train loss : 0.001 /   test loss : 1.298
iteration : 340/500  -  train loss : 0.001 /   test loss : 1.308
iteration : 350/500  -  train loss : 0.001 /   test loss : 1.315
iteration : 360/500  -  train loss : 0.001 /   test loss : 1.304
iteration : 370/500  -  train loss : 0.001 /   test loss : 1.319
iteration : 380/500  -  train loss : 0.001 /   test loss : 1.319
iteration : 390/500  -  train loss : 0.001 /   test loss : 1.319
iteration : 400/500  -  train loss : 0.001 /   test loss : 1.307
iteration : 410/500  -  train loss : 0.001 /   test loss : 1.313
iteration : 420/500  -  train loss : 0.001 /   test loss : 1.327
iteration : 430/500  -  train loss : 0.001 /   test loss : 1.327
iteration : 440/500  -  train loss : 0.001 /   test loss : 1.328
iteration : 450/500  -  train loss : 0.001 /   test loss : 1.324
iteration : 460/500  -  train loss : 0.001 /   test loss : 1.32
iteration : 470/500  -  train loss : 0.001 /   test loss : 1.325
iteration : 480/500  -  train loss : 0.001 /   test loss : 1.315
iteration : 490/500  -  train loss : 0.003 /   test loss : 1.336
iteration : 500/500  -  train loss : 0.001 /   test loss : 1.33

Training complete   //   Running time : 205  ------------


[Gene 6] Model 1 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([120, 27389])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 27389])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 1.025 /   test loss : 0.408
iteration : 10/500  -  train loss : 0.038 /   test loss : 0.434
iteration : 20/500  -  train loss : 0.007 /   test loss : 0.413
iteration : 30/500  -  train loss : 0.016 /   test loss : 0.447
iteration : 40/500  -  train loss : 0.013 /   test loss : 0.381
iteration : 50/500  -  train loss : 0.006 /   test loss : 0.418
iteration : 60/500  -  train loss : 0.006 /   test loss : 0.424
iteration : 70/500  -  train loss : 0.003 /   test loss : 0.395
iteration : 80/500  -  train loss : 0.011 /   test loss : 0.363
iteration : 90/500  -  train loss : 0.005 /   test loss : 0.4
iteration : 100/500  -  train loss : 0.003 /   test loss : 0.364
iteration : 110/500  -  train loss : 0.004 /   test loss : 0.367
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.376
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.383
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.386
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.363
iteration : 160/500  -  train loss : 0.002 /   test loss : 0.38
iteration : 170/500  -  train loss : 0.003 /   test loss : 0.382
iteration : 180/500  -  train loss : 0.003 /   test loss : 0.379
iteration : 190/500  -  train loss : 0.004 /   test loss : 0.349
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.358
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.367
iteration : 220/500  -  train loss : 0.002 /   test loss : 0.355
iteration : 230/500  -  train loss : 0.004 /   test loss : 0.326
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.362
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.359
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.353
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.353
iteration : 280/500  -  train loss : 0.003 /   test loss : 0.372
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.344
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.342
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.351
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.349
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.342
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.348
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.341
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.349
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.33
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.336
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.337
iteration : 400/500  -  train loss : 0.002 /   test loss : 0.327
iteration : 410/500  -  train loss : 0.002 /   test loss : 0.327
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.328
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.332
iteration : 440/500  -  train loss : 0.002 /   test loss : 0.329
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.339
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.328
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.325
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.344
iteration : 490/500  -  train loss : 0.002 /   test loss : 0.319
iteration : 500/500  -  train loss : 0.003 /   test loss : 0.338

Training complete   //   Running time : 202  ------------


[Gene 7] Model 1 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 17331])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 17331])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.459 /   test loss : 0.498
iteration : 10/500  -  train loss : 0.021 /   test loss : 0.46
iteration : 20/500  -  train loss : 0.004 /   test loss : 0.443
iteration : 30/500  -  train loss : 0.003 /   test loss : 0.432
iteration : 40/500  -  train loss : 0.002 /   test loss : 0.446
iteration : 50/500  -  train loss : 0.003 /   test loss : 0.449
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.446
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.444
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.443
iteration : 90/500  -  train loss : 0.005 /   test loss : 0.451
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.453
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.447
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.443
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.445
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.444
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.452
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.444
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.442
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.445
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.443
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.445
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.441
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.441
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.445
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.446
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.447
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.441
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.452
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.447
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.448
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.444
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.441
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.443
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.435
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.446
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.437
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.442
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.439
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.435
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.433
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.438
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.439
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.441
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.443
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.437
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.437
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.431
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.432
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.431
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.44
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.44

Training complete   //   Running time : 133  ------------


[Gene 7] Model 1 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 17331])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 17331])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.459 /   test loss : 0.405
iteration : 10/500  -  train loss : 0.015 /   test loss : 0.514
iteration : 20/500  -  train loss : 0.005 /   test loss : 0.498
iteration : 30/500  -  train loss : 0.004 /   test loss : 0.506
iteration : 40/500  -  train loss : 0.003 /   test loss : 0.487
iteration : 50/500  -  train loss : 0.003 /   test loss : 0.493
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.494
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.498
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.497
iteration : 90/500  -  train loss : 0.004 /   test loss : 0.473
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.483
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.463
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.471
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.479
iteration : 140/500  -  train loss : 0.003 /   test loss : 0.456
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.473
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.475
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.468
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.468
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.457
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.463
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.463
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.462
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.456
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.464
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.458
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.456
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.457
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.461
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.45
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.452
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.456
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.453
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.449
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.464
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.451
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.447
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.451
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.444
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.443
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.444
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.444
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.44
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.441
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.45
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.437
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.449
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.436
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.44
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.438
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.442

Training complete   //   Running time : 131  ------------


[Gene 7] Model 1 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 17331])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 17331])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.493 /   test loss : 0.301
iteration : 10/500  -  train loss : 0.018 /   test loss : 0.264
iteration : 20/500  -  train loss : 0.006 /   test loss : 0.229
iteration : 30/500  -  train loss : 0.004 /   test loss : 0.276
iteration : 40/500  -  train loss : 0.005 /   test loss : 0.237
iteration : 50/500  -  train loss : 0.004 /   test loss : 0.243
iteration : 60/500  -  train loss : 0.003 /   test loss : 0.268
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.251
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.252
iteration : 90/500  -  train loss : 0.005 /   test loss : 0.221
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.231
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.24
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.243
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.249
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.221
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.236
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.236
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.236
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.219
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.227
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.225
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.224
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.233
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.225
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.225
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.234
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.226
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.208
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.227
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.205
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.212
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.215
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.218
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.227
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.212
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.223
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.212
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.217
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.213
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.218
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.204
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.216
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.213
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.206
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.225
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.212
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.228
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.214
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.204
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.214
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.208

Training complete   //   Running time : 132  ------------


[Gene 7] Model 1 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 17331])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 17331])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.36 /   test loss : 1.468
iteration : 10/500  -  train loss : 0.018 /   test loss : 1.142
iteration : 20/500  -  train loss : 0.004 /   test loss : 1.181
iteration : 30/500  -  train loss : 0.002 /   test loss : 1.196
iteration : 40/500  -  train loss : 0.002 /   test loss : 1.209
iteration : 50/500  -  train loss : 0.002 /   test loss : 1.204
iteration : 60/500  -  train loss : 0.004 /   test loss : 1.159
iteration : 70/500  -  train loss : 0.002 /   test loss : 1.179
iteration : 80/500  -  train loss : 0.001 /   test loss : 1.213
iteration : 90/500  -  train loss : 0.003 /   test loss : 1.246
iteration : 100/500  -  train loss : 0.001 /   test loss : 1.213
iteration : 110/500  -  train loss : 0.002 /   test loss : 1.201
iteration : 120/500  -  train loss : 0.001 /   test loss : 1.217
iteration : 130/500  -  train loss : 0.001 /   test loss : 1.228
iteration : 140/500  -  train loss : 0.002 /   test loss : 1.263
iteration : 150/500  -  train loss : 0.001 /   test loss : 1.219
iteration : 160/500  -  train loss : 0.001 /   test loss : 1.224
iteration : 170/500  -  train loss : 0.001 /   test loss : 1.215
iteration : 180/500  -  train loss : 0.001 /   test loss : 1.233
iteration : 190/500  -  train loss : 0.001 /   test loss : 1.215
iteration : 200/500  -  train loss : 0.001 /   test loss : 1.234
iteration : 210/500  -  train loss : 0.001 /   test loss : 1.224
iteration : 220/500  -  train loss : 0.001 /   test loss : 1.22
iteration : 230/500  -  train loss : 0.001 /   test loss : 1.227
iteration : 240/500  -  train loss : 0.001 /   test loss : 1.227
iteration : 250/500  -  train loss : 0.001 /   test loss : 1.218
iteration : 260/500  -  train loss : 0.001 /   test loss : 1.246
iteration : 270/500  -  train loss : 0.0 /   test loss : 1.22
iteration : 280/500  -  train loss : 0.001 /   test loss : 1.217
iteration : 290/500  -  train loss : 0.001 /   test loss : 1.217
iteration : 300/500  -  train loss : 0.001 /   test loss : 1.263
iteration : 310/500  -  train loss : 0.001 /   test loss : 1.212
iteration : 320/500  -  train loss : 0.001 /   test loss : 1.225
iteration : 330/500  -  train loss : 0.001 /   test loss : 1.206
iteration : 340/500  -  train loss : 0.001 /   test loss : 1.223
iteration : 350/500  -  train loss : 0.001 /   test loss : 1.22
iteration : 360/500  -  train loss : 0.001 /   test loss : 1.212
iteration : 370/500  -  train loss : 0.001 /   test loss : 1.211
iteration : 380/500  -  train loss : 0.001 /   test loss : 1.23
iteration : 390/500  -  train loss : 0.001 /   test loss : 1.235
iteration : 400/500  -  train loss : 0.001 /   test loss : 1.233
iteration : 410/500  -  train loss : 0.001 /   test loss : 1.237
iteration : 420/500  -  train loss : 0.001 /   test loss : 1.233
iteration : 430/500  -  train loss : 0.001 /   test loss : 1.235
iteration : 440/500  -  train loss : 0.001 /   test loss : 1.241
iteration : 450/500  -  train loss : 0.001 /   test loss : 1.232
iteration : 460/500  -  train loss : 0.001 /   test loss : 1.235
iteration : 470/500  -  train loss : 0.001 /   test loss : 1.24
iteration : 480/500  -  train loss : 0.001 /   test loss : 1.258
iteration : 490/500  -  train loss : 0.0 /   test loss : 1.241
iteration : 500/500  -  train loss : 0.001 /   test loss : 1.25

Training complete   //   Running time : 131  ------------


[Gene 7] Model 1 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([120, 17331])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 17331])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.403 /   test loss : 0.707
iteration : 10/500  -  train loss : 0.01 /   test loss : 0.485
iteration : 20/500  -  train loss : 0.004 /   test loss : 0.505
iteration : 30/500  -  train loss : 0.003 /   test loss : 0.51
iteration : 40/500  -  train loss : 0.003 /   test loss : 0.509
iteration : 50/500  -  train loss : 0.002 /   test loss : 0.511
iteration : 60/500  -  train loss : 0.003 /   test loss : 0.513
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.513
iteration : 80/500  -  train loss : 0.003 /   test loss : 0.511
iteration : 90/500  -  train loss : 0.003 /   test loss : 0.513
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.517
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.504
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.514
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.517
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.502
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.515
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.519
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.517
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.521
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.513
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.517
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.519
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.512
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.519
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.514
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.522
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.52
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.525
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.526
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.527
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.522
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.538
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.53
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.526
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.539
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.543
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.525
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.521
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.531
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.54
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.54
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.539
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.532
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.544
iteration : 440/500  -  train loss : 0.002 /   test loss : 0.534
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.545
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.534
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.537
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.544
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.53
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.531

Training complete   //   Running time : 128  ------------


[Gene 8] Model 1 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 22963])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22963])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.23 /   test loss : 0.326
iteration : 10/500  -  train loss : 0.008 /   test loss : 0.233
iteration : 20/500  -  train loss : 0.008 /   test loss : 0.226
iteration : 30/500  -  train loss : 0.004 /   test loss : 0.237
iteration : 40/500  -  train loss : 0.002 /   test loss : 0.226
iteration : 50/500  -  train loss : 0.001 /   test loss : 0.231
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.232
iteration : 70/500  -  train loss : 0.001 /   test loss : 0.226
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.227
iteration : 90/500  -  train loss : 0.001 /   test loss : 0.227
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.23
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.222
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.227
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.226
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.227
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.225
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.223
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.226
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.224
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.228
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.227
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.226
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.23
iteration : 230/500  -  train loss : 0.0 /   test loss : 0.228
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.229
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.226
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.227
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.226
iteration : 280/500  -  train loss : 0.0 /   test loss : 0.227
iteration : 290/500  -  train loss : 0.0 /   test loss : 0.228
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.228
iteration : 310/500  -  train loss : 0.0 /   test loss : 0.226
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.224
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.228
iteration : 340/500  -  train loss : 0.0 /   test loss : 0.229
iteration : 350/500  -  train loss : 0.0 /   test loss : 0.229
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.225
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.226
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.228
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.229
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.226
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.229
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.229
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.224
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.226
iteration : 450/500  -  train loss : 0.0 /   test loss : 0.226
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.226
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.228
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.223
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.227
iteration : 500/500  -  train loss : 0.0 /   test loss : 0.224

Training complete   //   Running time : 173  ------------


[Gene 8] Model 1 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 22963])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22963])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.182 /   test loss : 0.383
iteration : 10/500  -  train loss : 0.009 /   test loss : 0.253
iteration : 20/500  -  train loss : 0.005 /   test loss : 0.251
iteration : 30/500  -  train loss : 0.001 /   test loss : 0.26
iteration : 40/500  -  train loss : 0.002 /   test loss : 0.259
iteration : 50/500  -  train loss : 0.001 /   test loss : 0.261
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.263
iteration : 70/500  -  train loss : 0.001 /   test loss : 0.264
iteration : 80/500  -  train loss : 0.003 /   test loss : 0.268
iteration : 90/500  -  train loss : 0.001 /   test loss : 0.266
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.271
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.274
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.273
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.273
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.277
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.275
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.28
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.277
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.282
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.277
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.274
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.279
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.281
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.281
iteration : 240/500  -  train loss : 0.0 /   test loss : 0.282
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.285
iteration : 260/500  -  train loss : 0.0 /   test loss : 0.286
iteration : 270/500  -  train loss : 0.0 /   test loss : 0.288
iteration : 280/500  -  train loss : 0.0 /   test loss : 0.286
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.29
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.287
iteration : 310/500  -  train loss : 0.0 /   test loss : 0.287
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.291
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.291
iteration : 340/500  -  train loss : 0.0 /   test loss : 0.288
iteration : 350/500  -  train loss : 0.0 /   test loss : 0.288
iteration : 360/500  -  train loss : 0.0 /   test loss : 0.287
iteration : 370/500  -  train loss : 0.0 /   test loss : 0.286
iteration : 380/500  -  train loss : 0.0 /   test loss : 0.29
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.291
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.29
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.291
iteration : 420/500  -  train loss : 0.0 /   test loss : 0.29
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.289
iteration : 440/500  -  train loss : 0.0 /   test loss : 0.29
iteration : 450/500  -  train loss : 0.0 /   test loss : 0.294
iteration : 460/500  -  train loss : 0.0 /   test loss : 0.291
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.292
iteration : 480/500  -  train loss : 0.0 /   test loss : 0.292
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.296
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.296

Training complete   //   Running time : 171  ------------


[Gene 8] Model 1 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 22963])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22963])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.166 /   test loss : 0.181
iteration : 10/500  -  train loss : 0.006 /   test loss : 0.145
iteration : 20/500  -  train loss : 0.006 /   test loss : 0.138
iteration : 30/500  -  train loss : 0.003 /   test loss : 0.14
iteration : 40/500  -  train loss : 0.004 /   test loss : 0.133
iteration : 50/500  -  train loss : 0.002 /   test loss : 0.141
iteration : 60/500  -  train loss : 0.003 /   test loss : 0.139
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.149
iteration : 80/500  -  train loss : 0.006 /   test loss : 0.151
iteration : 90/500  -  train loss : 0.001 /   test loss : 0.146
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.146
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.15
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.143
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.15
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.144
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.148
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.144
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.146
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.142
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.139
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.148
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.146
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.143
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.146
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.143
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.144
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.145
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.15
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.145
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.144
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.148
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.146
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 400/500  -  train loss : 0.0 /   test loss : 0.146
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.148
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.145
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.145
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.148
iteration : 480/500  -  train loss : 0.0 /   test loss : 0.147
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.151

Training complete   //   Running time : 171  ------------


[Gene 8] Model 1 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 22963])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22963])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.194 /   test loss : 0.165
iteration : 10/500  -  train loss : 0.015 /   test loss : 0.223
iteration : 20/500  -  train loss : 0.004 /   test loss : 0.163
iteration : 30/500  -  train loss : 0.002 /   test loss : 0.176
iteration : 40/500  -  train loss : 0.003 /   test loss : 0.182
iteration : 50/500  -  train loss : 0.002 /   test loss : 0.179
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.178
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.182
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.187
iteration : 90/500  -  train loss : 0.001 /   test loss : 0.17
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.178
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.18
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.185
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.18
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.177
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.179
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.184
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.186
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.175
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.176
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.185
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.184
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.176
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.18
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.184
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.184
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.187
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.186
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.188
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.184
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.187
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.183
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 330/500  -  train loss : 0.0 /   test loss : 0.184
iteration : 340/500  -  train loss : 0.0 /   test loss : 0.188
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.186
iteration : 360/500  -  train loss : 0.0 /   test loss : 0.187
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.179
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.181
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.182
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.18
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.182
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.184
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.189
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.184
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.182
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.182
iteration : 470/500  -  train loss : 0.0 /   test loss : 0.186
iteration : 480/500  -  train loss : 0.0 /   test loss : 0.184
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.188
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.186

Training complete   //   Running time : 172  ------------


[Gene 8] Model 1 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([120, 22963])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 22963])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.181 /   test loss : 0.315
iteration : 10/500  -  train loss : 0.014 /   test loss : 0.186
iteration : 20/500  -  train loss : 0.002 /   test loss : 0.186
iteration : 30/500  -  train loss : 0.003 /   test loss : 0.18
iteration : 40/500  -  train loss : 0.002 /   test loss : 0.183
iteration : 50/500  -  train loss : 0.001 /   test loss : 0.182
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.18
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.178
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.182
iteration : 90/500  -  train loss : 0.001 /   test loss : 0.185
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.183
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.186
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.188
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.189
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.188
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.188
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.189
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.189
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.187
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.193
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.19
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.193
iteration : 240/500  -  train loss : 0.0 /   test loss : 0.192
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.189
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.192
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.192
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 340/500  -  train loss : 0.0 /   test loss : 0.193
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.195
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.198
iteration : 390/500  -  train loss : 0.0 /   test loss : 0.196
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.197
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.197
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.198
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.195
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.2
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.196
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.199
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.2
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.196
iteration : 490/500  -  train loss : 0.0 /   test loss : 0.199
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.198

Training complete   //   Running time : 169  ------------


[Gene 9] Model 1 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 22048])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22048])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.77 /   test loss : 0.864
iteration : 10/500  -  train loss : 0.153 /   test loss : 0.837
iteration : 20/500  -  train loss : 0.027 /   test loss : 0.779
iteration : 30/500  -  train loss : 0.005 /   test loss : 0.791
iteration : 40/500  -  train loss : 0.006 /   test loss : 0.799
iteration : 50/500  -  train loss : 0.007 /   test loss : 0.77
iteration : 60/500  -  train loss : 0.003 /   test loss : 0.813
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.79
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.792
iteration : 90/500  -  train loss : 0.002 /   test loss : 0.812
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.795
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.793
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.795
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.806
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.791
iteration : 150/500  -  train loss : 0.003 /   test loss : 0.829
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.785
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.812
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.798
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.798
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.802
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.794
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.795
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.799
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.789
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.789
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.811
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.787
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.789
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.783
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.797
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.79
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.793
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.764
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.773
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.768
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.769
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.756
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.775
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.789
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.774
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.766
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.752
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.779
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.774
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.765
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.762
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.764
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.766
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.765
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.773

Training complete   //   Running time : 165  ------------


[Gene 9] Model 1 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 22048])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22048])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.783 /   test loss : 0.607
iteration : 10/500  -  train loss : 0.117 /   test loss : 0.711
iteration : 20/500  -  train loss : 0.014 /   test loss : 0.803
iteration : 30/500  -  train loss : 0.008 /   test loss : 0.835
iteration : 40/500  -  train loss : 0.009 /   test loss : 0.841
iteration : 50/500  -  train loss : 0.011 /   test loss : 0.845
iteration : 60/500  -  train loss : 0.004 /   test loss : 0.818
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.818
iteration : 80/500  -  train loss : 0.003 /   test loss : 0.82
iteration : 90/500  -  train loss : 0.003 /   test loss : 0.821
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.822
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.816
iteration : 120/500  -  train loss : 0.003 /   test loss : 0.797
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.797
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.788
iteration : 150/500  -  train loss : 0.003 /   test loss : 0.795
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.783
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.789
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.772
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.776
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.777
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.771
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.768
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.77
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.767
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.758
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.758
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.763
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.76
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.748
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.75
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.746
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.749
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.741
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.74
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.739
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.743
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.736
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.734
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.742
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.734
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.733
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.725
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.716
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.728
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.725
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.715
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.713
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.719
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.711
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.714

Training complete   //   Running time : 161  ------------


[Gene 9] Model 1 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 22048])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22048])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.605 /   test loss : 1.392
iteration : 10/500  -  train loss : 0.071 /   test loss : 1.44
iteration : 20/500  -  train loss : 0.007 /   test loss : 1.459
iteration : 30/500  -  train loss : 0.007 /   test loss : 1.476
iteration : 40/500  -  train loss : 0.006 /   test loss : 1.49
iteration : 50/500  -  train loss : 0.003 /   test loss : 1.46
iteration : 60/500  -  train loss : 0.002 /   test loss : 1.485
iteration : 70/500  -  train loss : 0.002 /   test loss : 1.471
iteration : 80/500  -  train loss : 0.003 /   test loss : 1.475
iteration : 90/500  -  train loss : 0.003 /   test loss : 1.473
iteration : 100/500  -  train loss : 0.004 /   test loss : 1.475
iteration : 110/500  -  train loss : 0.002 /   test loss : 1.473
iteration : 120/500  -  train loss : 0.003 /   test loss : 1.467
iteration : 130/500  -  train loss : 0.001 /   test loss : 1.469
iteration : 140/500  -  train loss : 0.001 /   test loss : 1.47
iteration : 150/500  -  train loss : 0.002 /   test loss : 1.475
iteration : 160/500  -  train loss : 0.001 /   test loss : 1.468
iteration : 170/500  -  train loss : 0.002 /   test loss : 1.459
iteration : 180/500  -  train loss : 0.001 /   test loss : 1.463
iteration : 190/500  -  train loss : 0.001 /   test loss : 1.459
iteration : 200/500  -  train loss : 0.001 /   test loss : 1.462
iteration : 210/500  -  train loss : 0.001 /   test loss : 1.464
iteration : 220/500  -  train loss : 0.001 /   test loss : 1.462
iteration : 230/500  -  train loss : 0.001 /   test loss : 1.464
iteration : 240/500  -  train loss : 0.001 /   test loss : 1.463
iteration : 250/500  -  train loss : 0.001 /   test loss : 1.463
iteration : 260/500  -  train loss : 0.001 /   test loss : 1.459
iteration : 270/500  -  train loss : 0.001 /   test loss : 1.454
iteration : 280/500  -  train loss : 0.001 /   test loss : 1.459
iteration : 290/500  -  train loss : 0.001 /   test loss : 1.462
iteration : 300/500  -  train loss : 0.001 /   test loss : 1.457
iteration : 310/500  -  train loss : 0.001 /   test loss : 1.461
iteration : 320/500  -  train loss : 0.001 /   test loss : 1.452
iteration : 330/500  -  train loss : 0.001 /   test loss : 1.446
iteration : 340/500  -  train loss : 0.001 /   test loss : 1.449
iteration : 350/500  -  train loss : 0.001 /   test loss : 1.447
iteration : 360/500  -  train loss : 0.001 /   test loss : 1.445
iteration : 370/500  -  train loss : 0.001 /   test loss : 1.444
iteration : 380/500  -  train loss : 0.001 /   test loss : 1.454
iteration : 390/500  -  train loss : 0.001 /   test loss : 1.447
iteration : 400/500  -  train loss : 0.001 /   test loss : 1.445
iteration : 410/500  -  train loss : 0.001 /   test loss : 1.449
iteration : 420/500  -  train loss : 0.001 /   test loss : 1.452
iteration : 430/500  -  train loss : 0.001 /   test loss : 1.451
iteration : 440/500  -  train loss : 0.001 /   test loss : 1.436
iteration : 450/500  -  train loss : 0.001 /   test loss : 1.439
iteration : 460/500  -  train loss : 0.001 /   test loss : 1.444
iteration : 470/500  -  train loss : 0.001 /   test loss : 1.442
iteration : 480/500  -  train loss : 0.001 /   test loss : 1.444
iteration : 490/500  -  train loss : 0.001 /   test loss : 1.438
iteration : 500/500  -  train loss : 0.001 /   test loss : 1.445

Training complete   //   Running time : 161  ------------


[Gene 9] Model 1 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 22048])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22048])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.747 /   test loss : 0.912
iteration : 10/500  -  train loss : 0.115 /   test loss : 0.912
iteration : 20/500  -  train loss : 0.015 /   test loss : 0.949
iteration : 30/500  -  train loss : 0.004 /   test loss : 0.946
iteration : 40/500  -  train loss : 0.008 /   test loss : 0.956
iteration : 50/500  -  train loss : 0.003 /   test loss : 0.941
iteration : 60/500  -  train loss : 0.003 /   test loss : 0.925
iteration : 70/500  -  train loss : 0.003 /   test loss : 0.949
iteration : 80/500  -  train loss : 0.004 /   test loss : 0.939
iteration : 90/500  -  train loss : 0.003 /   test loss : 0.965
iteration : 100/500  -  train loss : 0.004 /   test loss : 0.933
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.948
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.936
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.947
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.933
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.922
iteration : 160/500  -  train loss : 0.002 /   test loss : 0.954
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.937
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.944
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.928
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.937
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.943
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.935
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.942
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.936
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.941
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.931
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.936
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.933
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.938
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.93
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.936
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.932
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.942
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.927
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.94
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.933
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.938
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.936
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.936
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.933
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.935
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.934
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.929
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.927
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.937
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.931
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.94
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.943
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.944
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.935

Training complete   //   Running time : 162  ------------


[Gene 9] Model 1 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([120, 22048])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 22048])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.77 /   test loss : 0.738
iteration : 10/500  -  train loss : 0.123 /   test loss : 0.689
iteration : 20/500  -  train loss : 0.02 /   test loss : 0.714
iteration : 30/500  -  train loss : 0.005 /   test loss : 0.736
iteration : 40/500  -  train loss : 0.006 /   test loss : 0.711
iteration : 50/500  -  train loss : 0.005 /   test loss : 0.738
iteration : 60/500  -  train loss : 0.004 /   test loss : 0.717
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.714
iteration : 80/500  -  train loss : 0.004 /   test loss : 0.728
iteration : 90/500  -  train loss : 0.006 /   test loss : 0.699
iteration : 100/500  -  train loss : 0.003 /   test loss : 0.71
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.708
iteration : 120/500  -  train loss : 0.003 /   test loss : 0.708
iteration : 130/500  -  train loss : 0.004 /   test loss : 0.694
iteration : 140/500  -  train loss : 0.004 /   test loss : 0.713
iteration : 150/500  -  train loss : 0.003 /   test loss : 0.696
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.695
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.698
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.697
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.698
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.698
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.694
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.697
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.696
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.694
iteration : 250/500  -  train loss : 0.002 /   test loss : 0.702
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.696
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.693
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.694
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.69
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.687
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.685
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.679
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.69
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.683
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.685
iteration : 360/500  -  train loss : 0.002 /   test loss : 0.687
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.688
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.69
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.687
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.687
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.694
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.697
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.69
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.695
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.691
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.694
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.69
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.69
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.693
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.69

Training complete   //   Running time : 162  ------------


[Gene 10] Model 1 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 12638])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 12638])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.145 /   test loss : 0.218
iteration : 10/500  -  train loss : 0.009 /   test loss : 0.177
iteration : 20/500  -  train loss : 0.003 /   test loss : 0.178
iteration : 30/500  -  train loss : 0.004 /   test loss : 0.18
iteration : 40/500  -  train loss : 0.001 /   test loss : 0.174
iteration : 50/500  -  train loss : 0.002 /   test loss : 0.176
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.179
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.179
iteration : 80/500  -  train loss : 0.001 /   test loss : 0.178
iteration : 90/500  -  train loss : 0.001 /   test loss : 0.176
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.176
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.175
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.174
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.176
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.176
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.176
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.176
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.175
iteration : 180/500  -  train loss : 0.0 /   test loss : 0.173
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.174
iteration : 200/500  -  train loss : 0.0 /   test loss : 0.176
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.177
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.175
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.176
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.173
iteration : 250/500  -  train loss : 0.0 /   test loss : 0.174
iteration : 260/500  -  train loss : 0.0 /   test loss : 0.172
iteration : 270/500  -  train loss : 0.0 /   test loss : 0.173
iteration : 280/500  -  train loss : 0.0 /   test loss : 0.175
iteration : 290/500  -  train loss : 0.0 /   test loss : 0.175
iteration : 300/500  -  train loss : 0.0 /   test loss : 0.175
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.175
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.174
iteration : 330/500  -  train loss : 0.0 /   test loss : 0.175
iteration : 340/500  -  train loss : 0.0 /   test loss : 0.172
iteration : 350/500  -  train loss : 0.0 /   test loss : 0.176
iteration : 360/500  -  train loss : 0.0 /   test loss : 0.176
iteration : 370/500  -  train loss : 0.0 /   test loss : 0.174
iteration : 380/500  -  train loss : 0.0 /   test loss : 0.174
iteration : 390/500  -  train loss : 0.0 /   test loss : 0.175
iteration : 400/500  -  train loss : 0.0 /   test loss : 0.176
iteration : 410/500  -  train loss : 0.0 /   test loss : 0.174
iteration : 420/500  -  train loss : 0.0 /   test loss : 0.175
iteration : 430/500  -  train loss : 0.0 /   test loss : 0.175
iteration : 440/500  -  train loss : 0.0 /   test loss : 0.175
iteration : 450/500  -  train loss : 0.0 /   test loss : 0.173
iteration : 460/500  -  train loss : 0.0 /   test loss : 0.176
iteration : 470/500  -  train loss : 0.0 /   test loss : 0.175
iteration : 480/500  -  train loss : 0.0 /   test loss : 0.172
iteration : 490/500  -  train loss : 0.0 /   test loss : 0.173
iteration : 500/500  -  train loss : 0.0 /   test loss : 0.176

Training complete   //   Running time :  98  ------------


[Gene 10] Model 1 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 12638])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 12638])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.152 /   test loss : 0.197
iteration : 10/500  -  train loss : 0.01 /   test loss : 0.133
iteration : 20/500  -  train loss : 0.002 /   test loss : 0.137
iteration : 30/500  -  train loss : 0.002 /   test loss : 0.131
iteration : 40/500  -  train loss : 0.002 /   test loss : 0.137
iteration : 50/500  -  train loss : 0.002 /   test loss : 0.135
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.136
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.143
iteration : 80/500  -  train loss : 0.001 /   test loss : 0.145
iteration : 90/500  -  train loss : 0.001 /   test loss : 0.142
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.144
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.14
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.143
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.145
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.143
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.144
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 180/500  -  train loss : 0.0 /   test loss : 0.146
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.146
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 210/500  -  train loss : 0.0 /   test loss : 0.143
iteration : 220/500  -  train loss : 0.0 /   test loss : 0.144
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.145
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.144
iteration : 250/500  -  train loss : 0.0 /   test loss : 0.148
iteration : 260/500  -  train loss : 0.0 /   test loss : 0.151
iteration : 270/500  -  train loss : 0.0 /   test loss : 0.147
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.15
iteration : 290/500  -  train loss : 0.0 /   test loss : 0.149
iteration : 300/500  -  train loss : 0.0 /   test loss : 0.15
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.148
iteration : 330/500  -  train loss : 0.0 /   test loss : 0.151
iteration : 340/500  -  train loss : 0.0 /   test loss : 0.15
iteration : 350/500  -  train loss : 0.0 /   test loss : 0.149
iteration : 360/500  -  train loss : 0.0 /   test loss : 0.151
iteration : 370/500  -  train loss : 0.0 /   test loss : 0.154
iteration : 380/500  -  train loss : 0.0 /   test loss : 0.15
iteration : 390/500  -  train loss : 0.0 /   test loss : 0.151
iteration : 400/500  -  train loss : 0.0 /   test loss : 0.151
iteration : 410/500  -  train loss : 0.0 /   test loss : 0.15
iteration : 420/500  -  train loss : 0.0 /   test loss : 0.149
iteration : 430/500  -  train loss : 0.0 /   test loss : 0.151
iteration : 440/500  -  train loss : 0.0 /   test loss : 0.15
iteration : 450/500  -  train loss : 0.0 /   test loss : 0.151
iteration : 460/500  -  train loss : 0.0 /   test loss : 0.151
iteration : 470/500  -  train loss : 0.0 /   test loss : 0.15
iteration : 480/500  -  train loss : 0.0 /   test loss : 0.15
iteration : 490/500  -  train loss : 0.0 /   test loss : 0.149
iteration : 500/500  -  train loss : 0.0 /   test loss : 0.152

Training complete   //   Running time :  97  ------------


[Gene 10] Model 1 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 12638])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 12638])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.136 /   test loss : 0.25
iteration : 10/500  -  train loss : 0.01 /   test loss : 0.144
iteration : 20/500  -  train loss : 0.002 /   test loss : 0.15
iteration : 30/500  -  train loss : 0.002 /   test loss : 0.151
iteration : 40/500  -  train loss : 0.002 /   test loss : 0.152
iteration : 50/500  -  train loss : 0.001 /   test loss : 0.15
iteration : 60/500  -  train loss : 0.001 /   test loss : 0.151
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.156
iteration : 80/500  -  train loss : 0.001 /   test loss : 0.152
iteration : 90/500  -  train loss : 0.001 /   test loss : 0.152
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.152
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.157
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.155
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.158
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.158
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.157
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.159
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.154
iteration : 180/500  -  train loss : 0.0 /   test loss : 0.157
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.157
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.159
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.16
iteration : 220/500  -  train loss : 0.0 /   test loss : 0.159
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.157
iteration : 240/500  -  train loss : 0.0 /   test loss : 0.158
iteration : 250/500  -  train loss : 0.0 /   test loss : 0.157
iteration : 260/500  -  train loss : 0.0 /   test loss : 0.158
iteration : 270/500  -  train loss : 0.0 /   test loss : 0.159
iteration : 280/500  -  train loss : 0.0 /   test loss : 0.158
iteration : 290/500  -  train loss : 0.0 /   test loss : 0.157
iteration : 300/500  -  train loss : 0.0 /   test loss : 0.16
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.161
iteration : 320/500  -  train loss : 0.0 /   test loss : 0.158
iteration : 330/500  -  train loss : 0.0 /   test loss : 0.162
iteration : 340/500  -  train loss : 0.0 /   test loss : 0.16
iteration : 350/500  -  train loss : 0.0 /   test loss : 0.161
iteration : 360/500  -  train loss : 0.0 /   test loss : 0.157
iteration : 370/500  -  train loss : 0.0 /   test loss : 0.159
iteration : 380/500  -  train loss : 0.0 /   test loss : 0.158
iteration : 390/500  -  train loss : 0.0 /   test loss : 0.158
iteration : 400/500  -  train loss : 0.0 /   test loss : 0.16
iteration : 410/500  -  train loss : 0.0 /   test loss : 0.159
iteration : 420/500  -  train loss : 0.0 /   test loss : 0.159
iteration : 430/500  -  train loss : 0.0 /   test loss : 0.161
iteration : 440/500  -  train loss : 0.0 /   test loss : 0.158
iteration : 450/500  -  train loss : 0.0 /   test loss : 0.16
iteration : 460/500  -  train loss : 0.0 /   test loss : 0.159
iteration : 470/500  -  train loss : 0.0 /   test loss : 0.16
iteration : 480/500  -  train loss : 0.0 /   test loss : 0.159
iteration : 490/500  -  train loss : 0.0 /   test loss : 0.161
iteration : 500/500  -  train loss : 0.0 /   test loss : 0.159

Training complete   //   Running time :  97  ------------


[Gene 10] Model 1 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([123, 12638])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 12638])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.145 /   test loss : 0.184
iteration : 10/500  -  train loss : 0.008 /   test loss : 0.179
iteration : 20/500  -  train loss : 0.002 /   test loss : 0.181
iteration : 30/500  -  train loss : 0.003 /   test loss : 0.183
iteration : 40/500  -  train loss : 0.002 /   test loss : 0.196
iteration : 50/500  -  train loss : 0.002 /   test loss : 0.184
iteration : 60/500  -  train loss : 0.001 /   test loss : 0.182
iteration : 70/500  -  train loss : 0.002 /   test loss : 0.179
iteration : 80/500  -  train loss : 0.002 /   test loss : 0.189
iteration : 90/500  -  train loss : 0.003 /   test loss : 0.184
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.184
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.18
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.177
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.18
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.18
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.183
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.178
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.178
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.183
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.174
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.176
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.177
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.18
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.178
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.178
iteration : 250/500  -  train loss : 0.0 /   test loss : 0.179
iteration : 260/500  -  train loss : 0.0 /   test loss : 0.181
iteration : 270/500  -  train loss : 0.0 /   test loss : 0.179
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.179
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.179
iteration : 300/500  -  train loss : 0.0 /   test loss : 0.18
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.181
iteration : 320/500  -  train loss : 0.0 /   test loss : 0.176
iteration : 330/500  -  train loss : 0.0 /   test loss : 0.175
iteration : 340/500  -  train loss : 0.0 /   test loss : 0.179
iteration : 350/500  -  train loss : 0.0 /   test loss : 0.175
iteration : 360/500  -  train loss : 0.0 /   test loss : 0.177
iteration : 370/500  -  train loss : 0.0 /   test loss : 0.179
iteration : 380/500  -  train loss : 0.0 /   test loss : 0.176
iteration : 390/500  -  train loss : 0.0 /   test loss : 0.176
iteration : 400/500  -  train loss : 0.0 /   test loss : 0.177
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.178
iteration : 420/500  -  train loss : 0.0 /   test loss : 0.175
iteration : 430/500  -  train loss : 0.0 /   test loss : 0.176
iteration : 440/500  -  train loss : 0.0 /   test loss : 0.178
iteration : 450/500  -  train loss : 0.0 /   test loss : 0.178
iteration : 460/500  -  train loss : 0.0 /   test loss : 0.179
iteration : 470/500  -  train loss : 0.0 /   test loss : 0.176
iteration : 480/500  -  train loss : 0.0 /   test loss : 0.178
iteration : 490/500  -  train loss : 0.0 /   test loss : 0.176
iteration : 500/500  -  train loss : 0.0 /   test loss : 0.175

Training complete   //   Running time :  97  ------------


[Gene 10] Model 1 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.50

Data shape @@@@@@
Train data :  torch.Size([120, 12638])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 12638])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.155 /   test loss : 0.175
iteration : 10/500  -  train loss : 0.011 /   test loss : 0.139
iteration : 20/500  -  train loss : 0.003 /   test loss : 0.133
iteration : 30/500  -  train loss : 0.002 /   test loss : 0.134
iteration : 40/500  -  train loss : 0.001 /   test loss : 0.129
iteration : 50/500  -  train loss : 0.001 /   test loss : 0.133
iteration : 60/500  -  train loss : 0.002 /   test loss : 0.138
iteration : 70/500  -  train loss : 0.001 /   test loss : 0.137
iteration : 80/500  -  train loss : 0.001 /   test loss : 0.135
iteration : 90/500  -  train loss : 0.003 /   test loss : 0.133
iteration : 100/500  -  train loss : 0.001 /   test loss : 0.132
iteration : 110/500  -  train loss : 0.001 /   test loss : 0.13
iteration : 120/500  -  train loss : 0.001 /   test loss : 0.128
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.131
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.13
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.13
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.129
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.13
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.128
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.13
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.129
iteration : 210/500  -  train loss : 0.0 /   test loss : 0.126
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.129
iteration : 230/500  -  train loss : 0.0 /   test loss : 0.126
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.125
iteration : 250/500  -  train loss : 0.0 /   test loss : 0.127
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.126
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.124
iteration : 280/500  -  train loss : 0.0 /   test loss : 0.126
iteration : 290/500  -  train loss : 0.0 /   test loss : 0.125
iteration : 300/500  -  train loss : 0.0 /   test loss : 0.124
iteration : 310/500  -  train loss : 0.0 /   test loss : 0.124
iteration : 320/500  -  train loss : 0.0 /   test loss : 0.124
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.123
iteration : 340/500  -  train loss : 0.0 /   test loss : 0.123
iteration : 350/500  -  train loss : 0.0 /   test loss : 0.124
iteration : 360/500  -  train loss : 0.0 /   test loss : 0.124
iteration : 370/500  -  train loss : 0.0 /   test loss : 0.125
iteration : 380/500  -  train loss : 0.0 /   test loss : 0.125
iteration : 390/500  -  train loss : 0.0 /   test loss : 0.124
iteration : 400/500  -  train loss : 0.0 /   test loss : 0.124
iteration : 410/500  -  train loss : 0.0 /   test loss : 0.123
iteration : 420/500  -  train loss : 0.0 /   test loss : 0.122
iteration : 430/500  -  train loss : 0.0 /   test loss : 0.124
iteration : 440/500  -  train loss : 0.0 /   test loss : 0.123
iteration : 450/500  -  train loss : 0.0 /   test loss : 0.122
iteration : 460/500  -  train loss : 0.0 /   test loss : 0.124
iteration : 470/500  -  train loss : 0.0 /   test loss : 0.125
iteration : 480/500  -  train loss : 0.0 /   test loss : 0.125
iteration : 490/500  -  train loss : 0.0 /   test loss : 0.124
iteration : 500/500  -  train loss : 0.0 /   test loss : 0.125

Training complete   //   Running time :  96  ------------


[Gene 1] Model 2 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 23049])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23049])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.324 /   test loss : 0.32
iteration : 10/500  -  train loss : 0.061 /   test loss : 0.168
iteration : 20/500  -  train loss : 0.042 /   test loss : 0.178
iteration : 30/500  -  train loss : 0.017 /   test loss : 0.192
iteration : 40/500  -  train loss : 0.014 /   test loss : 0.174
iteration : 50/500  -  train loss : 0.012 /   test loss : 0.186
iteration : 60/500  -  train loss : 0.007 /   test loss : 0.18
iteration : 70/500  -  train loss : 0.006 /   test loss : 0.177
iteration : 80/500  -  train loss : 0.004 /   test loss : 0.188
iteration : 90/500  -  train loss : 0.003 /   test loss : 0.189
iteration : 100/500  -  train loss : 0.003 /   test loss : 0.187
iteration : 110/500  -  train loss : 0.004 /   test loss : 0.186
iteration : 120/500  -  train loss : 0.005 /   test loss : 0.184
iteration : 130/500  -  train loss : 0.003 /   test loss : 0.184
iteration : 140/500  -  train loss : 0.003 /   test loss : 0.191
iteration : 150/500  -  train loss : 0.003 /   test loss : 0.187
iteration : 160/500  -  train loss : 0.003 /   test loss : 0.188
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.191
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.19
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.194
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.192
iteration : 220/500  -  train loss : 0.002 /   test loss : 0.193
iteration : 230/500  -  train loss : 0.003 /   test loss : 0.195
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.196
iteration : 250/500  -  train loss : 0.002 /   test loss : 0.19
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.191
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.196
iteration : 280/500  -  train loss : 0.002 /   test loss : 0.197
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.189
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.2
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.199
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.195
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.199
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.197
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.197
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.188
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 400/500  -  train loss : 0.002 /   test loss : 0.198
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.192
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.198
iteration : 430/500  -  train loss : 0.002 /   test loss : 0.203
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.199
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.196
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.196
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.196
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.2
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.2
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.202

Training complete   //   Running time : 173  ------------


[Gene 1] Model 2 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 23049])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23049])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.302 /   test loss : 0.38
iteration : 10/500  -  train loss : 0.055 /   test loss : 0.304
iteration : 20/500  -  train loss : 0.036 /   test loss : 0.333
iteration : 30/500  -  train loss : 0.015 /   test loss : 0.297
iteration : 40/500  -  train loss : 0.012 /   test loss : 0.319
iteration : 50/500  -  train loss : 0.008 /   test loss : 0.301
iteration : 60/500  -  train loss : 0.009 /   test loss : 0.281
iteration : 70/500  -  train loss : 0.008 /   test loss : 0.31
iteration : 80/500  -  train loss : 0.005 /   test loss : 0.301
iteration : 90/500  -  train loss : 0.005 /   test loss : 0.31
iteration : 100/500  -  train loss : 0.003 /   test loss : 0.314
iteration : 110/500  -  train loss : 0.003 /   test loss : 0.319
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.314
iteration : 130/500  -  train loss : 0.003 /   test loss : 0.305
iteration : 140/500  -  train loss : 0.003 /   test loss : 0.321
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.311
iteration : 160/500  -  train loss : 0.002 /   test loss : 0.313
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.308
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.312
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.32
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.322
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.326
iteration : 220/500  -  train loss : 0.002 /   test loss : 0.319
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.318
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.307
iteration : 250/500  -  train loss : 0.002 /   test loss : 0.317
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.317
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.315
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.325
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.32
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.313
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.318
iteration : 320/500  -  train loss : 0.002 /   test loss : 0.323
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.33
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.329
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.323
iteration : 360/500  -  train loss : 0.002 /   test loss : 0.319
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.334
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.327
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.323
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.326
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.332
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.33
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.325
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.334
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.328
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.329
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.329
iteration : 480/500  -  train loss : 0.003 /   test loss : 0.333
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.337
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.336

Training complete   //   Running time : 172  ------------


[Gene 1] Model 2 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 23049])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23049])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.325 /   test loss : 0.311
iteration : 10/500  -  train loss : 0.061 /   test loss : 0.226
iteration : 20/500  -  train loss : 0.028 /   test loss : 0.21
iteration : 30/500  -  train loss : 0.014 /   test loss : 0.216
iteration : 40/500  -  train loss : 0.011 /   test loss : 0.224
iteration : 50/500  -  train loss : 0.009 /   test loss : 0.224
iteration : 60/500  -  train loss : 0.008 /   test loss : 0.223
iteration : 70/500  -  train loss : 0.006 /   test loss : 0.226
iteration : 80/500  -  train loss : 0.005 /   test loss : 0.227
iteration : 90/500  -  train loss : 0.004 /   test loss : 0.235
iteration : 100/500  -  train loss : 0.003 /   test loss : 0.236
iteration : 110/500  -  train loss : 0.005 /   test loss : 0.237
iteration : 120/500  -  train loss : 0.004 /   test loss : 0.242
iteration : 130/500  -  train loss : 0.003 /   test loss : 0.235
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.232
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.233
iteration : 160/500  -  train loss : 0.002 /   test loss : 0.239
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.238
iteration : 180/500  -  train loss : 0.003 /   test loss : 0.234
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.237
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.234
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.237
iteration : 220/500  -  train loss : 0.002 /   test loss : 0.241
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.24
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.24
iteration : 250/500  -  train loss : 0.002 /   test loss : 0.24
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.241
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.238
iteration : 280/500  -  train loss : 0.002 /   test loss : 0.24
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.241
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.242
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.241
iteration : 320/500  -  train loss : 0.003 /   test loss : 0.245
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.245
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.242
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.243
iteration : 360/500  -  train loss : 0.002 /   test loss : 0.245
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.24
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.243
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.242
iteration : 400/500  -  train loss : 0.002 /   test loss : 0.249
iteration : 410/500  -  train loss : 0.002 /   test loss : 0.239
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.245
iteration : 430/500  -  train loss : 0.003 /   test loss : 0.246
iteration : 440/500  -  train loss : 0.002 /   test loss : 0.242
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.242
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.238
iteration : 470/500  -  train loss : 0.002 /   test loss : 0.235
iteration : 480/500  -  train loss : 0.003 /   test loss : 0.242
iteration : 490/500  -  train loss : 0.002 /   test loss : 0.244
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.246

Training complete   //   Running time : 173  ------------


[Gene 1] Model 2 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 23049])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23049])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.274 /   test loss : 0.538
iteration : 10/500  -  train loss : 0.051 /   test loss : 0.35
iteration : 20/500  -  train loss : 0.027 /   test loss : 0.315
iteration : 30/500  -  train loss : 0.016 /   test loss : 0.323
iteration : 40/500  -  train loss : 0.012 /   test loss : 0.313
iteration : 50/500  -  train loss : 0.007 /   test loss : 0.316
iteration : 60/500  -  train loss : 0.005 /   test loss : 0.305
iteration : 70/500  -  train loss : 0.005 /   test loss : 0.312
iteration : 80/500  -  train loss : 0.004 /   test loss : 0.317
iteration : 90/500  -  train loss : 0.004 /   test loss : 0.318
iteration : 100/500  -  train loss : 0.003 /   test loss : 0.32
iteration : 110/500  -  train loss : 0.003 /   test loss : 0.327
iteration : 120/500  -  train loss : 0.003 /   test loss : 0.333
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.324
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.327
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.325
iteration : 160/500  -  train loss : 0.003 /   test loss : 0.331
iteration : 170/500  -  train loss : 0.003 /   test loss : 0.324
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.324
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.326
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.333
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.325
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.322
iteration : 230/500  -  train loss : 0.002 /   test loss : 0.328
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.33
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.336
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.334
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.329
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.326
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.338
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.326
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.33
iteration : 320/500  -  train loss : 0.002 /   test loss : 0.336
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.327
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.331
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.332
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.33
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.337
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.326
iteration : 390/500  -  train loss : 0.002 /   test loss : 0.33
iteration : 400/500  -  train loss : 0.002 /   test loss : 0.338
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.338
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.337
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.34
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.325
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.338
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.328
iteration : 470/500  -  train loss : 0.002 /   test loss : 0.332
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.336
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.34
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.328

Training complete   //   Running time : 173  ------------


[Gene 1] Model 2 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([120, 23049])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 23049])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.336 /   test loss : 0.268
iteration : 10/500  -  train loss : 0.066 /   test loss : 0.194
iteration : 20/500  -  train loss : 0.034 /   test loss : 0.174
iteration : 30/500  -  train loss : 0.03 /   test loss : 0.195
iteration : 40/500  -  train loss : 0.016 /   test loss : 0.199
iteration : 50/500  -  train loss : 0.01 /   test loss : 0.193
iteration : 60/500  -  train loss : 0.006 /   test loss : 0.184
iteration : 70/500  -  train loss : 0.006 /   test loss : 0.188
iteration : 80/500  -  train loss : 0.004 /   test loss : 0.189
iteration : 90/500  -  train loss : 0.005 /   test loss : 0.188
iteration : 100/500  -  train loss : 0.004 /   test loss : 0.195
iteration : 110/500  -  train loss : 0.003 /   test loss : 0.189
iteration : 120/500  -  train loss : 0.004 /   test loss : 0.191
iteration : 130/500  -  train loss : 0.003 /   test loss : 0.194
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.187
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.189
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.189
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.191
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.189
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.195
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.195
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.194
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.189
iteration : 230/500  -  train loss : 0.002 /   test loss : 0.194
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.191
iteration : 250/500  -  train loss : 0.002 /   test loss : 0.193
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.19
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.189
iteration : 280/500  -  train loss : 0.002 /   test loss : 0.192
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.196
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.194
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.192
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.189
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.191
iteration : 340/500  -  train loss : 0.003 /   test loss : 0.192
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 360/500  -  train loss : 0.002 /   test loss : 0.192
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.193
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 400/500  -  train loss : 0.002 /   test loss : 0.194
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.195
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.195
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.197
iteration : 440/500  -  train loss : 0.002 /   test loss : 0.197
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.199
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.197
iteration : 490/500  -  train loss : 0.002 /   test loss : 0.197
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.198

Training complete   //   Running time : 170  ------------


[Gene 2] Model 2 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 22930])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22930])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.692 /   test loss : 0.616
iteration : 10/500  -  train loss : 0.118 /   test loss : 0.49
iteration : 20/500  -  train loss : 0.045 /   test loss : 0.531
iteration : 30/500  -  train loss : 0.019 /   test loss : 0.529
iteration : 40/500  -  train loss : 0.02 /   test loss : 0.523
iteration : 50/500  -  train loss : 0.008 /   test loss : 0.546
iteration : 60/500  -  train loss : 0.009 /   test loss : 0.548
iteration : 70/500  -  train loss : 0.007 /   test loss : 0.534
iteration : 80/500  -  train loss : 0.006 /   test loss : 0.518
iteration : 90/500  -  train loss : 0.006 /   test loss : 0.518
iteration : 100/500  -  train loss : 0.003 /   test loss : 0.52
iteration : 110/500  -  train loss : 0.004 /   test loss : 0.531
iteration : 120/500  -  train loss : 0.005 /   test loss : 0.523
iteration : 130/500  -  train loss : 0.004 /   test loss : 0.528
iteration : 140/500  -  train loss : 0.003 /   test loss : 0.522
iteration : 150/500  -  train loss : 0.004 /   test loss : 0.523
iteration : 160/500  -  train loss : 0.004 /   test loss : 0.521
iteration : 170/500  -  train loss : 0.004 /   test loss : 0.53
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.532
iteration : 190/500  -  train loss : 0.003 /   test loss : 0.524
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.525
iteration : 210/500  -  train loss : 0.003 /   test loss : 0.529
iteration : 220/500  -  train loss : 0.006 /   test loss : 0.532
iteration : 230/500  -  train loss : 0.004 /   test loss : 0.526
iteration : 240/500  -  train loss : 0.004 /   test loss : 0.525
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.52
iteration : 260/500  -  train loss : 0.003 /   test loss : 0.519
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.524
iteration : 280/500  -  train loss : 0.004 /   test loss : 0.519
iteration : 290/500  -  train loss : 0.003 /   test loss : 0.51
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.517
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.514
iteration : 320/500  -  train loss : 0.004 /   test loss : 0.512
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.516
iteration : 340/500  -  train loss : 0.003 /   test loss : 0.52
iteration : 350/500  -  train loss : 0.003 /   test loss : 0.519
iteration : 360/500  -  train loss : 0.003 /   test loss : 0.525
iteration : 370/500  -  train loss : 0.003 /   test loss : 0.519
iteration : 380/500  -  train loss : 0.002 /   test loss : 0.523
iteration : 390/500  -  train loss : 0.006 /   test loss : 0.507
iteration : 400/500  -  train loss : 0.003 /   test loss : 0.512
iteration : 410/500  -  train loss : 0.003 /   test loss : 0.514
iteration : 420/500  -  train loss : 0.003 /   test loss : 0.518
iteration : 430/500  -  train loss : 0.004 /   test loss : 0.515
iteration : 440/500  -  train loss : 0.003 /   test loss : 0.515
iteration : 450/500  -  train loss : 0.003 /   test loss : 0.519
iteration : 460/500  -  train loss : 0.003 /   test loss : 0.527
iteration : 470/500  -  train loss : 0.003 /   test loss : 0.526
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.53
iteration : 490/500  -  train loss : 0.003 /   test loss : 0.52
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.52

Training complete   //   Running time : 172  ------------


[Gene 2] Model 2 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 22930])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22930])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.565 /   test loss : 1.318
iteration : 10/500  -  train loss : 0.104 /   test loss : 0.676
iteration : 20/500  -  train loss : 0.046 /   test loss : 0.719
iteration : 30/500  -  train loss : 0.023 /   test loss : 0.752
iteration : 40/500  -  train loss : 0.014 /   test loss : 0.774
iteration : 50/500  -  train loss : 0.013 /   test loss : 0.764
iteration : 60/500  -  train loss : 0.012 /   test loss : 0.731
iteration : 70/500  -  train loss : 0.007 /   test loss : 0.761
iteration : 80/500  -  train loss : 0.006 /   test loss : 0.736
iteration : 90/500  -  train loss : 0.005 /   test loss : 0.77
iteration : 100/500  -  train loss : 0.003 /   test loss : 0.766
iteration : 110/500  -  train loss : 0.003 /   test loss : 0.768
iteration : 120/500  -  train loss : 0.005 /   test loss : 0.767
iteration : 130/500  -  train loss : 0.004 /   test loss : 0.747
iteration : 140/500  -  train loss : 0.003 /   test loss : 0.756
iteration : 150/500  -  train loss : 0.003 /   test loss : 0.76
iteration : 160/500  -  train loss : 0.004 /   test loss : 0.782
iteration : 170/500  -  train loss : 0.003 /   test loss : 0.779
iteration : 180/500  -  train loss : 0.003 /   test loss : 0.766
iteration : 190/500  -  train loss : 0.003 /   test loss : 0.804
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.787
iteration : 210/500  -  train loss : 0.005 /   test loss : 0.836
iteration : 220/500  -  train loss : 0.003 /   test loss : 0.801
iteration : 230/500  -  train loss : 0.002 /   test loss : 0.769
iteration : 240/500  -  train loss : 0.004 /   test loss : 0.829
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.786
iteration : 260/500  -  train loss : 0.003 /   test loss : 0.82
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.791
iteration : 280/500  -  train loss : 0.003 /   test loss : 0.791
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.801
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.796
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.798
iteration : 320/500  -  train loss : 0.004 /   test loss : 0.813
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.789
iteration : 340/500  -  train loss : 0.003 /   test loss : 0.808
iteration : 350/500  -  train loss : 0.003 /   test loss : 0.829
iteration : 360/500  -  train loss : 0.002 /   test loss : 0.824
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.81
iteration : 380/500  -  train loss : 0.002 /   test loss : 0.799
iteration : 390/500  -  train loss : 0.002 /   test loss : 0.803
iteration : 400/500  -  train loss : 0.002 /   test loss : 0.788
iteration : 410/500  -  train loss : 0.004 /   test loss : 0.82
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.815
iteration : 430/500  -  train loss : 0.003 /   test loss : 0.823
iteration : 440/500  -  train loss : 0.002 /   test loss : 0.801
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.794
iteration : 460/500  -  train loss : 0.003 /   test loss : 0.802
iteration : 470/500  -  train loss : 0.002 /   test loss : 0.803
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.802
iteration : 490/500  -  train loss : 0.003 /   test loss : 0.797
iteration : 500/500  -  train loss : 0.003 /   test loss : 0.815

Training complete   //   Running time : 172  ------------


[Gene 2] Model 2 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 22930])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22930])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.711 /   test loss : 0.668
iteration : 10/500  -  train loss : 0.136 /   test loss : 0.381
iteration : 20/500  -  train loss : 0.052 /   test loss : 0.412
iteration : 30/500  -  train loss : 0.034 /   test loss : 0.439
iteration : 40/500  -  train loss : 0.017 /   test loss : 0.427
iteration : 50/500  -  train loss : 0.014 /   test loss : 0.436
iteration : 60/500  -  train loss : 0.01 /   test loss : 0.433
iteration : 70/500  -  train loss : 0.008 /   test loss : 0.446
iteration : 80/500  -  train loss : 0.008 /   test loss : 0.414
iteration : 90/500  -  train loss : 0.004 /   test loss : 0.424
iteration : 100/500  -  train loss : 0.007 /   test loss : 0.426
iteration : 110/500  -  train loss : 0.004 /   test loss : 0.431
iteration : 120/500  -  train loss : 0.007 /   test loss : 0.441
iteration : 130/500  -  train loss : 0.003 /   test loss : 0.438
iteration : 140/500  -  train loss : 0.003 /   test loss : 0.446
iteration : 150/500  -  train loss : 0.004 /   test loss : 0.442
iteration : 160/500  -  train loss : 0.004 /   test loss : 0.439
iteration : 170/500  -  train loss : 0.003 /   test loss : 0.435
iteration : 180/500  -  train loss : 0.003 /   test loss : 0.448
iteration : 190/500  -  train loss : 0.003 /   test loss : 0.458
iteration : 200/500  -  train loss : 0.003 /   test loss : 0.443
iteration : 210/500  -  train loss : 0.004 /   test loss : 0.462
iteration : 220/500  -  train loss : 0.003 /   test loss : 0.451
iteration : 230/500  -  train loss : 0.003 /   test loss : 0.444
iteration : 240/500  -  train loss : 0.003 /   test loss : 0.454
iteration : 250/500  -  train loss : 0.004 /   test loss : 0.449
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.452
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.452
iteration : 280/500  -  train loss : 0.005 /   test loss : 0.463
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.463
iteration : 300/500  -  train loss : 0.003 /   test loss : 0.458
iteration : 310/500  -  train loss : 0.004 /   test loss : 0.443
iteration : 320/500  -  train loss : 0.004 /   test loss : 0.467
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.45
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.453
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.456
iteration : 360/500  -  train loss : 0.004 /   test loss : 0.454
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.455
iteration : 380/500  -  train loss : 0.002 /   test loss : 0.458
iteration : 390/500  -  train loss : 0.003 /   test loss : 0.47
iteration : 400/500  -  train loss : 0.002 /   test loss : 0.454
iteration : 410/500  -  train loss : 0.003 /   test loss : 0.462
iteration : 420/500  -  train loss : 0.003 /   test loss : 0.474
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.464
iteration : 440/500  -  train loss : 0.003 /   test loss : 0.463
iteration : 450/500  -  train loss : 0.003 /   test loss : 0.463
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.458
iteration : 470/500  -  train loss : 0.003 /   test loss : 0.472
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.455
iteration : 490/500  -  train loss : 0.003 /   test loss : 0.46
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.468

Training complete   //   Running time : 171  ------------


[Gene 2] Model 2 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 22930])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22930])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.696 /   test loss : 0.641
iteration : 10/500  -  train loss : 0.142 /   test loss : 0.502
iteration : 20/500  -  train loss : 0.058 /   test loss : 0.437
iteration : 30/500  -  train loss : 0.036 /   test loss : 0.453
iteration : 40/500  -  train loss : 0.02 /   test loss : 0.429
iteration : 50/500  -  train loss : 0.016 /   test loss : 0.413
iteration : 60/500  -  train loss : 0.01 /   test loss : 0.418
iteration : 70/500  -  train loss : 0.009 /   test loss : 0.409
iteration : 80/500  -  train loss : 0.006 /   test loss : 0.418
iteration : 90/500  -  train loss : 0.008 /   test loss : 0.4
iteration : 100/500  -  train loss : 0.005 /   test loss : 0.407
iteration : 110/500  -  train loss : 0.004 /   test loss : 0.414
iteration : 120/500  -  train loss : 0.005 /   test loss : 0.448
iteration : 130/500  -  train loss : 0.004 /   test loss : 0.411
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.417
iteration : 150/500  -  train loss : 0.005 /   test loss : 0.421
iteration : 160/500  -  train loss : 0.004 /   test loss : 0.438
iteration : 170/500  -  train loss : 0.005 /   test loss : 0.419
iteration : 180/500  -  train loss : 0.004 /   test loss : 0.41
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.42
iteration : 200/500  -  train loss : 0.003 /   test loss : 0.411
iteration : 210/500  -  train loss : 0.004 /   test loss : 0.416
iteration : 220/500  -  train loss : 0.004 /   test loss : 0.43
iteration : 230/500  -  train loss : 0.003 /   test loss : 0.417
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.424
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.432
iteration : 260/500  -  train loss : 0.003 /   test loss : 0.422
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.425
iteration : 280/500  -  train loss : 0.002 /   test loss : 0.415
iteration : 290/500  -  train loss : 0.003 /   test loss : 0.423
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.424
iteration : 310/500  -  train loss : 0.005 /   test loss : 0.431
iteration : 320/500  -  train loss : 0.003 /   test loss : 0.428
iteration : 330/500  -  train loss : 0.003 /   test loss : 0.431
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.429
iteration : 350/500  -  train loss : 0.003 /   test loss : 0.435
iteration : 360/500  -  train loss : 0.005 /   test loss : 0.427
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.432
iteration : 380/500  -  train loss : 0.003 /   test loss : 0.433
iteration : 390/500  -  train loss : 0.002 /   test loss : 0.425
iteration : 400/500  -  train loss : 0.003 /   test loss : 0.433
iteration : 410/500  -  train loss : 0.002 /   test loss : 0.432
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.429
iteration : 430/500  -  train loss : 0.004 /   test loss : 0.43
iteration : 440/500  -  train loss : 0.002 /   test loss : 0.416
iteration : 450/500  -  train loss : 0.004 /   test loss : 0.418
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.418
iteration : 470/500  -  train loss : 0.004 /   test loss : 0.423
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.436
iteration : 490/500  -  train loss : 0.004 /   test loss : 0.428
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.42

Training complete   //   Running time : 172  ------------


[Gene 2] Model 2 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([120, 22930])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 22930])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.693 /   test loss : 0.504
iteration : 10/500  -  train loss : 0.144 /   test loss : 0.349
iteration : 20/500  -  train loss : 0.058 /   test loss : 0.328
iteration : 30/500  -  train loss : 0.031 /   test loss : 0.323
iteration : 40/500  -  train loss : 0.018 /   test loss : 0.324
iteration : 50/500  -  train loss : 0.011 /   test loss : 0.32
iteration : 60/500  -  train loss : 0.015 /   test loss : 0.325
iteration : 70/500  -  train loss : 0.013 /   test loss : 0.325
iteration : 80/500  -  train loss : 0.007 /   test loss : 0.325
iteration : 90/500  -  train loss : 0.007 /   test loss : 0.321
iteration : 100/500  -  train loss : 0.006 /   test loss : 0.332
iteration : 110/500  -  train loss : 0.007 /   test loss : 0.33
iteration : 120/500  -  train loss : 0.006 /   test loss : 0.339
iteration : 130/500  -  train loss : 0.004 /   test loss : 0.333
iteration : 140/500  -  train loss : 0.005 /   test loss : 0.336
iteration : 150/500  -  train loss : 0.004 /   test loss : 0.332
iteration : 160/500  -  train loss : 0.004 /   test loss : 0.33
iteration : 170/500  -  train loss : 0.004 /   test loss : 0.335
iteration : 180/500  -  train loss : 0.003 /   test loss : 0.33
iteration : 190/500  -  train loss : 0.005 /   test loss : 0.336
iteration : 200/500  -  train loss : 0.004 /   test loss : 0.343
iteration : 210/500  -  train loss : 0.006 /   test loss : 0.343
iteration : 220/500  -  train loss : 0.004 /   test loss : 0.341
iteration : 230/500  -  train loss : 0.005 /   test loss : 0.349
iteration : 240/500  -  train loss : 0.003 /   test loss : 0.351
iteration : 250/500  -  train loss : 0.004 /   test loss : 0.35
iteration : 260/500  -  train loss : 0.003 /   test loss : 0.349
iteration : 270/500  -  train loss : 0.003 /   test loss : 0.351
iteration : 280/500  -  train loss : 0.003 /   test loss : 0.347
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.346
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.351
iteration : 310/500  -  train loss : 0.004 /   test loss : 0.351
iteration : 320/500  -  train loss : 0.004 /   test loss : 0.355
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.348
iteration : 340/500  -  train loss : 0.005 /   test loss : 0.36
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.35
iteration : 360/500  -  train loss : 0.002 /   test loss : 0.351
iteration : 370/500  -  train loss : 0.003 /   test loss : 0.355
iteration : 380/500  -  train loss : 0.002 /   test loss : 0.357
iteration : 390/500  -  train loss : 0.002 /   test loss : 0.355
iteration : 400/500  -  train loss : 0.003 /   test loss : 0.358
iteration : 410/500  -  train loss : 0.004 /   test loss : 0.357
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.357
iteration : 430/500  -  train loss : 0.003 /   test loss : 0.357
iteration : 440/500  -  train loss : 0.004 /   test loss : 0.361
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.361
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.358
iteration : 470/500  -  train loss : 0.003 /   test loss : 0.357
iteration : 480/500  -  train loss : 0.003 /   test loss : 0.36
iteration : 490/500  -  train loss : 0.003 /   test loss : 0.362
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.354

Training complete   //   Running time : 169  ------------


[Gene 3] Model 2 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 18753])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 18753])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.929 /   test loss : 0.324
iteration : 10/500  -  train loss : 0.224 /   test loss : 0.155
iteration : 20/500  -  train loss : 0.1 /   test loss : 0.178
iteration : 30/500  -  train loss : 0.047 /   test loss : 0.202
iteration : 40/500  -  train loss : 0.028 /   test loss : 0.203
iteration : 50/500  -  train loss : 0.019 /   test loss : 0.192
iteration : 60/500  -  train loss : 0.013 /   test loss : 0.193
iteration : 70/500  -  train loss : 0.01 /   test loss : 0.199
iteration : 80/500  -  train loss : 0.008 /   test loss : 0.201
iteration : 90/500  -  train loss : 0.005 /   test loss : 0.19
iteration : 100/500  -  train loss : 0.004 /   test loss : 0.203
iteration : 110/500  -  train loss : 0.004 /   test loss : 0.196
iteration : 120/500  -  train loss : 0.004 /   test loss : 0.201
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.184
iteration : 140/500  -  train loss : 0.003 /   test loss : 0.178
iteration : 150/500  -  train loss : 0.003 /   test loss : 0.192
iteration : 160/500  -  train loss : 0.004 /   test loss : 0.189
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.184
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.181
iteration : 190/500  -  train loss : 0.004 /   test loss : 0.165
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.172
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.186
iteration : 220/500  -  train loss : 0.004 /   test loss : 0.168
iteration : 230/500  -  train loss : 0.002 /   test loss : 0.168
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.181
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.174
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.171
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.173
iteration : 280/500  -  train loss : 0.002 /   test loss : 0.165
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.182
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.167
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.169
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.166
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.167
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.177
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.172
iteration : 360/500  -  train loss : 0.002 /   test loss : 0.173
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.171
iteration : 380/500  -  train loss : 0.002 /   test loss : 0.178
iteration : 390/500  -  train loss : 0.002 /   test loss : 0.171
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.171
iteration : 410/500  -  train loss : 0.002 /   test loss : 0.161
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.163
iteration : 430/500  -  train loss : 0.002 /   test loss : 0.164
iteration : 440/500  -  train loss : 0.004 /   test loss : 0.16
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.165
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.169
iteration : 470/500  -  train loss : 0.002 /   test loss : 0.168
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.161
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.159
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.166

Training complete   //   Running time : 141  ------------


[Gene 3] Model 2 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 18753])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 18753])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.507 /   test loss : 2.025
iteration : 10/500  -  train loss : 0.101 /   test loss : 1.01
iteration : 20/500  -  train loss : 0.042 /   test loss : 1.069
iteration : 30/500  -  train loss : 0.021 /   test loss : 1.021
iteration : 40/500  -  train loss : 0.012 /   test loss : 1.04
iteration : 50/500  -  train loss : 0.008 /   test loss : 1.016
iteration : 60/500  -  train loss : 0.007 /   test loss : 1.038
iteration : 70/500  -  train loss : 0.006 /   test loss : 1.016
iteration : 80/500  -  train loss : 0.005 /   test loss : 1.008
iteration : 90/500  -  train loss : 0.003 /   test loss : 1.02
iteration : 100/500  -  train loss : 0.003 /   test loss : 1.025
iteration : 110/500  -  train loss : 0.003 /   test loss : 1.034
iteration : 120/500  -  train loss : 0.003 /   test loss : 1.006
iteration : 130/500  -  train loss : 0.002 /   test loss : 1.01
iteration : 140/500  -  train loss : 0.002 /   test loss : 1.004
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.995
iteration : 160/500  -  train loss : 0.003 /   test loss : 1.004
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.987
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.996
iteration : 190/500  -  train loss : 0.003 /   test loss : 1.001
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.984
iteration : 210/500  -  train loss : 0.002 /   test loss : 1.014
iteration : 220/500  -  train loss : 0.002 /   test loss : 0.983
iteration : 230/500  -  train loss : 0.002 /   test loss : 0.983
iteration : 240/500  -  train loss : 0.001 /   test loss : 1.008
iteration : 250/500  -  train loss : 0.002 /   test loss : 1.004
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.992
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.972
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.982
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.989
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.988
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.964
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.95
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.964
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.975
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.992
iteration : 360/500  -  train loss : 0.002 /   test loss : 1.007
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.953
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.94
iteration : 390/500  -  train loss : 0.002 /   test loss : 0.993
iteration : 400/500  -  train loss : 0.002 /   test loss : 0.985
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.969
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.947
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.977
iteration : 440/500  -  train loss : 0.003 /   test loss : 1.015
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.952
iteration : 460/500  -  train loss : 0.002 /   test loss : 1.014
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.962
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.982
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.967
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.95

Training complete   //   Running time : 142  ------------


[Gene 3] Model 2 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 18753])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 18753])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.9 /   test loss : 0.431
iteration : 10/500  -  train loss : 0.223 /   test loss : 0.3
iteration : 20/500  -  train loss : 0.104 /   test loss : 0.255
iteration : 30/500  -  train loss : 0.051 /   test loss : 0.23
iteration : 40/500  -  train loss : 0.024 /   test loss : 0.243
iteration : 50/500  -  train loss : 0.021 /   test loss : 0.253
iteration : 60/500  -  train loss : 0.012 /   test loss : 0.242
iteration : 70/500  -  train loss : 0.011 /   test loss : 0.24
iteration : 80/500  -  train loss : 0.007 /   test loss : 0.247
iteration : 90/500  -  train loss : 0.006 /   test loss : 0.247
iteration : 100/500  -  train loss : 0.009 /   test loss : 0.252
iteration : 110/500  -  train loss : 0.003 /   test loss : 0.234
iteration : 120/500  -  train loss : 0.004 /   test loss : 0.241
iteration : 130/500  -  train loss : 0.004 /   test loss : 0.247
iteration : 140/500  -  train loss : 0.004 /   test loss : 0.252
iteration : 150/500  -  train loss : 0.003 /   test loss : 0.239
iteration : 160/500  -  train loss : 0.003 /   test loss : 0.246
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.25
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.243
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.243
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.248
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.248
iteration : 220/500  -  train loss : 0.002 /   test loss : 0.252
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.248
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.247
iteration : 250/500  -  train loss : 0.002 /   test loss : 0.247
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.244
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.241
iteration : 280/500  -  train loss : 0.002 /   test loss : 0.241
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.246
iteration : 300/500  -  train loss : 0.004 /   test loss : 0.243
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.243
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.245
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.245
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.247
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.251
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.251
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.253
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.249
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.248
iteration : 400/500  -  train loss : 0.002 /   test loss : 0.243
iteration : 410/500  -  train loss : 0.002 /   test loss : 0.24
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.246
iteration : 430/500  -  train loss : 0.003 /   test loss : 0.249
iteration : 440/500  -  train loss : 0.002 /   test loss : 0.253
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.248
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.249
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.251
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.249
iteration : 490/500  -  train loss : 0.002 /   test loss : 0.247
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.245

Training complete   //   Running time : 141  ------------


[Gene 3] Model 2 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 18753])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 18753])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.777 /   test loss : 0.987
iteration : 10/500  -  train loss : 0.202 /   test loss : 0.352
iteration : 20/500  -  train loss : 0.089 /   test loss : 0.364
iteration : 30/500  -  train loss : 0.044 /   test loss : 0.375
iteration : 40/500  -  train loss : 0.025 /   test loss : 0.384
iteration : 50/500  -  train loss : 0.016 /   test loss : 0.368
iteration : 60/500  -  train loss : 0.011 /   test loss : 0.382
iteration : 70/500  -  train loss : 0.01 /   test loss : 0.371
iteration : 80/500  -  train loss : 0.007 /   test loss : 0.356
iteration : 90/500  -  train loss : 0.005 /   test loss : 0.362
iteration : 100/500  -  train loss : 0.005 /   test loss : 0.356
iteration : 110/500  -  train loss : 0.004 /   test loss : 0.344
iteration : 120/500  -  train loss : 0.004 /   test loss : 0.35
iteration : 130/500  -  train loss : 0.004 /   test loss : 0.348
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.349
iteration : 150/500  -  train loss : 0.003 /   test loss : 0.346
iteration : 160/500  -  train loss : 0.004 /   test loss : 0.337
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.338
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.334
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.333
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.329
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.326
iteration : 220/500  -  train loss : 0.002 /   test loss : 0.323
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.323
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.32
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.319
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.318
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.318
iteration : 280/500  -  train loss : 0.002 /   test loss : 0.312
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.321
iteration : 300/500  -  train loss : 0.003 /   test loss : 0.32
iteration : 310/500  -  train loss : 0.003 /   test loss : 0.317
iteration : 320/500  -  train loss : 0.002 /   test loss : 0.32
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.315
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.315
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.315
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.316
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.318
iteration : 380/500  -  train loss : 0.002 /   test loss : 0.318
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.316
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.312
iteration : 410/500  -  train loss : 0.002 /   test loss : 0.308
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.304
iteration : 430/500  -  train loss : 0.003 /   test loss : 0.304
iteration : 440/500  -  train loss : 0.002 /   test loss : 0.305
iteration : 450/500  -  train loss : 0.003 /   test loss : 0.311
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.307
iteration : 470/500  -  train loss : 0.002 /   test loss : 0.306
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.31
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.307
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.299

Training complete   //   Running time : 141  ------------


[Gene 3] Model 2 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([120, 18753])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 18753])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.838 /   test loss : 0.462
iteration : 10/500  -  train loss : 0.219 /   test loss : 0.226
iteration : 20/500  -  train loss : 0.106 /   test loss : 0.234
iteration : 30/500  -  train loss : 0.058 /   test loss : 0.213
iteration : 40/500  -  train loss : 0.031 /   test loss : 0.214
iteration : 50/500  -  train loss : 0.021 /   test loss : 0.201
iteration : 60/500  -  train loss : 0.015 /   test loss : 0.208
iteration : 70/500  -  train loss : 0.012 /   test loss : 0.195
iteration : 80/500  -  train loss : 0.006 /   test loss : 0.196
iteration : 90/500  -  train loss : 0.006 /   test loss : 0.198
iteration : 100/500  -  train loss : 0.005 /   test loss : 0.201
iteration : 110/500  -  train loss : 0.004 /   test loss : 0.203
iteration : 120/500  -  train loss : 0.003 /   test loss : 0.204
iteration : 130/500  -  train loss : 0.003 /   test loss : 0.201
iteration : 140/500  -  train loss : 0.004 /   test loss : 0.205
iteration : 150/500  -  train loss : 0.003 /   test loss : 0.198
iteration : 160/500  -  train loss : 0.005 /   test loss : 0.208
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.209
iteration : 180/500  -  train loss : 0.003 /   test loss : 0.208
iteration : 190/500  -  train loss : 0.003 /   test loss : 0.205
iteration : 200/500  -  train loss : 0.004 /   test loss : 0.215
iteration : 210/500  -  train loss : 0.003 /   test loss : 0.216
iteration : 220/500  -  train loss : 0.002 /   test loss : 0.213
iteration : 230/500  -  train loss : 0.002 /   test loss : 0.211
iteration : 240/500  -  train loss : 0.003 /   test loss : 0.206
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.218
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.214
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.21
iteration : 280/500  -  train loss : 0.004 /   test loss : 0.21
iteration : 290/500  -  train loss : 0.003 /   test loss : 0.21
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.211
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.214
iteration : 320/500  -  train loss : 0.002 /   test loss : 0.219
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.218
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.219
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.22
iteration : 360/500  -  train loss : 0.002 /   test loss : 0.218
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.211
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.21
iteration : 390/500  -  train loss : 0.002 /   test loss : 0.216
iteration : 400/500  -  train loss : 0.004 /   test loss : 0.212
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.213
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.225
iteration : 430/500  -  train loss : 0.002 /   test loss : 0.223
iteration : 440/500  -  train loss : 0.002 /   test loss : 0.227
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.219
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.221
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.22
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.224
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.223
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.226

Training complete   //   Running time : 139  ------------


[Gene 4] Model 2 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 23718])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23718])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.687 /   test loss : 0.301
iteration : 10/500  -  train loss : 0.201 /   test loss : 0.268
iteration : 20/500  -  train loss : 0.089 /   test loss : 0.283
iteration : 30/500  -  train loss : 0.046 /   test loss : 0.283
iteration : 40/500  -  train loss : 0.023 /   test loss : 0.292
iteration : 50/500  -  train loss : 0.02 /   test loss : 0.294
iteration : 60/500  -  train loss : 0.016 /   test loss : 0.308
iteration : 70/500  -  train loss : 0.01 /   test loss : 0.295
iteration : 80/500  -  train loss : 0.007 /   test loss : 0.293
iteration : 90/500  -  train loss : 0.011 /   test loss : 0.285
iteration : 100/500  -  train loss : 0.007 /   test loss : 0.283
iteration : 110/500  -  train loss : 0.006 /   test loss : 0.283
iteration : 120/500  -  train loss : 0.004 /   test loss : 0.291
iteration : 130/500  -  train loss : 0.004 /   test loss : 0.278
iteration : 140/500  -  train loss : 0.003 /   test loss : 0.292
iteration : 150/500  -  train loss : 0.004 /   test loss : 0.28
iteration : 160/500  -  train loss : 0.003 /   test loss : 0.285
iteration : 170/500  -  train loss : 0.004 /   test loss : 0.271
iteration : 180/500  -  train loss : 0.004 /   test loss : 0.273
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.284
iteration : 200/500  -  train loss : 0.005 /   test loss : 0.272
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.28
iteration : 220/500  -  train loss : 0.003 /   test loss : 0.271
iteration : 230/500  -  train loss : 0.003 /   test loss : 0.273
iteration : 240/500  -  train loss : 0.003 /   test loss : 0.279
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.273
iteration : 260/500  -  train loss : 0.003 /   test loss : 0.278
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.282
iteration : 280/500  -  train loss : 0.004 /   test loss : 0.27
iteration : 290/500  -  train loss : 0.003 /   test loss : 0.279
iteration : 300/500  -  train loss : 0.004 /   test loss : 0.278
iteration : 310/500  -  train loss : 0.003 /   test loss : 0.271
iteration : 320/500  -  train loss : 0.002 /   test loss : 0.273
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.271
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.278
iteration : 350/500  -  train loss : 0.003 /   test loss : 0.277
iteration : 360/500  -  train loss : 0.003 /   test loss : 0.273
iteration : 370/500  -  train loss : 0.003 /   test loss : 0.279
iteration : 380/500  -  train loss : 0.003 /   test loss : 0.281
iteration : 390/500  -  train loss : 0.004 /   test loss : 0.266
iteration : 400/500  -  train loss : 0.002 /   test loss : 0.282
iteration : 410/500  -  train loss : 0.003 /   test loss : 0.277
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.277
iteration : 430/500  -  train loss : 0.002 /   test loss : 0.277
iteration : 440/500  -  train loss : 0.005 /   test loss : 0.264
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.276
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.277
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.276
iteration : 480/500  -  train loss : 0.003 /   test loss : 0.278
iteration : 490/500  -  train loss : 0.003 /   test loss : 0.264
iteration : 500/500  -  train loss : 0.003 /   test loss : 0.267

Training complete   //   Running time : 179  ------------


[Gene 4] Model 2 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 23718])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23718])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.496 /   test loss : 1.0
iteration : 10/500  -  train loss : 0.128 /   test loss : 0.956
iteration : 20/500  -  train loss : 0.058 /   test loss : 0.936
iteration : 30/500  -  train loss : 0.038 /   test loss : 0.928
iteration : 40/500  -  train loss : 0.023 /   test loss : 0.92
iteration : 50/500  -  train loss : 0.019 /   test loss : 0.94
iteration : 60/500  -  train loss : 0.013 /   test loss : 0.932
iteration : 70/500  -  train loss : 0.009 /   test loss : 0.921
iteration : 80/500  -  train loss : 0.006 /   test loss : 0.928
iteration : 90/500  -  train loss : 0.006 /   test loss : 0.921
iteration : 100/500  -  train loss : 0.008 /   test loss : 0.919
iteration : 110/500  -  train loss : 0.004 /   test loss : 0.909
iteration : 120/500  -  train loss : 0.005 /   test loss : 0.917
iteration : 130/500  -  train loss : 0.004 /   test loss : 0.902
iteration : 140/500  -  train loss : 0.003 /   test loss : 0.896
iteration : 150/500  -  train loss : 0.003 /   test loss : 0.897
iteration : 160/500  -  train loss : 0.003 /   test loss : 0.891
iteration : 170/500  -  train loss : 0.004 /   test loss : 0.892
iteration : 180/500  -  train loss : 0.003 /   test loss : 0.894
iteration : 190/500  -  train loss : 0.003 /   test loss : 0.9
iteration : 200/500  -  train loss : 0.006 /   test loss : 0.888
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.893
iteration : 220/500  -  train loss : 0.003 /   test loss : 0.894
iteration : 230/500  -  train loss : 0.003 /   test loss : 0.887
iteration : 240/500  -  train loss : 0.003 /   test loss : 0.884
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.89
iteration : 260/500  -  train loss : 0.003 /   test loss : 0.891
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.877
iteration : 280/500  -  train loss : 0.003 /   test loss : 0.88
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.885
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.889
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.89
iteration : 320/500  -  train loss : 0.002 /   test loss : 0.878
iteration : 330/500  -  train loss : 0.005 /   test loss : 0.878
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.885
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.881
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.874
iteration : 370/500  -  train loss : 0.003 /   test loss : 0.887
iteration : 380/500  -  train loss : 0.002 /   test loss : 0.883
iteration : 390/500  -  train loss : 0.003 /   test loss : 0.88
iteration : 400/500  -  train loss : 0.002 /   test loss : 0.882
iteration : 410/500  -  train loss : 0.002 /   test loss : 0.875
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.873
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.879
iteration : 440/500  -  train loss : 0.003 /   test loss : 0.871
iteration : 450/500  -  train loss : 0.003 /   test loss : 0.874
iteration : 460/500  -  train loss : 0.003 /   test loss : 0.877
iteration : 470/500  -  train loss : 0.003 /   test loss : 0.879
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.873
iteration : 490/500  -  train loss : 0.003 /   test loss : 0.871
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.873

Training complete   //   Running time : 177  ------------


[Gene 4] Model 2 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 23718])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23718])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.677 /   test loss : 0.779
iteration : 10/500  -  train loss : 0.195 /   test loss : 0.5
iteration : 20/500  -  train loss : 0.083 /   test loss : 0.407
iteration : 30/500  -  train loss : 0.046 /   test loss : 0.426
iteration : 40/500  -  train loss : 0.031 /   test loss : 0.472
iteration : 50/500  -  train loss : 0.027 /   test loss : 0.42
iteration : 60/500  -  train loss : 0.013 /   test loss : 0.433
iteration : 70/500  -  train loss : 0.009 /   test loss : 0.445
iteration : 80/500  -  train loss : 0.007 /   test loss : 0.448
iteration : 90/500  -  train loss : 0.006 /   test loss : 0.436
iteration : 100/500  -  train loss : 0.005 /   test loss : 0.439
iteration : 110/500  -  train loss : 0.004 /   test loss : 0.444
iteration : 120/500  -  train loss : 0.003 /   test loss : 0.449
iteration : 130/500  -  train loss : 0.005 /   test loss : 0.435
iteration : 140/500  -  train loss : 0.003 /   test loss : 0.438
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.447
iteration : 160/500  -  train loss : 0.002 /   test loss : 0.445
iteration : 170/500  -  train loss : 0.005 /   test loss : 0.441
iteration : 180/500  -  train loss : 0.003 /   test loss : 0.437
iteration : 190/500  -  train loss : 0.005 /   test loss : 0.441
iteration : 200/500  -  train loss : 0.003 /   test loss : 0.446
iteration : 210/500  -  train loss : 0.003 /   test loss : 0.428
iteration : 220/500  -  train loss : 0.004 /   test loss : 0.434
iteration : 230/500  -  train loss : 0.002 /   test loss : 0.441
iteration : 240/500  -  train loss : 0.004 /   test loss : 0.445
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.448
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.444
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.45
iteration : 280/500  -  train loss : 0.003 /   test loss : 0.446
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.439
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.429
iteration : 310/500  -  train loss : 0.003 /   test loss : 0.441
iteration : 320/500  -  train loss : 0.002 /   test loss : 0.446
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.446
iteration : 340/500  -  train loss : 0.003 /   test loss : 0.446
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.439
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.439
iteration : 370/500  -  train loss : 0.003 /   test loss : 0.441
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.444
iteration : 390/500  -  train loss : 0.003 /   test loss : 0.45
iteration : 400/500  -  train loss : 0.003 /   test loss : 0.449
iteration : 410/500  -  train loss : 0.003 /   test loss : 0.445
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.439
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.433
iteration : 440/500  -  train loss : 0.002 /   test loss : 0.44
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.44
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.438
iteration : 470/500  -  train loss : 0.002 /   test loss : 0.444
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.433
iteration : 490/500  -  train loss : 0.003 /   test loss : 0.434
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.434

Training complete   //   Running time : 177  ------------


[Gene 4] Model 2 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 23718])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23718])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.592 /   test loss : 1.074
iteration : 10/500  -  train loss : 0.154 /   test loss : 0.802
iteration : 20/500  -  train loss : 0.056 /   test loss : 0.718
iteration : 30/500  -  train loss : 0.032 /   test loss : 0.777
iteration : 40/500  -  train loss : 0.015 /   test loss : 0.775
iteration : 50/500  -  train loss : 0.01 /   test loss : 0.727
iteration : 60/500  -  train loss : 0.015 /   test loss : 0.73
iteration : 70/500  -  train loss : 0.006 /   test loss : 0.726
iteration : 80/500  -  train loss : 0.005 /   test loss : 0.747
iteration : 90/500  -  train loss : 0.004 /   test loss : 0.739
iteration : 100/500  -  train loss : 0.005 /   test loss : 0.745
iteration : 110/500  -  train loss : 0.005 /   test loss : 0.765
iteration : 120/500  -  train loss : 0.004 /   test loss : 0.763
iteration : 130/500  -  train loss : 0.003 /   test loss : 0.759
iteration : 140/500  -  train loss : 0.003 /   test loss : 0.748
iteration : 150/500  -  train loss : 0.003 /   test loss : 0.75
iteration : 160/500  -  train loss : 0.003 /   test loss : 0.775
iteration : 170/500  -  train loss : 0.003 /   test loss : 0.758
iteration : 180/500  -  train loss : 0.003 /   test loss : 0.761
iteration : 190/500  -  train loss : 0.003 /   test loss : 0.768
iteration : 200/500  -  train loss : 0.003 /   test loss : 0.778
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.76
iteration : 220/500  -  train loss : 0.004 /   test loss : 0.76
iteration : 230/500  -  train loss : 0.003 /   test loss : 0.764
iteration : 240/500  -  train loss : 0.003 /   test loss : 0.78
iteration : 250/500  -  train loss : 0.002 /   test loss : 0.776
iteration : 260/500  -  train loss : 0.003 /   test loss : 0.773
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.793
iteration : 280/500  -  train loss : 0.003 /   test loss : 0.788
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.769
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.78
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.785
iteration : 320/500  -  train loss : 0.002 /   test loss : 0.789
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.774
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.782
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.785
iteration : 360/500  -  train loss : 0.002 /   test loss : 0.776
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.777
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.779
iteration : 390/500  -  train loss : 0.002 /   test loss : 0.788
iteration : 400/500  -  train loss : 0.002 /   test loss : 0.788
iteration : 410/500  -  train loss : 0.002 /   test loss : 0.78
iteration : 420/500  -  train loss : 0.003 /   test loss : 0.765
iteration : 430/500  -  train loss : 0.002 /   test loss : 0.776
iteration : 440/500  -  train loss : 0.002 /   test loss : 0.784
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.786
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.788
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.778
iteration : 480/500  -  train loss : 0.003 /   test loss : 0.779
iteration : 490/500  -  train loss : 0.002 /   test loss : 0.787
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.788

Training complete   //   Running time : 176  ------------


[Gene 4] Model 2 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([120, 23718])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 23718])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.683 /   test loss : 0.378
iteration : 10/500  -  train loss : 0.208 /   test loss : 0.265
iteration : 20/500  -  train loss : 0.089 /   test loss : 0.281
iteration : 30/500  -  train loss : 0.046 /   test loss : 0.286
iteration : 40/500  -  train loss : 0.027 /   test loss : 0.28
iteration : 50/500  -  train loss : 0.018 /   test loss : 0.286
iteration : 60/500  -  train loss : 0.013 /   test loss : 0.279
iteration : 70/500  -  train loss : 0.012 /   test loss : 0.275
iteration : 80/500  -  train loss : 0.008 /   test loss : 0.274
iteration : 90/500  -  train loss : 0.004 /   test loss : 0.279
iteration : 100/500  -  train loss : 0.006 /   test loss : 0.284
iteration : 110/500  -  train loss : 0.005 /   test loss : 0.286
iteration : 120/500  -  train loss : 0.007 /   test loss : 0.281
iteration : 130/500  -  train loss : 0.005 /   test loss : 0.284
iteration : 140/500  -  train loss : 0.004 /   test loss : 0.279
iteration : 150/500  -  train loss : 0.004 /   test loss : 0.275
iteration : 160/500  -  train loss : 0.005 /   test loss : 0.271
iteration : 170/500  -  train loss : 0.004 /   test loss : 0.274
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.28
iteration : 190/500  -  train loss : 0.003 /   test loss : 0.278
iteration : 200/500  -  train loss : 0.003 /   test loss : 0.277
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.281
iteration : 220/500  -  train loss : 0.004 /   test loss : 0.287
iteration : 230/500  -  train loss : 0.002 /   test loss : 0.277
iteration : 240/500  -  train loss : 0.004 /   test loss : 0.274
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.272
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.277
iteration : 270/500  -  train loss : 0.003 /   test loss : 0.277
iteration : 280/500  -  train loss : 0.002 /   test loss : 0.274
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.271
iteration : 300/500  -  train loss : 0.004 /   test loss : 0.269
iteration : 310/500  -  train loss : 0.003 /   test loss : 0.277
iteration : 320/500  -  train loss : 0.003 /   test loss : 0.27
iteration : 330/500  -  train loss : 0.003 /   test loss : 0.281
iteration : 340/500  -  train loss : 0.005 /   test loss : 0.275
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.275
iteration : 360/500  -  train loss : 0.003 /   test loss : 0.276
iteration : 370/500  -  train loss : 0.003 /   test loss : 0.283
iteration : 380/500  -  train loss : 0.005 /   test loss : 0.283
iteration : 390/500  -  train loss : 0.002 /   test loss : 0.276
iteration : 400/500  -  train loss : 0.004 /   test loss : 0.278
iteration : 410/500  -  train loss : 0.004 /   test loss : 0.275
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.275
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.279
iteration : 440/500  -  train loss : 0.002 /   test loss : 0.269
iteration : 450/500  -  train loss : 0.003 /   test loss : 0.267
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.271
iteration : 470/500  -  train loss : 0.002 /   test loss : 0.277
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.276
iteration : 490/500  -  train loss : 0.002 /   test loss : 0.283
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.274

Training complete   //   Running time : 173  ------------


[Gene 5] Model 2 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 21013])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 21013])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.59 /   test loss : 1.31
iteration : 10/500  -  train loss : 0.272 /   test loss : 0.916
iteration : 20/500  -  train loss : 0.168 /   test loss : 0.934
iteration : 30/500  -  train loss : 0.116 /   test loss : 1.02
iteration : 40/500  -  train loss : 0.074 /   test loss : 0.963
iteration : 50/500  -  train loss : 0.045 /   test loss : 1.028
iteration : 60/500  -  train loss : 0.03 /   test loss : 1.022
iteration : 70/500  -  train loss : 0.02 /   test loss : 1.06
iteration : 80/500  -  train loss : 0.013 /   test loss : 1.034
iteration : 90/500  -  train loss : 0.011 /   test loss : 1.033
iteration : 100/500  -  train loss : 0.011 /   test loss : 1.06
iteration : 110/500  -  train loss : 0.007 /   test loss : 1.048
iteration : 120/500  -  train loss : 0.005 /   test loss : 1.052
iteration : 130/500  -  train loss : 0.005 /   test loss : 1.049
iteration : 140/500  -  train loss : 0.003 /   test loss : 1.046
iteration : 150/500  -  train loss : 0.003 /   test loss : 1.048
iteration : 160/500  -  train loss : 0.002 /   test loss : 1.061
iteration : 170/500  -  train loss : 0.002 /   test loss : 1.056
iteration : 180/500  -  train loss : 0.003 /   test loss : 1.044
iteration : 190/500  -  train loss : 0.003 /   test loss : 1.046
iteration : 200/500  -  train loss : 0.003 /   test loss : 1.033
iteration : 210/500  -  train loss : 0.002 /   test loss : 1.041
iteration : 220/500  -  train loss : 0.002 /   test loss : 1.047
iteration : 230/500  -  train loss : 0.002 /   test loss : 1.037
iteration : 240/500  -  train loss : 0.002 /   test loss : 1.043
iteration : 250/500  -  train loss : 0.004 /   test loss : 1.058
iteration : 260/500  -  train loss : 0.004 /   test loss : 1.038
iteration : 270/500  -  train loss : 0.003 /   test loss : 1.034
iteration : 280/500  -  train loss : 0.003 /   test loss : 1.036
iteration : 290/500  -  train loss : 0.003 /   test loss : 1.025
iteration : 300/500  -  train loss : 0.002 /   test loss : 1.024
iteration : 310/500  -  train loss : 0.002 /   test loss : 1.022
iteration : 320/500  -  train loss : 0.002 /   test loss : 1.019
iteration : 330/500  -  train loss : 0.001 /   test loss : 1.037
iteration : 340/500  -  train loss : 0.002 /   test loss : 1.046
iteration : 350/500  -  train loss : 0.002 /   test loss : 1.029
iteration : 360/500  -  train loss : 0.003 /   test loss : 1.03
iteration : 370/500  -  train loss : 0.003 /   test loss : 1.035
iteration : 380/500  -  train loss : 0.002 /   test loss : 1.047
iteration : 390/500  -  train loss : 0.003 /   test loss : 1.062
iteration : 400/500  -  train loss : 0.005 /   test loss : 1.036
iteration : 410/500  -  train loss : 0.004 /   test loss : 1.06
iteration : 420/500  -  train loss : 0.002 /   test loss : 1.076
iteration : 430/500  -  train loss : 0.002 /   test loss : 1.051
iteration : 440/500  -  train loss : 0.002 /   test loss : 1.045
iteration : 450/500  -  train loss : 0.002 /   test loss : 1.042
iteration : 460/500  -  train loss : 0.002 /   test loss : 1.029
iteration : 470/500  -  train loss : 0.002 /   test loss : 1.036
iteration : 480/500  -  train loss : 0.002 /   test loss : 1.048
iteration : 490/500  -  train loss : 0.004 /   test loss : 1.066
iteration : 500/500  -  train loss : 0.003 /   test loss : 1.03

Training complete   //   Running time : 157  ------------


[Gene 5] Model 2 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 21013])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 21013])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.804 /   test loss : 0.269
iteration : 10/500  -  train loss : 0.376 /   test loss : 0.182
iteration : 20/500  -  train loss : 0.245 /   test loss : 0.244
iteration : 30/500  -  train loss : 0.164 /   test loss : 0.254
iteration : 40/500  -  train loss : 0.107 /   test loss : 0.314
iteration : 50/500  -  train loss : 0.07 /   test loss : 0.334
iteration : 60/500  -  train loss : 0.046 /   test loss : 0.343
iteration : 70/500  -  train loss : 0.032 /   test loss : 0.361
iteration : 80/500  -  train loss : 0.023 /   test loss : 0.359
iteration : 90/500  -  train loss : 0.02 /   test loss : 0.314
iteration : 100/500  -  train loss : 0.012 /   test loss : 0.339
iteration : 110/500  -  train loss : 0.01 /   test loss : 0.333
iteration : 120/500  -  train loss : 0.006 /   test loss : 0.337
iteration : 130/500  -  train loss : 0.006 /   test loss : 0.34
iteration : 140/500  -  train loss : 0.006 /   test loss : 0.333
iteration : 150/500  -  train loss : 0.006 /   test loss : 0.337
iteration : 160/500  -  train loss : 0.004 /   test loss : 0.333
iteration : 170/500  -  train loss : 0.004 /   test loss : 0.316
iteration : 180/500  -  train loss : 0.006 /   test loss : 0.299
iteration : 190/500  -  train loss : 0.004 /   test loss : 0.33
iteration : 200/500  -  train loss : 0.004 /   test loss : 0.319
iteration : 210/500  -  train loss : 0.004 /   test loss : 0.316
iteration : 220/500  -  train loss : 0.002 /   test loss : 0.312
iteration : 230/500  -  train loss : 0.002 /   test loss : 0.315
iteration : 240/500  -  train loss : 0.004 /   test loss : 0.291
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.284
iteration : 260/500  -  train loss : 0.004 /   test loss : 0.294
iteration : 270/500  -  train loss : 0.004 /   test loss : 0.285
iteration : 280/500  -  train loss : 0.003 /   test loss : 0.288
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.294
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.285
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.296
iteration : 320/500  -  train loss : 0.003 /   test loss : 0.283
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.286
iteration : 340/500  -  train loss : 0.003 /   test loss : 0.27
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.277
iteration : 360/500  -  train loss : 0.003 /   test loss : 0.275
iteration : 370/500  -  train loss : 0.003 /   test loss : 0.29
iteration : 380/500  -  train loss : 0.002 /   test loss : 0.281
iteration : 390/500  -  train loss : 0.003 /   test loss : 0.27
iteration : 400/500  -  train loss : 0.004 /   test loss : 0.251
iteration : 410/500  -  train loss : 0.003 /   test loss : 0.27
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.267
iteration : 430/500  -  train loss : 0.003 /   test loss : 0.264
iteration : 440/500  -  train loss : 0.004 /   test loss : 0.274
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.277
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.272
iteration : 470/500  -  train loss : 0.003 /   test loss : 0.287
iteration : 480/500  -  train loss : 0.003 /   test loss : 0.274
iteration : 490/500  -  train loss : 0.005 /   test loss : 0.249
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.263

Training complete   //   Running time : 157  ------------


[Gene 5] Model 2 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 21013])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 21013])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.754 /   test loss : 0.411
iteration : 10/500  -  train loss : 0.373 /   test loss : 0.345
iteration : 20/500  -  train loss : 0.25 /   test loss : 0.36
iteration : 30/500  -  train loss : 0.177 /   test loss : 0.368
iteration : 40/500  -  train loss : 0.121 /   test loss : 0.369
iteration : 50/500  -  train loss : 0.079 /   test loss : 0.39
iteration : 60/500  -  train loss : 0.056 /   test loss : 0.386
iteration : 70/500  -  train loss : 0.041 /   test loss : 0.383
iteration : 80/500  -  train loss : 0.027 /   test loss : 0.384
iteration : 90/500  -  train loss : 0.024 /   test loss : 0.387
iteration : 100/500  -  train loss : 0.013 /   test loss : 0.391
iteration : 110/500  -  train loss : 0.011 /   test loss : 0.396
iteration : 120/500  -  train loss : 0.007 /   test loss : 0.399
iteration : 130/500  -  train loss : 0.011 /   test loss : 0.384
iteration : 140/500  -  train loss : 0.006 /   test loss : 0.383
iteration : 150/500  -  train loss : 0.004 /   test loss : 0.375
iteration : 160/500  -  train loss : 0.005 /   test loss : 0.371
iteration : 170/500  -  train loss : 0.004 /   test loss : 0.355
iteration : 180/500  -  train loss : 0.005 /   test loss : 0.36
iteration : 190/500  -  train loss : 0.003 /   test loss : 0.374
iteration : 200/500  -  train loss : 0.003 /   test loss : 0.38
iteration : 210/500  -  train loss : 0.005 /   test loss : 0.375
iteration : 220/500  -  train loss : 0.003 /   test loss : 0.374
iteration : 230/500  -  train loss : 0.003 /   test loss : 0.363
iteration : 240/500  -  train loss : 0.005 /   test loss : 0.355
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.356
iteration : 260/500  -  train loss : 0.004 /   test loss : 0.347
iteration : 270/500  -  train loss : 0.004 /   test loss : 0.352
iteration : 280/500  -  train loss : 0.004 /   test loss : 0.355
iteration : 290/500  -  train loss : 0.004 /   test loss : 0.34
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.358
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.353
iteration : 320/500  -  train loss : 0.003 /   test loss : 0.349
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.356
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.345
iteration : 350/500  -  train loss : 0.003 /   test loss : 0.345
iteration : 360/500  -  train loss : 0.005 /   test loss : 0.344
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.352
iteration : 380/500  -  train loss : 0.002 /   test loss : 0.348
iteration : 390/500  -  train loss : 0.008 /   test loss : 0.345
iteration : 400/500  -  train loss : 0.006 /   test loss : 0.336
iteration : 410/500  -  train loss : 0.003 /   test loss : 0.339
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.346
iteration : 430/500  -  train loss : 0.004 /   test loss : 0.338
iteration : 440/500  -  train loss : 0.003 /   test loss : 0.339
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.35
iteration : 460/500  -  train loss : 0.003 /   test loss : 0.335
iteration : 470/500  -  train loss : 0.003 /   test loss : 0.334
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.338
iteration : 490/500  -  train loss : 0.003 /   test loss : 0.35
iteration : 500/500  -  train loss : 0.003 /   test loss : 0.35

Training complete   //   Running time : 157  ------------


[Gene 5] Model 2 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 21013])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 21013])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.794 /   test loss : 0.355
iteration : 10/500  -  train loss : 0.376 /   test loss : 0.213
iteration : 20/500  -  train loss : 0.255 /   test loss : 0.274
iteration : 30/500  -  train loss : 0.186 /   test loss : 0.224
iteration : 40/500  -  train loss : 0.123 /   test loss : 0.257
iteration : 50/500  -  train loss : 0.087 /   test loss : 0.259
iteration : 60/500  -  train loss : 0.06 /   test loss : 0.285
iteration : 70/500  -  train loss : 0.04 /   test loss : 0.283
iteration : 80/500  -  train loss : 0.027 /   test loss : 0.257
iteration : 90/500  -  train loss : 0.022 /   test loss : 0.253
iteration : 100/500  -  train loss : 0.015 /   test loss : 0.262
iteration : 110/500  -  train loss : 0.011 /   test loss : 0.262
iteration : 120/500  -  train loss : 0.008 /   test loss : 0.276
iteration : 130/500  -  train loss : 0.009 /   test loss : 0.294
iteration : 140/500  -  train loss : 0.005 /   test loss : 0.27
iteration : 150/500  -  train loss : 0.004 /   test loss : 0.265
iteration : 160/500  -  train loss : 0.005 /   test loss : 0.283
iteration : 170/500  -  train loss : 0.006 /   test loss : 0.24
iteration : 180/500  -  train loss : 0.005 /   test loss : 0.25
iteration : 190/500  -  train loss : 0.005 /   test loss : 0.268
iteration : 200/500  -  train loss : 0.006 /   test loss : 0.279
iteration : 210/500  -  train loss : 0.005 /   test loss : 0.285
iteration : 220/500  -  train loss : 0.003 /   test loss : 0.269
iteration : 230/500  -  train loss : 0.003 /   test loss : 0.264
iteration : 240/500  -  train loss : 0.004 /   test loss : 0.252
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.246
iteration : 260/500  -  train loss : 0.004 /   test loss : 0.25
iteration : 270/500  -  train loss : 0.003 /   test loss : 0.256
iteration : 280/500  -  train loss : 0.004 /   test loss : 0.256
iteration : 290/500  -  train loss : 0.003 /   test loss : 0.252
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.254
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.258
iteration : 320/500  -  train loss : 0.003 /   test loss : 0.248
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.246
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.252
iteration : 350/500  -  train loss : 0.004 /   test loss : 0.258
iteration : 360/500  -  train loss : 0.004 /   test loss : 0.259
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.256
iteration : 380/500  -  train loss : 0.002 /   test loss : 0.256
iteration : 390/500  -  train loss : 0.003 /   test loss : 0.262
iteration : 400/500  -  train loss : 0.006 /   test loss : 0.253
iteration : 410/500  -  train loss : 0.003 /   test loss : 0.243
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.252
iteration : 430/500  -  train loss : 0.003 /   test loss : 0.248
iteration : 440/500  -  train loss : 0.002 /   test loss : 0.256
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.264
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.26
iteration : 470/500  -  train loss : 0.002 /   test loss : 0.25
iteration : 480/500  -  train loss : 0.003 /   test loss : 0.24
iteration : 490/500  -  train loss : 0.003 /   test loss : 0.241
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.252

Training complete   //   Running time : 157  ------------


[Gene 5] Model 2 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([120, 21013])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 21013])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.528 /   test loss : 1.413
iteration : 10/500  -  train loss : 0.193 /   test loss : 1.21
iteration : 20/500  -  train loss : 0.118 /   test loss : 1.203
iteration : 30/500  -  train loss : 0.078 /   test loss : 1.24
iteration : 40/500  -  train loss : 0.049 /   test loss : 1.215
iteration : 50/500  -  train loss : 0.049 /   test loss : 1.321
iteration : 60/500  -  train loss : 0.022 /   test loss : 1.258
iteration : 70/500  -  train loss : 0.017 /   test loss : 1.26
iteration : 80/500  -  train loss : 0.012 /   test loss : 1.248
iteration : 90/500  -  train loss : 0.011 /   test loss : 1.272
iteration : 100/500  -  train loss : 0.015 /   test loss : 1.28
iteration : 110/500  -  train loss : 0.006 /   test loss : 1.213
iteration : 120/500  -  train loss : 0.006 /   test loss : 1.233
iteration : 130/500  -  train loss : 0.005 /   test loss : 1.229
iteration : 140/500  -  train loss : 0.004 /   test loss : 1.23
iteration : 150/500  -  train loss : 0.004 /   test loss : 1.231
iteration : 160/500  -  train loss : 0.006 /   test loss : 1.263
iteration : 170/500  -  train loss : 0.003 /   test loss : 1.244
iteration : 180/500  -  train loss : 0.002 /   test loss : 1.239
iteration : 190/500  -  train loss : 0.002 /   test loss : 1.22
iteration : 200/500  -  train loss : 0.003 /   test loss : 1.209
iteration : 210/500  -  train loss : 0.002 /   test loss : 1.245
iteration : 220/500  -  train loss : 0.003 /   test loss : 1.226
iteration : 230/500  -  train loss : 0.003 /   test loss : 1.231
iteration : 240/500  -  train loss : 0.005 /   test loss : 1.261
iteration : 250/500  -  train loss : 0.002 /   test loss : 1.242
iteration : 260/500  -  train loss : 0.003 /   test loss : 1.238
iteration : 270/500  -  train loss : 0.003 /   test loss : 1.232
iteration : 280/500  -  train loss : 0.002 /   test loss : 1.243
iteration : 290/500  -  train loss : 0.004 /   test loss : 1.225
iteration : 300/500  -  train loss : 0.003 /   test loss : 1.237
iteration : 310/500  -  train loss : 0.003 /   test loss : 1.24
iteration : 320/500  -  train loss : 0.003 /   test loss : 1.227
iteration : 330/500  -  train loss : 0.002 /   test loss : 1.233
iteration : 340/500  -  train loss : 0.002 /   test loss : 1.242
iteration : 350/500  -  train loss : 0.001 /   test loss : 1.232
iteration : 360/500  -  train loss : 0.003 /   test loss : 1.218
iteration : 370/500  -  train loss : 0.002 /   test loss : 1.221
iteration : 380/500  -  train loss : 0.003 /   test loss : 1.231
iteration : 390/500  -  train loss : 0.004 /   test loss : 1.27
iteration : 400/500  -  train loss : 0.002 /   test loss : 1.232
iteration : 410/500  -  train loss : 0.003 /   test loss : 1.259
iteration : 420/500  -  train loss : 0.002 /   test loss : 1.24
iteration : 430/500  -  train loss : 0.002 /   test loss : 1.22
iteration : 440/500  -  train loss : 0.002 /   test loss : 1.235
iteration : 450/500  -  train loss : 0.001 /   test loss : 1.238
iteration : 460/500  -  train loss : 0.002 /   test loss : 1.221
iteration : 470/500  -  train loss : 0.002 /   test loss : 1.21
iteration : 480/500  -  train loss : 0.001 /   test loss : 1.216
iteration : 490/500  -  train loss : 0.002 /   test loss : 1.224
iteration : 500/500  -  train loss : 0.002 /   test loss : 1.218

Training complete   //   Running time : 155  ------------


[Gene 6] Model 2 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 27389])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 27389])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 1.023 /   test loss : 1.808
iteration : 10/500  -  train loss : 0.25 /   test loss : 1.283
iteration : 20/500  -  train loss : 0.091 /   test loss : 1.112
iteration : 30/500  -  train loss : 0.043 /   test loss : 1.112
iteration : 40/500  -  train loss : 0.024 /   test loss : 1.08
iteration : 50/500  -  train loss : 0.024 /   test loss : 1.083
iteration : 60/500  -  train loss : 0.012 /   test loss : 1.085
iteration : 70/500  -  train loss : 0.009 /   test loss : 1.073
iteration : 80/500  -  train loss : 0.006 /   test loss : 1.071
iteration : 90/500  -  train loss : 0.007 /   test loss : 1.076
iteration : 100/500  -  train loss : 0.006 /   test loss : 1.058
iteration : 110/500  -  train loss : 0.004 /   test loss : 1.093
iteration : 120/500  -  train loss : 0.005 /   test loss : 1.101
iteration : 130/500  -  train loss : 0.012 /   test loss : 1.07
iteration : 140/500  -  train loss : 0.005 /   test loss : 1.11
iteration : 150/500  -  train loss : 0.005 /   test loss : 1.086
iteration : 160/500  -  train loss : 0.003 /   test loss : 1.076
iteration : 170/500  -  train loss : 0.003 /   test loss : 1.066
iteration : 180/500  -  train loss : 0.007 /   test loss : 1.082
iteration : 190/500  -  train loss : 0.003 /   test loss : 1.09
iteration : 200/500  -  train loss : 0.003 /   test loss : 1.098
iteration : 210/500  -  train loss : 0.003 /   test loss : 1.093
iteration : 220/500  -  train loss : 0.003 /   test loss : 1.09
iteration : 230/500  -  train loss : 0.003 /   test loss : 1.094
iteration : 240/500  -  train loss : 0.004 /   test loss : 1.098
iteration : 250/500  -  train loss : 0.006 /   test loss : 1.12
iteration : 260/500  -  train loss : 0.002 /   test loss : 1.11
iteration : 270/500  -  train loss : 0.003 /   test loss : 1.127
iteration : 280/500  -  train loss : 0.004 /   test loss : 1.11
iteration : 290/500  -  train loss : 0.002 /   test loss : 1.101
iteration : 300/500  -  train loss : 0.004 /   test loss : 1.135
iteration : 310/500  -  train loss : 0.003 /   test loss : 1.122
iteration : 320/500  -  train loss : 0.002 /   test loss : 1.115
iteration : 330/500  -  train loss : 0.003 /   test loss : 1.121
iteration : 340/500  -  train loss : 0.003 /   test loss : 1.113
iteration : 350/500  -  train loss : 0.002 /   test loss : 1.118
iteration : 360/500  -  train loss : 0.002 /   test loss : 1.13
iteration : 370/500  -  train loss : 0.003 /   test loss : 1.113
iteration : 380/500  -  train loss : 0.005 /   test loss : 1.08
iteration : 390/500  -  train loss : 0.006 /   test loss : 1.168
iteration : 400/500  -  train loss : 0.003 /   test loss : 1.103
iteration : 410/500  -  train loss : 0.004 /   test loss : 1.162
iteration : 420/500  -  train loss : 0.003 /   test loss : 1.147
iteration : 430/500  -  train loss : 0.003 /   test loss : 1.156
iteration : 440/500  -  train loss : 0.005 /   test loss : 1.098
iteration : 450/500  -  train loss : 0.004 /   test loss : 1.154
iteration : 460/500  -  train loss : 0.003 /   test loss : 1.135
iteration : 470/500  -  train loss : 0.003 /   test loss : 1.161
iteration : 480/500  -  train loss : 0.003 /   test loss : 1.153
iteration : 490/500  -  train loss : 0.002 /   test loss : 1.125
iteration : 500/500  -  train loss : 0.005 /   test loss : 1.153

Training complete   //   Running time : 207  ------------


[Gene 6] Model 2 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 27389])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 27389])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 1.26 /   test loss : 0.652
iteration : 10/500  -  train loss : 0.302 /   test loss : 0.432
iteration : 20/500  -  train loss : 0.097 /   test loss : 0.404
iteration : 30/500  -  train loss : 0.053 /   test loss : 0.356
iteration : 40/500  -  train loss : 0.029 /   test loss : 0.424
iteration : 50/500  -  train loss : 0.023 /   test loss : 0.4
iteration : 60/500  -  train loss : 0.013 /   test loss : 0.379
iteration : 70/500  -  train loss : 0.01 /   test loss : 0.382
iteration : 80/500  -  train loss : 0.008 /   test loss : 0.392
iteration : 90/500  -  train loss : 0.007 /   test loss : 0.392
iteration : 100/500  -  train loss : 0.007 /   test loss : 0.393
iteration : 110/500  -  train loss : 0.007 /   test loss : 0.379
iteration : 120/500  -  train loss : 0.006 /   test loss : 0.375
iteration : 130/500  -  train loss : 0.005 /   test loss : 0.402
iteration : 140/500  -  train loss : 0.007 /   test loss : 0.402
iteration : 150/500  -  train loss : 0.007 /   test loss : 0.405
iteration : 160/500  -  train loss : 0.004 /   test loss : 0.387
iteration : 170/500  -  train loss : 0.005 /   test loss : 0.396
iteration : 180/500  -  train loss : 0.004 /   test loss : 0.391
iteration : 190/500  -  train loss : 0.005 /   test loss : 0.402
iteration : 200/500  -  train loss : 0.003 /   test loss : 0.389
iteration : 210/500  -  train loss : 0.003 /   test loss : 0.39
iteration : 220/500  -  train loss : 0.003 /   test loss : 0.38
iteration : 230/500  -  train loss : 0.004 /   test loss : 0.386
iteration : 240/500  -  train loss : 0.006 /   test loss : 0.39
iteration : 250/500  -  train loss : 0.004 /   test loss : 0.372
iteration : 260/500  -  train loss : 0.003 /   test loss : 0.381
iteration : 270/500  -  train loss : 0.004 /   test loss : 0.378
iteration : 280/500  -  train loss : 0.002 /   test loss : 0.38
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.374
iteration : 300/500  -  train loss : 0.003 /   test loss : 0.383
iteration : 310/500  -  train loss : 0.005 /   test loss : 0.388
iteration : 320/500  -  train loss : 0.005 /   test loss : 0.38
iteration : 330/500  -  train loss : 0.004 /   test loss : 0.377
iteration : 340/500  -  train loss : 0.005 /   test loss : 0.385
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.371
iteration : 360/500  -  train loss : 0.002 /   test loss : 0.372
iteration : 370/500  -  train loss : 0.003 /   test loss : 0.37
iteration : 380/500  -  train loss : 0.004 /   test loss : 0.376
iteration : 390/500  -  train loss : 0.004 /   test loss : 0.377
iteration : 400/500  -  train loss : 0.006 /   test loss : 0.402
iteration : 410/500  -  train loss : 0.003 /   test loss : 0.396
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.384
iteration : 430/500  -  train loss : 0.007 /   test loss : 0.399
iteration : 440/500  -  train loss : 0.004 /   test loss : 0.38
iteration : 450/500  -  train loss : 0.006 /   test loss : 0.407
iteration : 460/500  -  train loss : 0.005 /   test loss : 0.384
iteration : 470/500  -  train loss : 0.004 /   test loss : 0.39
iteration : 480/500  -  train loss : 0.003 /   test loss : 0.384
iteration : 490/500  -  train loss : 0.003 /   test loss : 0.384
iteration : 500/500  -  train loss : 0.003 /   test loss : 0.394

Training complete   //   Running time : 201  ------------


[Gene 6] Model 2 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 27389])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 27389])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 1.043 /   test loss : 1.815
iteration : 10/500  -  train loss : 0.253 /   test loss : 1.265
iteration : 20/500  -  train loss : 0.084 /   test loss : 1.161
iteration : 30/500  -  train loss : 0.038 /   test loss : 1.092
iteration : 40/500  -  train loss : 0.021 /   test loss : 1.101
iteration : 50/500  -  train loss : 0.02 /   test loss : 1.085
iteration : 60/500  -  train loss : 0.011 /   test loss : 1.105
iteration : 70/500  -  train loss : 0.009 /   test loss : 1.11
iteration : 80/500  -  train loss : 0.009 /   test loss : 1.119
iteration : 90/500  -  train loss : 0.006 /   test loss : 1.109
iteration : 100/500  -  train loss : 0.003 /   test loss : 1.103
iteration : 110/500  -  train loss : 0.006 /   test loss : 1.114
iteration : 120/500  -  train loss : 0.006 /   test loss : 1.121
iteration : 130/500  -  train loss : 0.004 /   test loss : 1.114
iteration : 140/500  -  train loss : 0.007 /   test loss : 1.107
iteration : 150/500  -  train loss : 0.003 /   test loss : 1.1
iteration : 160/500  -  train loss : 0.002 /   test loss : 1.084
iteration : 170/500  -  train loss : 0.008 /   test loss : 1.096
iteration : 180/500  -  train loss : 0.003 /   test loss : 1.117
iteration : 190/500  -  train loss : 0.004 /   test loss : 1.122
iteration : 200/500  -  train loss : 0.003 /   test loss : 1.094
iteration : 210/500  -  train loss : 0.004 /   test loss : 1.118
iteration : 220/500  -  train loss : 0.003 /   test loss : 1.106
iteration : 230/500  -  train loss : 0.002 /   test loss : 1.117
iteration : 240/500  -  train loss : 0.004 /   test loss : 1.132
iteration : 250/500  -  train loss : 0.004 /   test loss : 1.117
iteration : 260/500  -  train loss : 0.002 /   test loss : 1.106
iteration : 270/500  -  train loss : 0.005 /   test loss : 1.139
iteration : 280/500  -  train loss : 0.003 /   test loss : 1.117
iteration : 290/500  -  train loss : 0.003 /   test loss : 1.114
iteration : 300/500  -  train loss : 0.003 /   test loss : 1.121
iteration : 310/500  -  train loss : 0.007 /   test loss : 1.132
iteration : 320/500  -  train loss : 0.002 /   test loss : 1.113
iteration : 330/500  -  train loss : 0.004 /   test loss : 1.113
iteration : 340/500  -  train loss : 0.002 /   test loss : 1.108
iteration : 350/500  -  train loss : 0.005 /   test loss : 1.138
iteration : 360/500  -  train loss : 0.006 /   test loss : 1.145
iteration : 370/500  -  train loss : 0.004 /   test loss : 1.129
iteration : 380/500  -  train loss : 0.002 /   test loss : 1.112
iteration : 390/500  -  train loss : 0.003 /   test loss : 1.138
iteration : 400/500  -  train loss : 0.005 /   test loss : 1.14
iteration : 410/500  -  train loss : 0.003 /   test loss : 1.119
iteration : 420/500  -  train loss : 0.002 /   test loss : 1.123
iteration : 430/500  -  train loss : 0.004 /   test loss : 1.15
iteration : 440/500  -  train loss : 0.002 /   test loss : 1.104
iteration : 450/500  -  train loss : 0.007 /   test loss : 1.171
iteration : 460/500  -  train loss : 0.002 /   test loss : 1.131
iteration : 470/500  -  train loss : 0.004 /   test loss : 1.145
iteration : 480/500  -  train loss : 0.003 /   test loss : 1.144
iteration : 490/500  -  train loss : 0.002 /   test loss : 1.116
iteration : 500/500  -  train loss : 0.008 /   test loss : 1.155

Training complete   //   Running time : 200  ------------


[Gene 6] Model 2 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 27389])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 27389])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 1.057 /   test loss : 1.633
iteration : 10/500  -  train loss : 0.236 /   test loss : 1.239
iteration : 20/500  -  train loss : 0.089 /   test loss : 1.049
iteration : 30/500  -  train loss : 0.042 /   test loss : 1.099
iteration : 40/500  -  train loss : 0.024 /   test loss : 1.12
iteration : 50/500  -  train loss : 0.013 /   test loss : 1.099
iteration : 60/500  -  train loss : 0.01 /   test loss : 1.116
iteration : 70/500  -  train loss : 0.008 /   test loss : 1.136
iteration : 80/500  -  train loss : 0.007 /   test loss : 1.142
iteration : 90/500  -  train loss : 0.009 /   test loss : 1.15
iteration : 100/500  -  train loss : 0.006 /   test loss : 1.157
iteration : 110/500  -  train loss : 0.005 /   test loss : 1.184
iteration : 120/500  -  train loss : 0.006 /   test loss : 1.21
iteration : 130/500  -  train loss : 0.003 /   test loss : 1.188
iteration : 140/500  -  train loss : 0.004 /   test loss : 1.184
iteration : 150/500  -  train loss : 0.005 /   test loss : 1.191
iteration : 160/500  -  train loss : 0.003 /   test loss : 1.196
iteration : 170/500  -  train loss : 0.004 /   test loss : 1.232
iteration : 180/500  -  train loss : 0.002 /   test loss : 1.228
iteration : 190/500  -  train loss : 0.005 /   test loss : 1.246
iteration : 200/500  -  train loss : 0.003 /   test loss : 1.203
iteration : 210/500  -  train loss : 0.003 /   test loss : 1.226
iteration : 220/500  -  train loss : 0.001 /   test loss : 1.239
iteration : 230/500  -  train loss : 0.003 /   test loss : 1.261
iteration : 240/500  -  train loss : 0.008 /   test loss : 1.283
iteration : 250/500  -  train loss : 0.003 /   test loss : 1.261
iteration : 260/500  -  train loss : 0.005 /   test loss : 1.268
iteration : 270/500  -  train loss : 0.003 /   test loss : 1.264
iteration : 280/500  -  train loss : 0.004 /   test loss : 1.3
iteration : 290/500  -  train loss : 0.002 /   test loss : 1.273
iteration : 300/500  -  train loss : 0.003 /   test loss : 1.266
iteration : 310/500  -  train loss : 0.006 /   test loss : 1.277
iteration : 320/500  -  train loss : 0.004 /   test loss : 1.268
iteration : 330/500  -  train loss : 0.003 /   test loss : 1.279
iteration : 340/500  -  train loss : 0.002 /   test loss : 1.272
iteration : 350/500  -  train loss : 0.002 /   test loss : 1.288
iteration : 360/500  -  train loss : 0.003 /   test loss : 1.288
iteration : 370/500  -  train loss : 0.004 /   test loss : 1.294
iteration : 380/500  -  train loss : 0.002 /   test loss : 1.278
iteration : 390/500  -  train loss : 0.004 /   test loss : 1.292
iteration : 400/500  -  train loss : 0.002 /   test loss : 1.269
iteration : 410/500  -  train loss : 0.002 /   test loss : 1.286
iteration : 420/500  -  train loss : 0.002 /   test loss : 1.31
iteration : 430/500  -  train loss : 0.002 /   test loss : 1.311
iteration : 440/500  -  train loss : 0.001 /   test loss : 1.304
iteration : 450/500  -  train loss : 0.005 /   test loss : 1.329
iteration : 460/500  -  train loss : 0.002 /   test loss : 1.32
iteration : 470/500  -  train loss : 0.004 /   test loss : 1.336
iteration : 480/500  -  train loss : 0.002 /   test loss : 1.33
iteration : 490/500  -  train loss : 0.001 /   test loss : 1.32
iteration : 500/500  -  train loss : 0.003 /   test loss : 1.323

Training complete   //   Running time : 200  ------------


[Gene 6] Model 2 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([120, 27389])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 27389])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 1.351 /   test loss : 0.444
iteration : 10/500  -  train loss : 0.313 /   test loss : 0.381
iteration : 20/500  -  train loss : 0.108 /   test loss : 0.404
iteration : 30/500  -  train loss : 0.053 /   test loss : 0.337
iteration : 40/500  -  train loss : 0.031 /   test loss : 0.39
iteration : 50/500  -  train loss : 0.04 /   test loss : 0.407
iteration : 60/500  -  train loss : 0.015 /   test loss : 0.364
iteration : 70/500  -  train loss : 0.014 /   test loss : 0.328
iteration : 80/500  -  train loss : 0.01 /   test loss : 0.343
iteration : 90/500  -  train loss : 0.008 /   test loss : 0.347
iteration : 100/500  -  train loss : 0.009 /   test loss : 0.356
iteration : 110/500  -  train loss : 0.008 /   test loss : 0.34
iteration : 120/500  -  train loss : 0.01 /   test loss : 0.307
iteration : 130/500  -  train loss : 0.009 /   test loss : 0.361
iteration : 140/500  -  train loss : 0.003 /   test loss : 0.32
iteration : 150/500  -  train loss : 0.008 /   test loss : 0.349
iteration : 160/500  -  train loss : 0.007 /   test loss : 0.347
iteration : 170/500  -  train loss : 0.003 /   test loss : 0.332
iteration : 180/500  -  train loss : 0.004 /   test loss : 0.335
iteration : 190/500  -  train loss : 0.004 /   test loss : 0.34
iteration : 200/500  -  train loss : 0.005 /   test loss : 0.336
iteration : 210/500  -  train loss : 0.006 /   test loss : 0.322
iteration : 220/500  -  train loss : 0.003 /   test loss : 0.321
iteration : 230/500  -  train loss : 0.004 /   test loss : 0.311
iteration : 240/500  -  train loss : 0.004 /   test loss : 0.302
iteration : 250/500  -  train loss : 0.005 /   test loss : 0.302
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.328
iteration : 270/500  -  train loss : 0.005 /   test loss : 0.326
iteration : 280/500  -  train loss : 0.003 /   test loss : 0.313
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.313
iteration : 300/500  -  train loss : 0.004 /   test loss : 0.31
iteration : 310/500  -  train loss : 0.005 /   test loss : 0.294
iteration : 320/500  -  train loss : 0.004 /   test loss : 0.312
iteration : 330/500  -  train loss : 0.005 /   test loss : 0.297
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.31
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.304
iteration : 360/500  -  train loss : 0.006 /   test loss : 0.32
iteration : 370/500  -  train loss : 0.003 /   test loss : 0.32
iteration : 380/500  -  train loss : 0.004 /   test loss : 0.304
iteration : 390/500  -  train loss : 0.004 /   test loss : 0.304
iteration : 400/500  -  train loss : 0.005 /   test loss : 0.299
iteration : 410/500  -  train loss : 0.004 /   test loss : 0.298
iteration : 420/500  -  train loss : 0.003 /   test loss : 0.288
iteration : 430/500  -  train loss : 0.003 /   test loss : 0.306
iteration : 440/500  -  train loss : 0.003 /   test loss : 0.302
iteration : 450/500  -  train loss : 0.007 /   test loss : 0.282
iteration : 460/500  -  train loss : 0.004 /   test loss : 0.299
iteration : 470/500  -  train loss : 0.003 /   test loss : 0.304
iteration : 480/500  -  train loss : 0.003 /   test loss : 0.305
iteration : 490/500  -  train loss : 0.003 /   test loss : 0.309
iteration : 500/500  -  train loss : 0.005 /   test loss : 0.299

Training complete   //   Running time : 197  ------------


[Gene 7] Model 2 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 17331])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 17331])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.673 /   test loss : 0.566
iteration : 10/500  -  train loss : 0.148 /   test loss : 0.482
iteration : 20/500  -  train loss : 0.051 /   test loss : 0.476
iteration : 30/500  -  train loss : 0.022 /   test loss : 0.446
iteration : 40/500  -  train loss : 0.013 /   test loss : 0.435
iteration : 50/500  -  train loss : 0.009 /   test loss : 0.43
iteration : 60/500  -  train loss : 0.012 /   test loss : 0.437
iteration : 70/500  -  train loss : 0.007 /   test loss : 0.422
iteration : 80/500  -  train loss : 0.004 /   test loss : 0.427
iteration : 90/500  -  train loss : 0.005 /   test loss : 0.433
iteration : 100/500  -  train loss : 0.003 /   test loss : 0.424
iteration : 110/500  -  train loss : 0.003 /   test loss : 0.426
iteration : 120/500  -  train loss : 0.004 /   test loss : 0.433
iteration : 130/500  -  train loss : 0.004 /   test loss : 0.423
iteration : 140/500  -  train loss : 0.005 /   test loss : 0.435
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.438
iteration : 160/500  -  train loss : 0.003 /   test loss : 0.432
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.429
iteration : 180/500  -  train loss : 0.004 /   test loss : 0.431
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.43
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.437
iteration : 210/500  -  train loss : 0.004 /   test loss : 0.426
iteration : 220/500  -  train loss : 0.002 /   test loss : 0.432
iteration : 230/500  -  train loss : 0.002 /   test loss : 0.428
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.427
iteration : 250/500  -  train loss : 0.002 /   test loss : 0.432
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.427
iteration : 270/500  -  train loss : 0.003 /   test loss : 0.425
iteration : 280/500  -  train loss : 0.002 /   test loss : 0.418
iteration : 290/500  -  train loss : 0.004 /   test loss : 0.423
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.429
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.429
iteration : 320/500  -  train loss : 0.002 /   test loss : 0.424
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.428
iteration : 340/500  -  train loss : 0.003 /   test loss : 0.43
iteration : 350/500  -  train loss : 0.003 /   test loss : 0.428
iteration : 360/500  -  train loss : 0.002 /   test loss : 0.435
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.431
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.43
iteration : 390/500  -  train loss : 0.003 /   test loss : 0.423
iteration : 400/500  -  train loss : 0.005 /   test loss : 0.436
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.431
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.427
iteration : 430/500  -  train loss : 0.002 /   test loss : 0.431
iteration : 440/500  -  train loss : 0.003 /   test loss : 0.429
iteration : 450/500  -  train loss : 0.003 /   test loss : 0.427
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.427
iteration : 470/500  -  train loss : 0.002 /   test loss : 0.427
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.423
iteration : 490/500  -  train loss : 0.002 /   test loss : 0.421
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.423

Training complete   //   Running time : 131  ------------


[Gene 7] Model 2 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 17331])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 17331])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.68 /   test loss : 0.362
iteration : 10/500  -  train loss : 0.132 /   test loss : 0.453
iteration : 20/500  -  train loss : 0.038 /   test loss : 0.441
iteration : 30/500  -  train loss : 0.015 /   test loss : 0.444
iteration : 40/500  -  train loss : 0.012 /   test loss : 0.444
iteration : 50/500  -  train loss : 0.009 /   test loss : 0.443
iteration : 60/500  -  train loss : 0.011 /   test loss : 0.441
iteration : 70/500  -  train loss : 0.006 /   test loss : 0.47
iteration : 80/500  -  train loss : 0.005 /   test loss : 0.451
iteration : 90/500  -  train loss : 0.005 /   test loss : 0.438
iteration : 100/500  -  train loss : 0.005 /   test loss : 0.446
iteration : 110/500  -  train loss : 0.003 /   test loss : 0.441
iteration : 120/500  -  train loss : 0.003 /   test loss : 0.446
iteration : 130/500  -  train loss : 0.004 /   test loss : 0.442
iteration : 140/500  -  train loss : 0.005 /   test loss : 0.43
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.448
iteration : 160/500  -  train loss : 0.003 /   test loss : 0.436
iteration : 170/500  -  train loss : 0.003 /   test loss : 0.447
iteration : 180/500  -  train loss : 0.004 /   test loss : 0.432
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.434
iteration : 200/500  -  train loss : 0.004 /   test loss : 0.432
iteration : 210/500  -  train loss : 0.004 /   test loss : 0.425
iteration : 220/500  -  train loss : 0.003 /   test loss : 0.429
iteration : 230/500  -  train loss : 0.002 /   test loss : 0.429
iteration : 240/500  -  train loss : 0.003 /   test loss : 0.429
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.436
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.433
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.426
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.428
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.429
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.424
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.429
iteration : 320/500  -  train loss : 0.003 /   test loss : 0.426
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.43
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.427
iteration : 350/500  -  train loss : 0.003 /   test loss : 0.424
iteration : 360/500  -  train loss : 0.002 /   test loss : 0.429
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.435
iteration : 380/500  -  train loss : 0.002 /   test loss : 0.427
iteration : 390/500  -  train loss : 0.002 /   test loss : 0.426
iteration : 400/500  -  train loss : 0.003 /   test loss : 0.424
iteration : 410/500  -  train loss : 0.003 /   test loss : 0.422
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.425
iteration : 430/500  -  train loss : 0.002 /   test loss : 0.432
iteration : 440/500  -  train loss : 0.002 /   test loss : 0.421
iteration : 450/500  -  train loss : 0.003 /   test loss : 0.423
iteration : 460/500  -  train loss : 0.003 /   test loss : 0.419
iteration : 470/500  -  train loss : 0.002 /   test loss : 0.437
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.43
iteration : 490/500  -  train loss : 0.002 /   test loss : 0.422
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.431

Training complete   //   Running time : 127  ------------


[Gene 7] Model 2 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 17331])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 17331])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.693 /   test loss : 0.267
iteration : 10/500  -  train loss : 0.155 /   test loss : 0.27
iteration : 20/500  -  train loss : 0.053 /   test loss : 0.207
iteration : 30/500  -  train loss : 0.023 /   test loss : 0.216
iteration : 40/500  -  train loss : 0.018 /   test loss : 0.255
iteration : 50/500  -  train loss : 0.013 /   test loss : 0.207
iteration : 60/500  -  train loss : 0.01 /   test loss : 0.214
iteration : 70/500  -  train loss : 0.007 /   test loss : 0.256
iteration : 80/500  -  train loss : 0.004 /   test loss : 0.232
iteration : 90/500  -  train loss : 0.004 /   test loss : 0.239
iteration : 100/500  -  train loss : 0.005 /   test loss : 0.237
iteration : 110/500  -  train loss : 0.004 /   test loss : 0.213
iteration : 120/500  -  train loss : 0.004 /   test loss : 0.209
iteration : 130/500  -  train loss : 0.003 /   test loss : 0.216
iteration : 140/500  -  train loss : 0.006 /   test loss : 0.204
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.214
iteration : 160/500  -  train loss : 0.004 /   test loss : 0.213
iteration : 170/500  -  train loss : 0.003 /   test loss : 0.219
iteration : 180/500  -  train loss : 0.004 /   test loss : 0.204
iteration : 190/500  -  train loss : 0.004 /   test loss : 0.207
iteration : 200/500  -  train loss : 0.003 /   test loss : 0.193
iteration : 210/500  -  train loss : 0.003 /   test loss : 0.214
iteration : 220/500  -  train loss : 0.003 /   test loss : 0.214
iteration : 230/500  -  train loss : 0.003 /   test loss : 0.216
iteration : 240/500  -  train loss : 0.003 /   test loss : 0.194
iteration : 250/500  -  train loss : 0.002 /   test loss : 0.2
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.199
iteration : 270/500  -  train loss : 0.003 /   test loss : 0.196
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.204
iteration : 290/500  -  train loss : 0.003 /   test loss : 0.207
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.198
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.204
iteration : 320/500  -  train loss : 0.003 /   test loss : 0.214
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.206
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.195
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.194
iteration : 360/500  -  train loss : 0.003 /   test loss : 0.191
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.196
iteration : 380/500  -  train loss : 0.003 /   test loss : 0.2
iteration : 390/500  -  train loss : 0.002 /   test loss : 0.201
iteration : 400/500  -  train loss : 0.003 /   test loss : 0.2
iteration : 410/500  -  train loss : 0.002 /   test loss : 0.191
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.197
iteration : 430/500  -  train loss : 0.002 /   test loss : 0.188
iteration : 440/500  -  train loss : 0.004 /   test loss : 0.205
iteration : 450/500  -  train loss : 0.003 /   test loss : 0.192
iteration : 460/500  -  train loss : 0.004 /   test loss : 0.19
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.19
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.197
iteration : 490/500  -  train loss : 0.004 /   test loss : 0.193
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.2

Training complete   //   Running time : 128  ------------


[Gene 7] Model 2 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 17331])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 17331])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.491 /   test loss : 1.662
iteration : 10/500  -  train loss : 0.123 /   test loss : 1.071
iteration : 20/500  -  train loss : 0.044 /   test loss : 1.157
iteration : 30/500  -  train loss : 0.021 /   test loss : 1.179
iteration : 40/500  -  train loss : 0.013 /   test loss : 1.143
iteration : 50/500  -  train loss : 0.009 /   test loss : 1.194
iteration : 60/500  -  train loss : 0.008 /   test loss : 1.179
iteration : 70/500  -  train loss : 0.005 /   test loss : 1.19
iteration : 80/500  -  train loss : 0.004 /   test loss : 1.157
iteration : 90/500  -  train loss : 0.006 /   test loss : 1.158
iteration : 100/500  -  train loss : 0.003 /   test loss : 1.134
iteration : 110/500  -  train loss : 0.003 /   test loss : 1.161
iteration : 120/500  -  train loss : 0.003 /   test loss : 1.179
iteration : 130/500  -  train loss : 0.003 /   test loss : 1.21
iteration : 140/500  -  train loss : 0.002 /   test loss : 1.202
iteration : 150/500  -  train loss : 0.002 /   test loss : 1.176
iteration : 160/500  -  train loss : 0.003 /   test loss : 1.203
iteration : 170/500  -  train loss : 0.002 /   test loss : 1.171
iteration : 180/500  -  train loss : 0.002 /   test loss : 1.181
iteration : 190/500  -  train loss : 0.002 /   test loss : 1.198
iteration : 200/500  -  train loss : 0.003 /   test loss : 1.234
iteration : 210/500  -  train loss : 0.002 /   test loss : 1.213
iteration : 220/500  -  train loss : 0.001 /   test loss : 1.206
iteration : 230/500  -  train loss : 0.001 /   test loss : 1.187
iteration : 240/500  -  train loss : 0.002 /   test loss : 1.183
iteration : 250/500  -  train loss : 0.001 /   test loss : 1.197
iteration : 260/500  -  train loss : 0.002 /   test loss : 1.197
iteration : 270/500  -  train loss : 0.001 /   test loss : 1.194
iteration : 280/500  -  train loss : 0.001 /   test loss : 1.189
iteration : 290/500  -  train loss : 0.002 /   test loss : 1.179
iteration : 300/500  -  train loss : 0.002 /   test loss : 1.182
iteration : 310/500  -  train loss : 0.001 /   test loss : 1.195
iteration : 320/500  -  train loss : 0.001 /   test loss : 1.188
iteration : 330/500  -  train loss : 0.001 /   test loss : 1.203
iteration : 340/500  -  train loss : 0.002 /   test loss : 1.214
iteration : 350/500  -  train loss : 0.002 /   test loss : 1.223
iteration : 360/500  -  train loss : 0.003 /   test loss : 1.223
iteration : 370/500  -  train loss : 0.001 /   test loss : 1.214
iteration : 380/500  -  train loss : 0.002 /   test loss : 1.203
iteration : 390/500  -  train loss : 0.003 /   test loss : 1.218
iteration : 400/500  -  train loss : 0.001 /   test loss : 1.202
iteration : 410/500  -  train loss : 0.002 /   test loss : 1.208
iteration : 420/500  -  train loss : 0.001 /   test loss : 1.205
iteration : 430/500  -  train loss : 0.001 /   test loss : 1.194
iteration : 440/500  -  train loss : 0.001 /   test loss : 1.204
iteration : 450/500  -  train loss : 0.001 /   test loss : 1.206
iteration : 460/500  -  train loss : 0.002 /   test loss : 1.206
iteration : 470/500  -  train loss : 0.001 /   test loss : 1.191
iteration : 480/500  -  train loss : 0.001 /   test loss : 1.197
iteration : 490/500  -  train loss : 0.001 /   test loss : 1.208
iteration : 500/500  -  train loss : 0.001 /   test loss : 1.185

Training complete   //   Running time : 128  ------------


[Gene 7] Model 2 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([120, 17331])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 17331])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.588 /   test loss : 0.796
iteration : 10/500  -  train loss : 0.139 /   test loss : 0.532
iteration : 20/500  -  train loss : 0.042 /   test loss : 0.502
iteration : 30/500  -  train loss : 0.019 /   test loss : 0.5
iteration : 40/500  -  train loss : 0.01 /   test loss : 0.479
iteration : 50/500  -  train loss : 0.011 /   test loss : 0.489
iteration : 60/500  -  train loss : 0.007 /   test loss : 0.488
iteration : 70/500  -  train loss : 0.007 /   test loss : 0.488
iteration : 80/500  -  train loss : 0.008 /   test loss : 0.499
iteration : 90/500  -  train loss : 0.008 /   test loss : 0.488
iteration : 100/500  -  train loss : 0.004 /   test loss : 0.487
iteration : 110/500  -  train loss : 0.004 /   test loss : 0.5
iteration : 120/500  -  train loss : 0.003 /   test loss : 0.498
iteration : 130/500  -  train loss : 0.004 /   test loss : 0.498
iteration : 140/500  -  train loss : 0.003 /   test loss : 0.504
iteration : 150/500  -  train loss : 0.004 /   test loss : 0.508
iteration : 160/500  -  train loss : 0.003 /   test loss : 0.515
iteration : 170/500  -  train loss : 0.003 /   test loss : 0.5
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.503
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.507
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.508
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.505
iteration : 220/500  -  train loss : 0.002 /   test loss : 0.512
iteration : 230/500  -  train loss : 0.003 /   test loss : 0.512
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.516
iteration : 250/500  -  train loss : 0.004 /   test loss : 0.523
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.514
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.511
iteration : 280/500  -  train loss : 0.002 /   test loss : 0.512
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.522
iteration : 300/500  -  train loss : 0.003 /   test loss : 0.522
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.514
iteration : 320/500  -  train loss : 0.004 /   test loss : 0.523
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.516
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.521
iteration : 350/500  -  train loss : 0.003 /   test loss : 0.515
iteration : 360/500  -  train loss : 0.003 /   test loss : 0.528
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.53
iteration : 380/500  -  train loss : 0.002 /   test loss : 0.524
iteration : 390/500  -  train loss : 0.002 /   test loss : 0.531
iteration : 400/500  -  train loss : 0.002 /   test loss : 0.527
iteration : 410/500  -  train loss : 0.003 /   test loss : 0.547
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.521
iteration : 430/500  -  train loss : 0.002 /   test loss : 0.524
iteration : 440/500  -  train loss : 0.002 /   test loss : 0.528
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.528
iteration : 460/500  -  train loss : 0.003 /   test loss : 0.536
iteration : 470/500  -  train loss : 0.002 /   test loss : 0.538
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.532
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.53
iteration : 500/500  -  train loss : 0.003 /   test loss : 0.528

Training complete   //   Running time : 127  ------------


[Gene 8] Model 2 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 22963])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22963])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.253 /   test loss : 0.299
iteration : 10/500  -  train loss : 0.041 /   test loss : 0.209
iteration : 20/500  -  train loss : 0.023 /   test loss : 0.239
iteration : 30/500  -  train loss : 0.011 /   test loss : 0.217
iteration : 40/500  -  train loss : 0.017 /   test loss : 0.243
iteration : 50/500  -  train loss : 0.004 /   test loss : 0.222
iteration : 60/500  -  train loss : 0.005 /   test loss : 0.221
iteration : 70/500  -  train loss : 0.004 /   test loss : 0.219
iteration : 80/500  -  train loss : 0.003 /   test loss : 0.22
iteration : 90/500  -  train loss : 0.004 /   test loss : 0.22
iteration : 100/500  -  train loss : 0.003 /   test loss : 0.221
iteration : 110/500  -  train loss : 0.003 /   test loss : 0.219
iteration : 120/500  -  train loss : 0.003 /   test loss : 0.224
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.223
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.223
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.218
iteration : 160/500  -  train loss : 0.002 /   test loss : 0.217
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.217
iteration : 180/500  -  train loss : 0.003 /   test loss : 0.224
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.224
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.221
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.221
iteration : 220/500  -  train loss : 0.002 /   test loss : 0.226
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.224
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.218
iteration : 250/500  -  train loss : 0.002 /   test loss : 0.215
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.217
iteration : 270/500  -  train loss : 0.003 /   test loss : 0.216
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.215
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.218
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.216
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.221
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.221
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.221
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.223
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.219
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.219
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.219
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.22
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.217
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.216
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.219
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.223
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.217
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.219
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.218
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.216
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.217
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.217
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.221
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.214

Training complete   //   Running time : 168  ------------


[Gene 8] Model 2 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 22963])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22963])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.224 /   test loss : 0.432
iteration : 10/500  -  train loss : 0.044 /   test loss : 0.223
iteration : 20/500  -  train loss : 0.029 /   test loss : 0.24
iteration : 30/500  -  train loss : 0.013 /   test loss : 0.245
iteration : 40/500  -  train loss : 0.016 /   test loss : 0.256
iteration : 50/500  -  train loss : 0.006 /   test loss : 0.244
iteration : 60/500  -  train loss : 0.006 /   test loss : 0.251
iteration : 70/500  -  train loss : 0.007 /   test loss : 0.259
iteration : 80/500  -  train loss : 0.004 /   test loss : 0.259
iteration : 90/500  -  train loss : 0.005 /   test loss : 0.259
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.258
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.269
iteration : 120/500  -  train loss : 0.003 /   test loss : 0.267
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.26
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.271
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.273
iteration : 160/500  -  train loss : 0.002 /   test loss : 0.27
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.276
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.283
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.275
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.275
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.269
iteration : 220/500  -  train loss : 0.002 /   test loss : 0.279
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.271
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.28
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.277
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.283
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.279
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.279
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.283
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.281
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.28
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.282
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.28
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.277
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.285
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.283
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.279
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.283
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.288
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.285
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.28
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.283
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.284
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.275
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.282
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.283
iteration : 470/500  -  train loss : 0.002 /   test loss : 0.283
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.273
iteration : 490/500  -  train loss : 0.002 /   test loss : 0.283
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.275

Training complete   //   Running time : 168  ------------


[Gene 8] Model 2 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 22963])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22963])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.272 /   test loss : 0.217
iteration : 10/500  -  train loss : 0.043 /   test loss : 0.143
iteration : 20/500  -  train loss : 0.033 /   test loss : 0.138
iteration : 30/500  -  train loss : 0.015 /   test loss : 0.138
iteration : 40/500  -  train loss : 0.016 /   test loss : 0.142
iteration : 50/500  -  train loss : 0.005 /   test loss : 0.137
iteration : 60/500  -  train loss : 0.005 /   test loss : 0.138
iteration : 70/500  -  train loss : 0.005 /   test loss : 0.144
iteration : 80/500  -  train loss : 0.004 /   test loss : 0.136
iteration : 90/500  -  train loss : 0.004 /   test loss : 0.135
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.137
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.146
iteration : 120/500  -  train loss : 0.003 /   test loss : 0.143
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.138
iteration : 140/500  -  train loss : 0.003 /   test loss : 0.147
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.144
iteration : 160/500  -  train loss : 0.002 /   test loss : 0.15
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.146
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.143
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.143
iteration : 210/500  -  train loss : 0.002 /   test loss : 0.147
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.145
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.148
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.149
iteration : 250/500  -  train loss : 0.002 /   test loss : 0.143
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.146
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.146
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.153
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.15
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.143
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.144
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.143
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.15
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.149
iteration : 360/500  -  train loss : 0.002 /   test loss : 0.148
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.148
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.148
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.148
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.151
iteration : 490/500  -  train loss : 0.002 /   test loss : 0.153
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.149

Training complete   //   Running time : 168  ------------


[Gene 8] Model 2 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 22963])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22963])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.271 /   test loss : 0.21
iteration : 10/500  -  train loss : 0.041 /   test loss : 0.121
iteration : 20/500  -  train loss : 0.033 /   test loss : 0.136
iteration : 30/500  -  train loss : 0.015 /   test loss : 0.18
iteration : 40/500  -  train loss : 0.015 /   test loss : 0.158
iteration : 50/500  -  train loss : 0.006 /   test loss : 0.183
iteration : 60/500  -  train loss : 0.005 /   test loss : 0.177
iteration : 70/500  -  train loss : 0.005 /   test loss : 0.185
iteration : 80/500  -  train loss : 0.003 /   test loss : 0.173
iteration : 90/500  -  train loss : 0.003 /   test loss : 0.175
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.172
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.176
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.174
iteration : 130/500  -  train loss : 0.003 /   test loss : 0.171
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.174
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.18
iteration : 160/500  -  train loss : 0.003 /   test loss : 0.18
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.175
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.177
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.177
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.183
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.179
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.181
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.18
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.179
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.181
iteration : 260/500  -  train loss : 0.002 /   test loss : 0.177
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.181
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.18
iteration : 290/500  -  train loss : 0.003 /   test loss : 0.178
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.173
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.17
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.177
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.172
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.175
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.177
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.175
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.179
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.178
iteration : 390/500  -  train loss : 0.002 /   test loss : 0.176
iteration : 400/500  -  train loss : 0.002 /   test loss : 0.174
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.174
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.178
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.178
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.18
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.183
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.183
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.177
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.177
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.182
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.177

Training complete   //   Running time : 168  ------------


[Gene 8] Model 2 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([120, 22963])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 22963])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.245 /   test loss : 0.285
iteration : 10/500  -  train loss : 0.041 /   test loss : 0.199
iteration : 20/500  -  train loss : 0.022 /   test loss : 0.192
iteration : 30/500  -  train loss : 0.013 /   test loss : 0.188
iteration : 40/500  -  train loss : 0.013 /   test loss : 0.192
iteration : 50/500  -  train loss : 0.008 /   test loss : 0.185
iteration : 60/500  -  train loss : 0.004 /   test loss : 0.18
iteration : 70/500  -  train loss : 0.005 /   test loss : 0.18
iteration : 80/500  -  train loss : 0.007 /   test loss : 0.184
iteration : 90/500  -  train loss : 0.003 /   test loss : 0.178
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.181
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.178
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.178
iteration : 130/500  -  train loss : 0.003 /   test loss : 0.182
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.182
iteration : 150/500  -  train loss : 0.003 /   test loss : 0.187
iteration : 160/500  -  train loss : 0.002 /   test loss : 0.187
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.186
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.187
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.188
iteration : 200/500  -  train loss : 0.002 /   test loss : 0.184
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.187
iteration : 220/500  -  train loss : 0.003 /   test loss : 0.186
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.185
iteration : 240/500  -  train loss : 0.003 /   test loss : 0.187
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.185
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.188
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.19
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.189
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.188
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.187
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.191
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.193
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.195
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.19
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.19
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.192
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.19
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.189
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.19
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.192
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.198
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.194
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.198
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.198
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.192
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.192
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.195
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.196

Training complete   //   Running time : 166  ------------


[Gene 9] Model 2 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 22048])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22048])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.892 /   test loss : 0.85
iteration : 10/500  -  train loss : 0.426 /   test loss : 0.788
iteration : 20/500  -  train loss : 0.249 /   test loss : 0.799
iteration : 30/500  -  train loss : 0.149 /   test loss : 0.787
iteration : 40/500  -  train loss : 0.094 /   test loss : 0.802
iteration : 50/500  -  train loss : 0.057 /   test loss : 0.775
iteration : 60/500  -  train loss : 0.037 /   test loss : 0.783
iteration : 70/500  -  train loss : 0.028 /   test loss : 0.77
iteration : 80/500  -  train loss : 0.018 /   test loss : 0.769
iteration : 90/500  -  train loss : 0.011 /   test loss : 0.789
iteration : 100/500  -  train loss : 0.008 /   test loss : 0.763
iteration : 110/500  -  train loss : 0.008 /   test loss : 0.765
iteration : 120/500  -  train loss : 0.006 /   test loss : 0.761
iteration : 130/500  -  train loss : 0.006 /   test loss : 0.779
iteration : 140/500  -  train loss : 0.005 /   test loss : 0.776
iteration : 150/500  -  train loss : 0.006 /   test loss : 0.765
iteration : 160/500  -  train loss : 0.006 /   test loss : 0.754
iteration : 170/500  -  train loss : 0.004 /   test loss : 0.751
iteration : 180/500  -  train loss : 0.006 /   test loss : 0.739
iteration : 190/500  -  train loss : 0.005 /   test loss : 0.751
iteration : 200/500  -  train loss : 0.004 /   test loss : 0.745
iteration : 210/500  -  train loss : 0.003 /   test loss : 0.758
iteration : 220/500  -  train loss : 0.002 /   test loss : 0.75
iteration : 230/500  -  train loss : 0.003 /   test loss : 0.784
iteration : 240/500  -  train loss : 0.004 /   test loss : 0.756
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.772
iteration : 260/500  -  train loss : 0.003 /   test loss : 0.761
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.758
iteration : 280/500  -  train loss : 0.004 /   test loss : 0.753
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.758
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.762
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.765
iteration : 320/500  -  train loss : 0.002 /   test loss : 0.755
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.747
iteration : 340/500  -  train loss : 0.003 /   test loss : 0.723
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.742
iteration : 360/500  -  train loss : 0.002 /   test loss : 0.752
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.758
iteration : 380/500  -  train loss : 0.003 /   test loss : 0.739
iteration : 390/500  -  train loss : 0.002 /   test loss : 0.732
iteration : 400/500  -  train loss : 0.002 /   test loss : 0.74
iteration : 410/500  -  train loss : 0.002 /   test loss : 0.734
iteration : 420/500  -  train loss : 0.003 /   test loss : 0.727
iteration : 430/500  -  train loss : 0.003 /   test loss : 0.732
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.736
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.729
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.735
iteration : 470/500  -  train loss : 0.002 /   test loss : 0.738
iteration : 480/500  -  train loss : 0.003 /   test loss : 0.75
iteration : 490/500  -  train loss : 0.002 /   test loss : 0.736
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.731

Training complete   //   Running time : 165  ------------


[Gene 9] Model 2 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 22048])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22048])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.936 /   test loss : 0.636
iteration : 10/500  -  train loss : 0.44 /   test loss : 0.589
iteration : 20/500  -  train loss : 0.229 /   test loss : 0.648
iteration : 30/500  -  train loss : 0.125 /   test loss : 0.706
iteration : 40/500  -  train loss : 0.071 /   test loss : 0.727
iteration : 50/500  -  train loss : 0.045 /   test loss : 0.731
iteration : 60/500  -  train loss : 0.03 /   test loss : 0.732
iteration : 70/500  -  train loss : 0.029 /   test loss : 0.739
iteration : 80/500  -  train loss : 0.016 /   test loss : 0.736
iteration : 90/500  -  train loss : 0.008 /   test loss : 0.751
iteration : 100/500  -  train loss : 0.007 /   test loss : 0.763
iteration : 110/500  -  train loss : 0.007 /   test loss : 0.751
iteration : 120/500  -  train loss : 0.006 /   test loss : 0.746
iteration : 130/500  -  train loss : 0.006 /   test loss : 0.738
iteration : 140/500  -  train loss : 0.005 /   test loss : 0.748
iteration : 150/500  -  train loss : 0.004 /   test loss : 0.753
iteration : 160/500  -  train loss : 0.005 /   test loss : 0.74
iteration : 170/500  -  train loss : 0.006 /   test loss : 0.72
iteration : 180/500  -  train loss : 0.005 /   test loss : 0.726
iteration : 190/500  -  train loss : 0.005 /   test loss : 0.725
iteration : 200/500  -  train loss : 0.004 /   test loss : 0.717
iteration : 210/500  -  train loss : 0.004 /   test loss : 0.72
iteration : 220/500  -  train loss : 0.004 /   test loss : 0.716
iteration : 230/500  -  train loss : 0.002 /   test loss : 0.72
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.723
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.722
iteration : 260/500  -  train loss : 0.003 /   test loss : 0.714
iteration : 270/500  -  train loss : 0.002 /   test loss : 0.711
iteration : 280/500  -  train loss : 0.004 /   test loss : 0.701
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.708
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.703
iteration : 310/500  -  train loss : 0.003 /   test loss : 0.694
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.699
iteration : 330/500  -  train loss : 0.002 /   test loss : 0.696
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.698
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.703
iteration : 360/500  -  train loss : 0.003 /   test loss : 0.698
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.705
iteration : 380/500  -  train loss : 0.002 /   test loss : 0.687
iteration : 390/500  -  train loss : 0.003 /   test loss : 0.693
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.692
iteration : 410/500  -  train loss : 0.002 /   test loss : 0.69
iteration : 420/500  -  train loss : 0.003 /   test loss : 0.689
iteration : 430/500  -  train loss : 0.002 /   test loss : 0.672
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.684
iteration : 450/500  -  train loss : 0.003 /   test loss : 0.678
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.677
iteration : 470/500  -  train loss : 0.002 /   test loss : 0.676
iteration : 480/500  -  train loss : 0.003 /   test loss : 0.663
iteration : 490/500  -  train loss : 0.002 /   test loss : 0.666
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.666

Training complete   //   Running time : 159  ------------


[Gene 9] Model 2 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 22048])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22048])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.742 /   test loss : 1.434
iteration : 10/500  -  train loss : 0.31 /   test loss : 1.379
iteration : 20/500  -  train loss : 0.154 /   test loss : 1.396
iteration : 30/500  -  train loss : 0.083 /   test loss : 1.414
iteration : 40/500  -  train loss : 0.05 /   test loss : 1.421
iteration : 50/500  -  train loss : 0.029 /   test loss : 1.439
iteration : 60/500  -  train loss : 0.021 /   test loss : 1.455
iteration : 70/500  -  train loss : 0.021 /   test loss : 1.454
iteration : 80/500  -  train loss : 0.01 /   test loss : 1.46
iteration : 90/500  -  train loss : 0.006 /   test loss : 1.444
iteration : 100/500  -  train loss : 0.006 /   test loss : 1.45
iteration : 110/500  -  train loss : 0.005 /   test loss : 1.442
iteration : 120/500  -  train loss : 0.005 /   test loss : 1.433
iteration : 130/500  -  train loss : 0.004 /   test loss : 1.438
iteration : 140/500  -  train loss : 0.004 /   test loss : 1.443
iteration : 150/500  -  train loss : 0.003 /   test loss : 1.418
iteration : 160/500  -  train loss : 0.004 /   test loss : 1.422
iteration : 170/500  -  train loss : 0.004 /   test loss : 1.414
iteration : 180/500  -  train loss : 0.004 /   test loss : 1.42
iteration : 190/500  -  train loss : 0.004 /   test loss : 1.414
iteration : 200/500  -  train loss : 0.003 /   test loss : 1.413
iteration : 210/500  -  train loss : 0.002 /   test loss : 1.426
iteration : 220/500  -  train loss : 0.003 /   test loss : 1.425
iteration : 230/500  -  train loss : 0.002 /   test loss : 1.442
iteration : 240/500  -  train loss : 0.002 /   test loss : 1.43
iteration : 250/500  -  train loss : 0.003 /   test loss : 1.425
iteration : 260/500  -  train loss : 0.003 /   test loss : 1.429
iteration : 270/500  -  train loss : 0.001 /   test loss : 1.423
iteration : 280/500  -  train loss : 0.004 /   test loss : 1.416
iteration : 290/500  -  train loss : 0.002 /   test loss : 1.419
iteration : 300/500  -  train loss : 0.002 /   test loss : 1.425
iteration : 310/500  -  train loss : 0.002 /   test loss : 1.425
iteration : 320/500  -  train loss : 0.002 /   test loss : 1.427
iteration : 330/500  -  train loss : 0.002 /   test loss : 1.418
iteration : 340/500  -  train loss : 0.002 /   test loss : 1.412
iteration : 350/500  -  train loss : 0.002 /   test loss : 1.418
iteration : 360/500  -  train loss : 0.002 /   test loss : 1.417
iteration : 370/500  -  train loss : 0.001 /   test loss : 1.422
iteration : 380/500  -  train loss : 0.002 /   test loss : 1.422
iteration : 390/500  -  train loss : 0.004 /   test loss : 1.409
iteration : 400/500  -  train loss : 0.002 /   test loss : 1.409
iteration : 410/500  -  train loss : 0.003 /   test loss : 1.426
iteration : 420/500  -  train loss : 0.002 /   test loss : 1.428
iteration : 430/500  -  train loss : 0.002 /   test loss : 1.413
iteration : 440/500  -  train loss : 0.001 /   test loss : 1.42
iteration : 450/500  -  train loss : 0.002 /   test loss : 1.415
iteration : 460/500  -  train loss : 0.001 /   test loss : 1.413
iteration : 470/500  -  train loss : 0.002 /   test loss : 1.407
iteration : 480/500  -  train loss : 0.003 /   test loss : 1.411
iteration : 490/500  -  train loss : 0.002 /   test loss : 1.411
iteration : 500/500  -  train loss : 0.001 /   test loss : 1.404

Training complete   //   Running time : 159  ------------


[Gene 9] Model 2 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 22048])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22048])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.902 /   test loss : 0.967
iteration : 10/500  -  train loss : 0.411 /   test loss : 0.847
iteration : 20/500  -  train loss : 0.223 /   test loss : 0.875
iteration : 30/500  -  train loss : 0.122 /   test loss : 0.878
iteration : 40/500  -  train loss : 0.073 /   test loss : 0.89
iteration : 50/500  -  train loss : 0.046 /   test loss : 0.892
iteration : 60/500  -  train loss : 0.028 /   test loss : 0.887
iteration : 70/500  -  train loss : 0.02 /   test loss : 0.904
iteration : 80/500  -  train loss : 0.015 /   test loss : 0.922
iteration : 90/500  -  train loss : 0.009 /   test loss : 0.901
iteration : 100/500  -  train loss : 0.01 /   test loss : 0.909
iteration : 110/500  -  train loss : 0.007 /   test loss : 0.921
iteration : 120/500  -  train loss : 0.008 /   test loss : 0.94
iteration : 130/500  -  train loss : 0.005 /   test loss : 0.915
iteration : 140/500  -  train loss : 0.007 /   test loss : 0.909
iteration : 150/500  -  train loss : 0.005 /   test loss : 0.893
iteration : 160/500  -  train loss : 0.004 /   test loss : 0.909
iteration : 170/500  -  train loss : 0.005 /   test loss : 0.909
iteration : 180/500  -  train loss : 0.002 /   test loss : 0.91
iteration : 190/500  -  train loss : 0.004 /   test loss : 0.903
iteration : 200/500  -  train loss : 0.003 /   test loss : 0.917
iteration : 210/500  -  train loss : 0.003 /   test loss : 0.913
iteration : 220/500  -  train loss : 0.002 /   test loss : 0.923
iteration : 230/500  -  train loss : 0.002 /   test loss : 0.911
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.922
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.924
iteration : 260/500  -  train loss : 0.004 /   test loss : 0.915
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.926
iteration : 280/500  -  train loss : 0.003 /   test loss : 0.921
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.915
iteration : 300/500  -  train loss : 0.002 /   test loss : 0.932
iteration : 310/500  -  train loss : 0.002 /   test loss : 0.915
iteration : 320/500  -  train loss : 0.003 /   test loss : 0.91
iteration : 330/500  -  train loss : 0.003 /   test loss : 0.907
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.921
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.908
iteration : 360/500  -  train loss : 0.002 /   test loss : 0.911
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.926
iteration : 380/500  -  train loss : 0.002 /   test loss : 0.919
iteration : 390/500  -  train loss : 0.003 /   test loss : 0.916
iteration : 400/500  -  train loss : 0.002 /   test loss : 0.925
iteration : 410/500  -  train loss : 0.002 /   test loss : 0.918
iteration : 420/500  -  train loss : 0.003 /   test loss : 0.918
iteration : 430/500  -  train loss : 0.003 /   test loss : 0.919
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.914
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.921
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.919
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.922
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.912
iteration : 490/500  -  train loss : 0.002 /   test loss : 0.928
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.919

Training complete   //   Running time : 159  ------------


[Gene 9] Model 2 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([120, 22048])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 22048])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.909 /   test loss : 0.782
iteration : 10/500  -  train loss : 0.434 /   test loss : 0.648
iteration : 20/500  -  train loss : 0.241 /   test loss : 0.662
iteration : 30/500  -  train loss : 0.139 /   test loss : 0.682
iteration : 40/500  -  train loss : 0.082 /   test loss : 0.653
iteration : 50/500  -  train loss : 0.048 /   test loss : 0.669
iteration : 60/500  -  train loss : 0.028 /   test loss : 0.663
iteration : 70/500  -  train loss : 0.019 /   test loss : 0.664
iteration : 80/500  -  train loss : 0.013 /   test loss : 0.678
iteration : 90/500  -  train loss : 0.013 /   test loss : 0.673
iteration : 100/500  -  train loss : 0.007 /   test loss : 0.686
iteration : 110/500  -  train loss : 0.01 /   test loss : 0.69
iteration : 120/500  -  train loss : 0.007 /   test loss : 0.685
iteration : 130/500  -  train loss : 0.006 /   test loss : 0.69
iteration : 140/500  -  train loss : 0.005 /   test loss : 0.679
iteration : 150/500  -  train loss : 0.004 /   test loss : 0.693
iteration : 160/500  -  train loss : 0.005 /   test loss : 0.686
iteration : 170/500  -  train loss : 0.003 /   test loss : 0.685
iteration : 180/500  -  train loss : 0.003 /   test loss : 0.677
iteration : 190/500  -  train loss : 0.005 /   test loss : 0.678
iteration : 200/500  -  train loss : 0.003 /   test loss : 0.677
iteration : 210/500  -  train loss : 0.004 /   test loss : 0.67
iteration : 220/500  -  train loss : 0.003 /   test loss : 0.679
iteration : 230/500  -  train loss : 0.003 /   test loss : 0.674
iteration : 240/500  -  train loss : 0.002 /   test loss : 0.678
iteration : 250/500  -  train loss : 0.003 /   test loss : 0.685
iteration : 260/500  -  train loss : 0.003 /   test loss : 0.684
iteration : 270/500  -  train loss : 0.003 /   test loss : 0.684
iteration : 280/500  -  train loss : 0.004 /   test loss : 0.683
iteration : 290/500  -  train loss : 0.002 /   test loss : 0.69
iteration : 300/500  -  train loss : 0.003 /   test loss : 0.684
iteration : 310/500  -  train loss : 0.003 /   test loss : 0.682
iteration : 320/500  -  train loss : 0.003 /   test loss : 0.68
iteration : 330/500  -  train loss : 0.003 /   test loss : 0.686
iteration : 340/500  -  train loss : 0.002 /   test loss : 0.692
iteration : 350/500  -  train loss : 0.002 /   test loss : 0.685
iteration : 360/500  -  train loss : 0.002 /   test loss : 0.689
iteration : 370/500  -  train loss : 0.002 /   test loss : 0.689
iteration : 380/500  -  train loss : 0.003 /   test loss : 0.683
iteration : 390/500  -  train loss : 0.002 /   test loss : 0.688
iteration : 400/500  -  train loss : 0.003 /   test loss : 0.69
iteration : 410/500  -  train loss : 0.002 /   test loss : 0.682
iteration : 420/500  -  train loss : 0.002 /   test loss : 0.685
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.69
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.686
iteration : 450/500  -  train loss : 0.002 /   test loss : 0.687
iteration : 460/500  -  train loss : 0.002 /   test loss : 0.689
iteration : 470/500  -  train loss : 0.002 /   test loss : 0.682
iteration : 480/500  -  train loss : 0.002 /   test loss : 0.683
iteration : 490/500  -  train loss : 0.003 /   test loss : 0.693
iteration : 500/500  -  train loss : 0.002 /   test loss : 0.687

Training complete   //   Running time : 159  ------------


[Gene 10] Model 2 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 12638])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 12638])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.19 /   test loss : 0.214
iteration : 10/500  -  train loss : 0.045 /   test loss : 0.197
iteration : 20/500  -  train loss : 0.017 /   test loss : 0.177
iteration : 30/500  -  train loss : 0.01 /   test loss : 0.171
iteration : 40/500  -  train loss : 0.006 /   test loss : 0.167
iteration : 50/500  -  train loss : 0.005 /   test loss : 0.174
iteration : 60/500  -  train loss : 0.004 /   test loss : 0.178
iteration : 70/500  -  train loss : 0.004 /   test loss : 0.172
iteration : 80/500  -  train loss : 0.003 /   test loss : 0.175
iteration : 90/500  -  train loss : 0.003 /   test loss : 0.173
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.172
iteration : 110/500  -  train loss : 0.003 /   test loss : 0.17
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.169
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.168
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.172
iteration : 150/500  -  train loss : 0.002 /   test loss : 0.173
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.17
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.172
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.174
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.173
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.171
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.172
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.172
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.175
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.17
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.173
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.174
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.172
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.175
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.172
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.172
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.172
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.175
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.175
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.176
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.174
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.172
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.169
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.173
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.17
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.173
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.174
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.174
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.176
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.173
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.172
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.17
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.172
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.17
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.171
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.171

Training complete   //   Running time :  96  ------------


[Gene 10] Model 2 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 12638])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 12638])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.193 /   test loss : 0.192
iteration : 10/500  -  train loss : 0.052 /   test loss : 0.128
iteration : 20/500  -  train loss : 0.023 /   test loss : 0.13
iteration : 30/500  -  train loss : 0.013 /   test loss : 0.132
iteration : 40/500  -  train loss : 0.008 /   test loss : 0.132
iteration : 50/500  -  train loss : 0.006 /   test loss : 0.137
iteration : 60/500  -  train loss : 0.004 /   test loss : 0.134
iteration : 70/500  -  train loss : 0.004 /   test loss : 0.132
iteration : 80/500  -  train loss : 0.004 /   test loss : 0.135
iteration : 90/500  -  train loss : 0.003 /   test loss : 0.14
iteration : 100/500  -  train loss : 0.003 /   test loss : 0.149
iteration : 110/500  -  train loss : 0.003 /   test loss : 0.146
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.15
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.141
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.139
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.144
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.142
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.142
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.144
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.148
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.145
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.143
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.14
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.142
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.143
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.146
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.148
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.142
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.144
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.144
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.145
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.146
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.145
iteration : 340/500  -  train loss : 0.0 /   test loss : 0.147
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.146
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.144
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.148
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.146
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.144
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.145
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.144
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.146
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 470/500  -  train loss : 0.0 /   test loss : 0.147
iteration : 480/500  -  train loss : 0.001 /   test loss : 0.148
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.147

Training complete   //   Running time :  95  ------------


[Gene 10] Model 2 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 12638])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 12638])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.178 /   test loss : 0.283
iteration : 10/500  -  train loss : 0.045 /   test loss : 0.152
iteration : 20/500  -  train loss : 0.021 /   test loss : 0.145
iteration : 30/500  -  train loss : 0.011 /   test loss : 0.148
iteration : 40/500  -  train loss : 0.007 /   test loss : 0.145
iteration : 50/500  -  train loss : 0.005 /   test loss : 0.151
iteration : 60/500  -  train loss : 0.004 /   test loss : 0.148
iteration : 70/500  -  train loss : 0.003 /   test loss : 0.147
iteration : 80/500  -  train loss : 0.004 /   test loss : 0.148
iteration : 90/500  -  train loss : 0.003 /   test loss : 0.149
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.147
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.15
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.148
iteration : 130/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.153
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.147
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.15
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.148
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.148
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.151
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.15
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.153
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.152
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.151
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.153
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.15
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.151
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.15
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.15
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.15
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.15
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.152
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.153
iteration : 350/500  -  train loss : 0.0 /   test loss : 0.15
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.152
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.15
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.15
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 400/500  -  train loss : 0.0 /   test loss : 0.147
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.154
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.153
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.149
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.148
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.152
iteration : 470/500  -  train loss : 0.0 /   test loss : 0.15
iteration : 480/500  -  train loss : 0.0 /   test loss : 0.15
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.152
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.151

Training complete   //   Running time :  95  ------------


[Gene 10] Model 2 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([123, 12638])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 12638])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.193 /   test loss : 0.188
iteration : 10/500  -  train loss : 0.048 /   test loss : 0.159
iteration : 20/500  -  train loss : 0.019 /   test loss : 0.162
iteration : 30/500  -  train loss : 0.011 /   test loss : 0.167
iteration : 40/500  -  train loss : 0.007 /   test loss : 0.173
iteration : 50/500  -  train loss : 0.005 /   test loss : 0.171
iteration : 60/500  -  train loss : 0.004 /   test loss : 0.171
iteration : 70/500  -  train loss : 0.004 /   test loss : 0.166
iteration : 80/500  -  train loss : 0.003 /   test loss : 0.175
iteration : 90/500  -  train loss : 0.003 /   test loss : 0.169
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.17
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.168
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.169
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.171
iteration : 140/500  -  train loss : 0.001 /   test loss : 0.169
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.172
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.172
iteration : 170/500  -  train loss : 0.002 /   test loss : 0.17
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.172
iteration : 190/500  -  train loss : 0.002 /   test loss : 0.169
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.167
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.171
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.169
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.168
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.169
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.168
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.169
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.168
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.167
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.17
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.169
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.168
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.173
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.17
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.168
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.17
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.172
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.169
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.168
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.171
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.167
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.171
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.17
iteration : 430/500  -  train loss : 0.0 /   test loss : 0.17
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.166
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.171
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.169
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.171
iteration : 480/500  -  train loss : 0.0 /   test loss : 0.171
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.17
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.169

Training complete   //   Running time :  94  ------------


[Gene 10] Model 2 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.90

Data shape @@@@@@
Train data :  torch.Size([120, 12638])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 12638])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.21 /   test loss : 0.213
iteration : 10/500  -  train loss : 0.049 /   test loss : 0.119
iteration : 20/500  -  train loss : 0.026 /   test loss : 0.131
iteration : 30/500  -  train loss : 0.015 /   test loss : 0.131
iteration : 40/500  -  train loss : 0.008 /   test loss : 0.131
iteration : 50/500  -  train loss : 0.006 /   test loss : 0.125
iteration : 60/500  -  train loss : 0.005 /   test loss : 0.127
iteration : 70/500  -  train loss : 0.004 /   test loss : 0.127
iteration : 80/500  -  train loss : 0.004 /   test loss : 0.122
iteration : 90/500  -  train loss : 0.002 /   test loss : 0.12
iteration : 100/500  -  train loss : 0.002 /   test loss : 0.124
iteration : 110/500  -  train loss : 0.002 /   test loss : 0.12
iteration : 120/500  -  train loss : 0.002 /   test loss : 0.123
iteration : 130/500  -  train loss : 0.002 /   test loss : 0.122
iteration : 140/500  -  train loss : 0.002 /   test loss : 0.124
iteration : 150/500  -  train loss : 0.001 /   test loss : 0.124
iteration : 160/500  -  train loss : 0.001 /   test loss : 0.121
iteration : 170/500  -  train loss : 0.001 /   test loss : 0.12
iteration : 180/500  -  train loss : 0.001 /   test loss : 0.119
iteration : 190/500  -  train loss : 0.001 /   test loss : 0.126
iteration : 200/500  -  train loss : 0.001 /   test loss : 0.124
iteration : 210/500  -  train loss : 0.001 /   test loss : 0.119
iteration : 220/500  -  train loss : 0.001 /   test loss : 0.123
iteration : 230/500  -  train loss : 0.001 /   test loss : 0.125
iteration : 240/500  -  train loss : 0.001 /   test loss : 0.122
iteration : 250/500  -  train loss : 0.001 /   test loss : 0.121
iteration : 260/500  -  train loss : 0.001 /   test loss : 0.125
iteration : 270/500  -  train loss : 0.001 /   test loss : 0.122
iteration : 280/500  -  train loss : 0.001 /   test loss : 0.124
iteration : 290/500  -  train loss : 0.001 /   test loss : 0.122
iteration : 300/500  -  train loss : 0.001 /   test loss : 0.122
iteration : 310/500  -  train loss : 0.001 /   test loss : 0.125
iteration : 320/500  -  train loss : 0.001 /   test loss : 0.122
iteration : 330/500  -  train loss : 0.001 /   test loss : 0.12
iteration : 340/500  -  train loss : 0.001 /   test loss : 0.122
iteration : 350/500  -  train loss : 0.001 /   test loss : 0.119
iteration : 360/500  -  train loss : 0.001 /   test loss : 0.121
iteration : 370/500  -  train loss : 0.001 /   test loss : 0.122
iteration : 380/500  -  train loss : 0.001 /   test loss : 0.12
iteration : 390/500  -  train loss : 0.001 /   test loss : 0.121
iteration : 400/500  -  train loss : 0.001 /   test loss : 0.121
iteration : 410/500  -  train loss : 0.001 /   test loss : 0.12
iteration : 420/500  -  train loss : 0.001 /   test loss : 0.123
iteration : 430/500  -  train loss : 0.001 /   test loss : 0.122
iteration : 440/500  -  train loss : 0.001 /   test loss : 0.123
iteration : 450/500  -  train loss : 0.001 /   test loss : 0.123
iteration : 460/500  -  train loss : 0.001 /   test loss : 0.121
iteration : 470/500  -  train loss : 0.001 /   test loss : 0.12
iteration : 480/500  -  train loss : 0.0 /   test loss : 0.119
iteration : 490/500  -  train loss : 0.001 /   test loss : 0.123
iteration : 500/500  -  train loss : 0.001 /   test loss : 0.121

Training complete   //   Running time :  94  ------------


[Gene 1] Model 3 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 23049])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23049])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.41 /   test loss : 0.379
iteration : 10/500  -  train loss : 0.295 /   test loss : 0.3
iteration : 20/500  -  train loss : 0.229 /   test loss : 0.254
iteration : 30/500  -  train loss : 0.2 /   test loss : 0.245
iteration : 40/500  -  train loss : 0.187 /   test loss : 0.235
iteration : 50/500  -  train loss : 0.18 /   test loss : 0.235
iteration : 60/500  -  train loss : 0.171 /   test loss : 0.234
iteration : 70/500  -  train loss : 0.164 /   test loss : 0.245
iteration : 80/500  -  train loss : 0.157 /   test loss : 0.24
iteration : 90/500  -  train loss : 0.148 /   test loss : 0.236
iteration : 100/500  -  train loss : 0.144 /   test loss : 0.236
iteration : 110/500  -  train loss : 0.139 /   test loss : 0.237
iteration : 120/500  -  train loss : 0.132 /   test loss : 0.237
iteration : 130/500  -  train loss : 0.123 /   test loss : 0.226
iteration : 140/500  -  train loss : 0.117 /   test loss : 0.23
iteration : 150/500  -  train loss : 0.112 /   test loss : 0.222
iteration : 160/500  -  train loss : 0.102 /   test loss : 0.217
iteration : 170/500  -  train loss : 0.1 /   test loss : 0.217
iteration : 180/500  -  train loss : 0.096 /   test loss : 0.217
iteration : 190/500  -  train loss : 0.093 /   test loss : 0.22
iteration : 200/500  -  train loss : 0.087 /   test loss : 0.219
iteration : 210/500  -  train loss : 0.085 /   test loss : 0.22
iteration : 220/500  -  train loss : 0.085 /   test loss : 0.224
iteration : 230/500  -  train loss : 0.08 /   test loss : 0.222
iteration : 240/500  -  train loss : 0.076 /   test loss : 0.221
iteration : 250/500  -  train loss : 0.076 /   test loss : 0.222
iteration : 260/500  -  train loss : 0.072 /   test loss : 0.216
iteration : 270/500  -  train loss : 0.069 /   test loss : 0.216
iteration : 280/500  -  train loss : 0.068 /   test loss : 0.216
iteration : 290/500  -  train loss : 0.067 /   test loss : 0.222
iteration : 300/500  -  train loss : 0.062 /   test loss : 0.219
iteration : 310/500  -  train loss : 0.061 /   test loss : 0.221
iteration : 320/500  -  train loss : 0.061 /   test loss : 0.221
iteration : 330/500  -  train loss : 0.061 /   test loss : 0.223
iteration : 340/500  -  train loss : 0.059 /   test loss : 0.221
iteration : 350/500  -  train loss : 0.059 /   test loss : 0.22
iteration : 360/500  -  train loss : 0.06 /   test loss : 0.22
iteration : 370/500  -  train loss : 0.057 /   test loss : 0.216
iteration : 380/500  -  train loss : 0.058 /   test loss : 0.219
iteration : 390/500  -  train loss : 0.058 /   test loss : 0.22
iteration : 400/500  -  train loss : 0.06 /   test loss : 0.224
iteration : 410/500  -  train loss : 0.058 /   test loss : 0.222
iteration : 420/500  -  train loss : 0.053 /   test loss : 0.217
iteration : 430/500  -  train loss : 0.054 /   test loss : 0.215
iteration : 440/500  -  train loss : 0.05 /   test loss : 0.214
iteration : 450/500  -  train loss : 0.05 /   test loss : 0.214
iteration : 460/500  -  train loss : 0.052 /   test loss : 0.217
iteration : 470/500  -  train loss : 0.051 /   test loss : 0.218
iteration : 480/500  -  train loss : 0.048 /   test loss : 0.218
iteration : 490/500  -  train loss : 0.048 /   test loss : 0.216
iteration : 500/500  -  train loss : 0.05 /   test loss : 0.218

Training complete   //   Running time : 175  ------------


[Gene 1] Model 3 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 23049])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23049])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.397 /   test loss : 0.419
iteration : 10/500  -  train loss : 0.274 /   test loss : 0.376
iteration : 20/500  -  train loss : 0.214 /   test loss : 0.371
iteration : 30/500  -  train loss : 0.182 /   test loss : 0.346
iteration : 40/500  -  train loss : 0.171 /   test loss : 0.346
iteration : 50/500  -  train loss : 0.17 /   test loss : 0.375
iteration : 60/500  -  train loss : 0.162 /   test loss : 0.35
iteration : 70/500  -  train loss : 0.157 /   test loss : 0.356
iteration : 80/500  -  train loss : 0.15 /   test loss : 0.355
iteration : 90/500  -  train loss : 0.14 /   test loss : 0.35
iteration : 100/500  -  train loss : 0.132 /   test loss : 0.352
iteration : 110/500  -  train loss : 0.125 /   test loss : 0.345
iteration : 120/500  -  train loss : 0.115 /   test loss : 0.348
iteration : 130/500  -  train loss : 0.109 /   test loss : 0.347
iteration : 140/500  -  train loss : 0.105 /   test loss : 0.337
iteration : 150/500  -  train loss : 0.101 /   test loss : 0.346
iteration : 160/500  -  train loss : 0.096 /   test loss : 0.343
iteration : 170/500  -  train loss : 0.092 /   test loss : 0.341
iteration : 180/500  -  train loss : 0.088 /   test loss : 0.341
iteration : 190/500  -  train loss : 0.083 /   test loss : 0.347
iteration : 200/500  -  train loss : 0.079 /   test loss : 0.341
iteration : 210/500  -  train loss : 0.076 /   test loss : 0.332
iteration : 220/500  -  train loss : 0.071 /   test loss : 0.334
iteration : 230/500  -  train loss : 0.073 /   test loss : 0.333
iteration : 240/500  -  train loss : 0.07 /   test loss : 0.336
iteration : 250/500  -  train loss : 0.066 /   test loss : 0.343
iteration : 260/500  -  train loss : 0.064 /   test loss : 0.344
iteration : 270/500  -  train loss : 0.066 /   test loss : 0.336
iteration : 280/500  -  train loss : 0.064 /   test loss : 0.343
iteration : 290/500  -  train loss : 0.066 /   test loss : 0.347
iteration : 300/500  -  train loss : 0.062 /   test loss : 0.345
iteration : 310/500  -  train loss : 0.061 /   test loss : 0.343
iteration : 320/500  -  train loss : 0.059 /   test loss : 0.341
iteration : 330/500  -  train loss : 0.061 /   test loss : 0.343
iteration : 340/500  -  train loss : 0.057 /   test loss : 0.343
iteration : 350/500  -  train loss : 0.054 /   test loss : 0.337
iteration : 360/500  -  train loss : 0.055 /   test loss : 0.334
iteration : 370/500  -  train loss : 0.056 /   test loss : 0.341
iteration : 380/500  -  train loss : 0.054 /   test loss : 0.34
iteration : 390/500  -  train loss : 0.052 /   test loss : 0.342
iteration : 400/500  -  train loss : 0.05 /   test loss : 0.343
iteration : 410/500  -  train loss : 0.049 /   test loss : 0.338
iteration : 420/500  -  train loss : 0.049 /   test loss : 0.34
iteration : 430/500  -  train loss : 0.048 /   test loss : 0.343
iteration : 440/500  -  train loss : 0.046 /   test loss : 0.338
iteration : 450/500  -  train loss : 0.047 /   test loss : 0.333
iteration : 460/500  -  train loss : 0.047 /   test loss : 0.341
iteration : 470/500  -  train loss : 0.046 /   test loss : 0.34
iteration : 480/500  -  train loss : 0.048 /   test loss : 0.333
iteration : 490/500  -  train loss : 0.046 /   test loss : 0.334
iteration : 500/500  -  train loss : 0.05 /   test loss : 0.338

Training complete   //   Running time : 169  ------------


[Gene 1] Model 3 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 23049])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23049])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.415 /   test loss : 0.348
iteration : 10/500  -  train loss : 0.291 /   test loss : 0.296
iteration : 20/500  -  train loss : 0.231 /   test loss : 0.276
iteration : 30/500  -  train loss : 0.189 /   test loss : 0.255
iteration : 40/500  -  train loss : 0.17 /   test loss : 0.254
iteration : 50/500  -  train loss : 0.164 /   test loss : 0.263
iteration : 60/500  -  train loss : 0.16 /   test loss : 0.258
iteration : 70/500  -  train loss : 0.157 /   test loss : 0.263
iteration : 80/500  -  train loss : 0.146 /   test loss : 0.262
iteration : 90/500  -  train loss : 0.138 /   test loss : 0.259
iteration : 100/500  -  train loss : 0.133 /   test loss : 0.263
iteration : 110/500  -  train loss : 0.125 /   test loss : 0.262
iteration : 120/500  -  train loss : 0.118 /   test loss : 0.259
iteration : 130/500  -  train loss : 0.11 /   test loss : 0.259
iteration : 140/500  -  train loss : 0.108 /   test loss : 0.26
iteration : 150/500  -  train loss : 0.103 /   test loss : 0.262
iteration : 160/500  -  train loss : 0.1 /   test loss : 0.262
iteration : 170/500  -  train loss : 0.098 /   test loss : 0.264
iteration : 180/500  -  train loss : 0.093 /   test loss : 0.262
iteration : 190/500  -  train loss : 0.088 /   test loss : 0.26
iteration : 200/500  -  train loss : 0.084 /   test loss : 0.259
iteration : 210/500  -  train loss : 0.081 /   test loss : 0.258
iteration : 220/500  -  train loss : 0.076 /   test loss : 0.261
iteration : 230/500  -  train loss : 0.073 /   test loss : 0.258
iteration : 240/500  -  train loss : 0.071 /   test loss : 0.257
iteration : 250/500  -  train loss : 0.071 /   test loss : 0.258
iteration : 260/500  -  train loss : 0.067 /   test loss : 0.257
iteration : 270/500  -  train loss : 0.065 /   test loss : 0.259
iteration : 280/500  -  train loss : 0.068 /   test loss : 0.262
iteration : 290/500  -  train loss : 0.073 /   test loss : 0.261
iteration : 300/500  -  train loss : 0.067 /   test loss : 0.256
iteration : 310/500  -  train loss : 0.065 /   test loss : 0.257
iteration : 320/500  -  train loss : 0.062 /   test loss : 0.255
iteration : 330/500  -  train loss : 0.063 /   test loss : 0.258
iteration : 340/500  -  train loss : 0.065 /   test loss : 0.262
iteration : 350/500  -  train loss : 0.062 /   test loss : 0.259
iteration : 360/500  -  train loss : 0.059 /   test loss : 0.258
iteration : 370/500  -  train loss : 0.056 /   test loss : 0.259
iteration : 380/500  -  train loss : 0.056 /   test loss : 0.259
iteration : 390/500  -  train loss : 0.055 /   test loss : 0.26
iteration : 400/500  -  train loss : 0.055 /   test loss : 0.26
iteration : 410/500  -  train loss : 0.055 /   test loss : 0.257
iteration : 420/500  -  train loss : 0.051 /   test loss : 0.258
iteration : 430/500  -  train loss : 0.054 /   test loss : 0.261
iteration : 440/500  -  train loss : 0.051 /   test loss : 0.261
iteration : 450/500  -  train loss : 0.048 /   test loss : 0.263
iteration : 460/500  -  train loss : 0.047 /   test loss : 0.262
iteration : 470/500  -  train loss : 0.046 /   test loss : 0.26
iteration : 480/500  -  train loss : 0.048 /   test loss : 0.262
iteration : 490/500  -  train loss : 0.05 /   test loss : 0.262
iteration : 500/500  -  train loss : 0.051 /   test loss : 0.264

Training complete   //   Running time : 168  ------------


[Gene 1] Model 3 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 23049])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23049])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.356 /   test loss : 0.591
iteration : 10/500  -  train loss : 0.254 /   test loss : 0.498
iteration : 20/500  -  train loss : 0.208 /   test loss : 0.441
iteration : 30/500  -  train loss : 0.18 /   test loss : 0.427
iteration : 40/500  -  train loss : 0.166 /   test loss : 0.422
iteration : 50/500  -  train loss : 0.159 /   test loss : 0.42
iteration : 60/500  -  train loss : 0.153 /   test loss : 0.426
iteration : 70/500  -  train loss : 0.149 /   test loss : 0.427
iteration : 80/500  -  train loss : 0.14 /   test loss : 0.427
iteration : 90/500  -  train loss : 0.132 /   test loss : 0.423
iteration : 100/500  -  train loss : 0.128 /   test loss : 0.418
iteration : 110/500  -  train loss : 0.122 /   test loss : 0.426
iteration : 120/500  -  train loss : 0.116 /   test loss : 0.423
iteration : 130/500  -  train loss : 0.107 /   test loss : 0.415
iteration : 140/500  -  train loss : 0.102 /   test loss : 0.412
iteration : 150/500  -  train loss : 0.1 /   test loss : 0.408
iteration : 160/500  -  train loss : 0.097 /   test loss : 0.408
iteration : 170/500  -  train loss : 0.093 /   test loss : 0.409
iteration : 180/500  -  train loss : 0.088 /   test loss : 0.407
iteration : 190/500  -  train loss : 0.085 /   test loss : 0.402
iteration : 200/500  -  train loss : 0.083 /   test loss : 0.406
iteration : 210/500  -  train loss : 0.082 /   test loss : 0.4
iteration : 220/500  -  train loss : 0.079 /   test loss : 0.403
iteration : 230/500  -  train loss : 0.076 /   test loss : 0.399
iteration : 240/500  -  train loss : 0.073 /   test loss : 0.399
iteration : 250/500  -  train loss : 0.071 /   test loss : 0.402
iteration : 260/500  -  train loss : 0.068 /   test loss : 0.403
iteration : 270/500  -  train loss : 0.066 /   test loss : 0.399
iteration : 280/500  -  train loss : 0.067 /   test loss : 0.4
iteration : 290/500  -  train loss : 0.066 /   test loss : 0.4
iteration : 300/500  -  train loss : 0.066 /   test loss : 0.398
iteration : 310/500  -  train loss : 0.065 /   test loss : 0.4
iteration : 320/500  -  train loss : 0.062 /   test loss : 0.399
iteration : 330/500  -  train loss : 0.062 /   test loss : 0.4
iteration : 340/500  -  train loss : 0.061 /   test loss : 0.397
iteration : 350/500  -  train loss : 0.06 /   test loss : 0.393
iteration : 360/500  -  train loss : 0.058 /   test loss : 0.394
iteration : 370/500  -  train loss : 0.057 /   test loss : 0.392
iteration : 380/500  -  train loss : 0.057 /   test loss : 0.395
iteration : 390/500  -  train loss : 0.054 /   test loss : 0.393
iteration : 400/500  -  train loss : 0.054 /   test loss : 0.392
iteration : 410/500  -  train loss : 0.053 /   test loss : 0.395
iteration : 420/500  -  train loss : 0.053 /   test loss : 0.396
iteration : 430/500  -  train loss : 0.053 /   test loss : 0.396
iteration : 440/500  -  train loss : 0.054 /   test loss : 0.397
iteration : 450/500  -  train loss : 0.048 /   test loss : 0.391
iteration : 460/500  -  train loss : 0.048 /   test loss : 0.391
iteration : 470/500  -  train loss : 0.047 /   test loss : 0.389
iteration : 480/500  -  train loss : 0.047 /   test loss : 0.39
iteration : 490/500  -  train loss : 0.044 /   test loss : 0.388
iteration : 500/500  -  train loss : 0.047 /   test loss : 0.393

Training complete   //   Running time : 169  ------------


[Gene 1] Model 3 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([120, 23049])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 23049])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.426 /   test loss : 0.305
iteration : 10/500  -  train loss : 0.302 /   test loss : 0.254
iteration : 20/500  -  train loss : 0.226 /   test loss : 0.236
iteration : 30/500  -  train loss : 0.198 /   test loss : 0.226
iteration : 40/500  -  train loss : 0.187 /   test loss : 0.229
iteration : 50/500  -  train loss : 0.18 /   test loss : 0.221
iteration : 60/500  -  train loss : 0.171 /   test loss : 0.219
iteration : 70/500  -  train loss : 0.163 /   test loss : 0.216
iteration : 80/500  -  train loss : 0.159 /   test loss : 0.22
iteration : 90/500  -  train loss : 0.15 /   test loss : 0.211
iteration : 100/500  -  train loss : 0.143 /   test loss : 0.211
iteration : 110/500  -  train loss : 0.133 /   test loss : 0.213
iteration : 120/500  -  train loss : 0.127 /   test loss : 0.211
iteration : 130/500  -  train loss : 0.122 /   test loss : 0.21
iteration : 140/500  -  train loss : 0.117 /   test loss : 0.207
iteration : 150/500  -  train loss : 0.11 /   test loss : 0.205
iteration : 160/500  -  train loss : 0.108 /   test loss : 0.204
iteration : 170/500  -  train loss : 0.104 /   test loss : 0.203
iteration : 180/500  -  train loss : 0.1 /   test loss : 0.204
iteration : 190/500  -  train loss : 0.096 /   test loss : 0.202
iteration : 200/500  -  train loss : 0.09 /   test loss : 0.2
iteration : 210/500  -  train loss : 0.087 /   test loss : 0.205
iteration : 220/500  -  train loss : 0.084 /   test loss : 0.201
iteration : 230/500  -  train loss : 0.082 /   test loss : 0.199
iteration : 240/500  -  train loss : 0.076 /   test loss : 0.198
iteration : 250/500  -  train loss : 0.075 /   test loss : 0.199
iteration : 260/500  -  train loss : 0.073 /   test loss : 0.197
iteration : 270/500  -  train loss : 0.067 /   test loss : 0.197
iteration : 280/500  -  train loss : 0.066 /   test loss : 0.196
iteration : 290/500  -  train loss : 0.068 /   test loss : 0.199
iteration : 300/500  -  train loss : 0.069 /   test loss : 0.203
iteration : 310/500  -  train loss : 0.068 /   test loss : 0.201
iteration : 320/500  -  train loss : 0.068 /   test loss : 0.2
iteration : 330/500  -  train loss : 0.067 /   test loss : 0.2
iteration : 340/500  -  train loss : 0.063 /   test loss : 0.198
iteration : 350/500  -  train loss : 0.059 /   test loss : 0.198
iteration : 360/500  -  train loss : 0.058 /   test loss : 0.199
iteration : 370/500  -  train loss : 0.059 /   test loss : 0.198
iteration : 380/500  -  train loss : 0.056 /   test loss : 0.2
iteration : 390/500  -  train loss : 0.052 /   test loss : 0.2
iteration : 400/500  -  train loss : 0.051 /   test loss : 0.198
iteration : 410/500  -  train loss : 0.053 /   test loss : 0.2
iteration : 420/500  -  train loss : 0.055 /   test loss : 0.203
iteration : 430/500  -  train loss : 0.056 /   test loss : 0.205
iteration : 440/500  -  train loss : 0.049 /   test loss : 0.201
iteration : 450/500  -  train loss : 0.049 /   test loss : 0.198
iteration : 460/500  -  train loss : 0.051 /   test loss : 0.198
iteration : 470/500  -  train loss : 0.052 /   test loss : 0.2
iteration : 480/500  -  train loss : 0.054 /   test loss : 0.2
iteration : 490/500  -  train loss : 0.052 /   test loss : 0.198
iteration : 500/500  -  train loss : 0.053 /   test loss : 0.199

Training complete   //   Running time : 166  ------------


[Gene 2] Model 3 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 22930])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22930])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.781 /   test loss : 0.617
iteration : 10/500  -  train loss : 0.541 /   test loss : 0.545
iteration : 20/500  -  train loss : 0.4 /   test loss : 0.507
iteration : 30/500  -  train loss : 0.35 /   test loss : 0.512
iteration : 40/500  -  train loss : 0.321 /   test loss : 0.504
iteration : 50/500  -  train loss : 0.301 /   test loss : 0.514
iteration : 60/500  -  train loss : 0.285 /   test loss : 0.517
iteration : 70/500  -  train loss : 0.27 /   test loss : 0.513
iteration : 80/500  -  train loss : 0.251 /   test loss : 0.513
iteration : 90/500  -  train loss : 0.238 /   test loss : 0.518
iteration : 100/500  -  train loss : 0.233 /   test loss : 0.515
iteration : 110/500  -  train loss : 0.221 /   test loss : 0.511
iteration : 120/500  -  train loss : 0.209 /   test loss : 0.509
iteration : 130/500  -  train loss : 0.193 /   test loss : 0.511
iteration : 140/500  -  train loss : 0.18 /   test loss : 0.517
iteration : 150/500  -  train loss : 0.169 /   test loss : 0.513
iteration : 160/500  -  train loss : 0.167 /   test loss : 0.513
iteration : 170/500  -  train loss : 0.158 /   test loss : 0.511
iteration : 180/500  -  train loss : 0.145 /   test loss : 0.514
iteration : 190/500  -  train loss : 0.136 /   test loss : 0.513
iteration : 200/500  -  train loss : 0.134 /   test loss : 0.517
iteration : 210/500  -  train loss : 0.135 /   test loss : 0.519
iteration : 220/500  -  train loss : 0.131 /   test loss : 0.524
iteration : 230/500  -  train loss : 0.128 /   test loss : 0.521
iteration : 240/500  -  train loss : 0.125 /   test loss : 0.518
iteration : 250/500  -  train loss : 0.123 /   test loss : 0.519
iteration : 260/500  -  train loss : 0.115 /   test loss : 0.521
iteration : 270/500  -  train loss : 0.108 /   test loss : 0.519
iteration : 280/500  -  train loss : 0.102 /   test loss : 0.519
iteration : 290/500  -  train loss : 0.101 /   test loss : 0.52
iteration : 300/500  -  train loss : 0.102 /   test loss : 0.52
iteration : 310/500  -  train loss : 0.096 /   test loss : 0.521
iteration : 320/500  -  train loss : 0.099 /   test loss : 0.514
iteration : 330/500  -  train loss : 0.099 /   test loss : 0.513
iteration : 340/500  -  train loss : 0.103 /   test loss : 0.516
iteration : 350/500  -  train loss : 0.094 /   test loss : 0.515
iteration : 360/500  -  train loss : 0.09 /   test loss : 0.521
iteration : 370/500  -  train loss : 0.088 /   test loss : 0.522
iteration : 380/500  -  train loss : 0.087 /   test loss : 0.521
iteration : 390/500  -  train loss : 0.092 /   test loss : 0.518
iteration : 400/500  -  train loss : 0.091 /   test loss : 0.516
iteration : 410/500  -  train loss : 0.082 /   test loss : 0.518
iteration : 420/500  -  train loss : 0.084 /   test loss : 0.516
iteration : 430/500  -  train loss : 0.082 /   test loss : 0.514
iteration : 440/500  -  train loss : 0.083 /   test loss : 0.518
iteration : 450/500  -  train loss : 0.084 /   test loss : 0.517
iteration : 460/500  -  train loss : 0.078 /   test loss : 0.513
iteration : 470/500  -  train loss : 0.08 /   test loss : 0.516
iteration : 480/500  -  train loss : 0.077 /   test loss : 0.519
iteration : 490/500  -  train loss : 0.082 /   test loss : 0.519
iteration : 500/500  -  train loss : 0.076 /   test loss : 0.513

Training complete   //   Running time : 169  ------------


[Gene 2] Model 3 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 22930])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22930])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.631 /   test loss : 1.265
iteration : 10/500  -  train loss : 0.455 /   test loss : 1.065
iteration : 20/500  -  train loss : 0.35 /   test loss : 0.989
iteration : 30/500  -  train loss : 0.308 /   test loss : 0.958
iteration : 40/500  -  train loss : 0.285 /   test loss : 0.925
iteration : 50/500  -  train loss : 0.268 /   test loss : 0.955
iteration : 60/500  -  train loss : 0.253 /   test loss : 0.943
iteration : 70/500  -  train loss : 0.238 /   test loss : 0.935
iteration : 80/500  -  train loss : 0.223 /   test loss : 0.927
iteration : 90/500  -  train loss : 0.213 /   test loss : 0.938
iteration : 100/500  -  train loss : 0.201 /   test loss : 0.925
iteration : 110/500  -  train loss : 0.194 /   test loss : 0.953
iteration : 120/500  -  train loss : 0.191 /   test loss : 0.952
iteration : 130/500  -  train loss : 0.183 /   test loss : 0.945
iteration : 140/500  -  train loss : 0.182 /   test loss : 0.963
iteration : 150/500  -  train loss : 0.173 /   test loss : 0.946
iteration : 160/500  -  train loss : 0.165 /   test loss : 0.928
iteration : 170/500  -  train loss : 0.154 /   test loss : 0.915
iteration : 180/500  -  train loss : 0.146 /   test loss : 0.918
iteration : 190/500  -  train loss : 0.138 /   test loss : 0.913
iteration : 200/500  -  train loss : 0.134 /   test loss : 0.923
iteration : 210/500  -  train loss : 0.135 /   test loss : 0.925
iteration : 220/500  -  train loss : 0.13 /   test loss : 0.923
iteration : 230/500  -  train loss : 0.123 /   test loss : 0.914
iteration : 240/500  -  train loss : 0.12 /   test loss : 0.915
iteration : 250/500  -  train loss : 0.122 /   test loss : 0.923
iteration : 260/500  -  train loss : 0.114 /   test loss : 0.907
iteration : 270/500  -  train loss : 0.105 /   test loss : 0.896
iteration : 280/500  -  train loss : 0.103 /   test loss : 0.888
iteration : 290/500  -  train loss : 0.105 /   test loss : 0.913
iteration : 300/500  -  train loss : 0.102 /   test loss : 0.913
iteration : 310/500  -  train loss : 0.097 /   test loss : 0.905
iteration : 320/500  -  train loss : 0.095 /   test loss : 0.913
iteration : 330/500  -  train loss : 0.096 /   test loss : 0.91
iteration : 340/500  -  train loss : 0.094 /   test loss : 0.911
iteration : 350/500  -  train loss : 0.092 /   test loss : 0.914
iteration : 360/500  -  train loss : 0.087 /   test loss : 0.92
iteration : 370/500  -  train loss : 0.088 /   test loss : 0.928
iteration : 380/500  -  train loss : 0.085 /   test loss : 0.917
iteration : 390/500  -  train loss : 0.082 /   test loss : 0.9
iteration : 400/500  -  train loss : 0.082 /   test loss : 0.91
iteration : 410/500  -  train loss : 0.082 /   test loss : 0.914
iteration : 420/500  -  train loss : 0.087 /   test loss : 0.929
iteration : 430/500  -  train loss : 0.085 /   test loss : 0.916
iteration : 440/500  -  train loss : 0.079 /   test loss : 0.911
iteration : 450/500  -  train loss : 0.08 /   test loss : 0.913
iteration : 460/500  -  train loss : 0.076 /   test loss : 0.903
iteration : 470/500  -  train loss : 0.074 /   test loss : 0.894
iteration : 480/500  -  train loss : 0.072 /   test loss : 0.9
iteration : 490/500  -  train loss : 0.072 /   test loss : 0.896
iteration : 500/500  -  train loss : 0.073 /   test loss : 0.911

Training complete   //   Running time : 168  ------------


[Gene 2] Model 3 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 22930])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22930])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.779 /   test loss : 0.666
iteration : 10/500  -  train loss : 0.559 /   test loss : 0.527
iteration : 20/500  -  train loss : 0.443 /   test loss : 0.475
iteration : 30/500  -  train loss : 0.382 /   test loss : 0.461
iteration : 40/500  -  train loss : 0.357 /   test loss : 0.46
iteration : 50/500  -  train loss : 0.334 /   test loss : 0.451
iteration : 60/500  -  train loss : 0.311 /   test loss : 0.448
iteration : 70/500  -  train loss : 0.29 /   test loss : 0.447
iteration : 80/500  -  train loss : 0.272 /   test loss : 0.45
iteration : 90/500  -  train loss : 0.259 /   test loss : 0.456
iteration : 100/500  -  train loss : 0.247 /   test loss : 0.458
iteration : 110/500  -  train loss : 0.232 /   test loss : 0.458
iteration : 120/500  -  train loss : 0.22 /   test loss : 0.455
iteration : 130/500  -  train loss : 0.212 /   test loss : 0.449
iteration : 140/500  -  train loss : 0.206 /   test loss : 0.45
iteration : 150/500  -  train loss : 0.197 /   test loss : 0.45
iteration : 160/500  -  train loss : 0.185 /   test loss : 0.44
iteration : 170/500  -  train loss : 0.173 /   test loss : 0.437
iteration : 180/500  -  train loss : 0.162 /   test loss : 0.429
iteration : 190/500  -  train loss : 0.152 /   test loss : 0.43
iteration : 200/500  -  train loss : 0.15 /   test loss : 0.429
iteration : 210/500  -  train loss : 0.152 /   test loss : 0.441
iteration : 220/500  -  train loss : 0.146 /   test loss : 0.447
iteration : 230/500  -  train loss : 0.142 /   test loss : 0.451
iteration : 240/500  -  train loss : 0.139 /   test loss : 0.455
iteration : 250/500  -  train loss : 0.128 /   test loss : 0.45
iteration : 260/500  -  train loss : 0.126 /   test loss : 0.465
iteration : 270/500  -  train loss : 0.124 /   test loss : 0.462
iteration : 280/500  -  train loss : 0.115 /   test loss : 0.452
iteration : 290/500  -  train loss : 0.108 /   test loss : 0.45
iteration : 300/500  -  train loss : 0.116 /   test loss : 0.46
iteration : 310/500  -  train loss : 0.115 /   test loss : 0.463
iteration : 320/500  -  train loss : 0.109 /   test loss : 0.463
iteration : 330/500  -  train loss : 0.109 /   test loss : 0.46
iteration : 340/500  -  train loss : 0.099 /   test loss : 0.456
iteration : 350/500  -  train loss : 0.096 /   test loss : 0.458
iteration : 360/500  -  train loss : 0.093 /   test loss : 0.46
iteration : 370/500  -  train loss : 0.089 /   test loss : 0.456
iteration : 380/500  -  train loss : 0.085 /   test loss : 0.45
iteration : 390/500  -  train loss : 0.087 /   test loss : 0.458
iteration : 400/500  -  train loss : 0.087 /   test loss : 0.461
iteration : 410/500  -  train loss : 0.087 /   test loss : 0.467
iteration : 420/500  -  train loss : 0.091 /   test loss : 0.472
iteration : 430/500  -  train loss : 0.091 /   test loss : 0.472
iteration : 440/500  -  train loss : 0.084 /   test loss : 0.475
iteration : 450/500  -  train loss : 0.087 /   test loss : 0.485
iteration : 460/500  -  train loss : 0.084 /   test loss : 0.481
iteration : 470/500  -  train loss : 0.081 /   test loss : 0.478
iteration : 480/500  -  train loss : 0.077 /   test loss : 0.473
iteration : 490/500  -  train loss : 0.078 /   test loss : 0.467
iteration : 500/500  -  train loss : 0.083 /   test loss : 0.477

Training complete   //   Running time : 168  ------------


[Gene 2] Model 3 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 22930])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22930])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.767 /   test loss : 0.71
iteration : 10/500  -  train loss : 0.56 /   test loss : 0.559
iteration : 20/500  -  train loss : 0.445 /   test loss : 0.487
iteration : 30/500  -  train loss : 0.378 /   test loss : 0.478
iteration : 40/500  -  train loss : 0.35 /   test loss : 0.462
iteration : 50/500  -  train loss : 0.323 /   test loss : 0.473
iteration : 60/500  -  train loss : 0.295 /   test loss : 0.477
iteration : 70/500  -  train loss : 0.283 /   test loss : 0.481
iteration : 80/500  -  train loss : 0.267 /   test loss : 0.472
iteration : 90/500  -  train loss : 0.251 /   test loss : 0.473
iteration : 100/500  -  train loss : 0.236 /   test loss : 0.458
iteration : 110/500  -  train loss : 0.224 /   test loss : 0.462
iteration : 120/500  -  train loss : 0.214 /   test loss : 0.468
iteration : 130/500  -  train loss : 0.205 /   test loss : 0.47
iteration : 140/500  -  train loss : 0.2 /   test loss : 0.466
iteration : 150/500  -  train loss : 0.182 /   test loss : 0.459
iteration : 160/500  -  train loss : 0.17 /   test loss : 0.475
iteration : 170/500  -  train loss : 0.165 /   test loss : 0.469
iteration : 180/500  -  train loss : 0.159 /   test loss : 0.467
iteration : 190/500  -  train loss : 0.156 /   test loss : 0.469
iteration : 200/500  -  train loss : 0.155 /   test loss : 0.469
iteration : 210/500  -  train loss : 0.153 /   test loss : 0.462
iteration : 220/500  -  train loss : 0.143 /   test loss : 0.464
iteration : 230/500  -  train loss : 0.132 /   test loss : 0.46
iteration : 240/500  -  train loss : 0.126 /   test loss : 0.451
iteration : 250/500  -  train loss : 0.124 /   test loss : 0.447
iteration : 260/500  -  train loss : 0.119 /   test loss : 0.449
iteration : 270/500  -  train loss : 0.117 /   test loss : 0.455
iteration : 280/500  -  train loss : 0.11 /   test loss : 0.453
iteration : 290/500  -  train loss : 0.111 /   test loss : 0.45
iteration : 300/500  -  train loss : 0.113 /   test loss : 0.453
iteration : 310/500  -  train loss : 0.106 /   test loss : 0.449
iteration : 320/500  -  train loss : 0.103 /   test loss : 0.45
iteration : 330/500  -  train loss : 0.103 /   test loss : 0.455
iteration : 340/500  -  train loss : 0.104 /   test loss : 0.457
iteration : 350/500  -  train loss : 0.105 /   test loss : 0.453
iteration : 360/500  -  train loss : 0.096 /   test loss : 0.446
iteration : 370/500  -  train loss : 0.092 /   test loss : 0.458
iteration : 380/500  -  train loss : 0.086 /   test loss : 0.446
iteration : 390/500  -  train loss : 0.086 /   test loss : 0.446
iteration : 400/500  -  train loss : 0.089 /   test loss : 0.451
iteration : 410/500  -  train loss : 0.091 /   test loss : 0.453
iteration : 420/500  -  train loss : 0.093 /   test loss : 0.455
iteration : 430/500  -  train loss : 0.098 /   test loss : 0.461
iteration : 440/500  -  train loss : 0.088 /   test loss : 0.455
iteration : 450/500  -  train loss : 0.088 /   test loss : 0.452
iteration : 460/500  -  train loss : 0.093 /   test loss : 0.457
iteration : 470/500  -  train loss : 0.085 /   test loss : 0.451
iteration : 480/500  -  train loss : 0.081 /   test loss : 0.46
iteration : 490/500  -  train loss : 0.079 /   test loss : 0.448
iteration : 500/500  -  train loss : 0.075 /   test loss : 0.449

Training complete   //   Running time : 168  ------------


[Gene 2] Model 3 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([120, 22930])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 22930])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.802 /   test loss : 0.55
iteration : 10/500  -  train loss : 0.576 /   test loss : 0.446
iteration : 20/500  -  train loss : 0.449 /   test loss : 0.399
iteration : 30/500  -  train loss : 0.396 /   test loss : 0.387
iteration : 40/500  -  train loss : 0.367 /   test loss : 0.389
iteration : 50/500  -  train loss : 0.34 /   test loss : 0.387
iteration : 60/500  -  train loss : 0.31 /   test loss : 0.385
iteration : 70/500  -  train loss : 0.295 /   test loss : 0.389
iteration : 80/500  -  train loss : 0.282 /   test loss : 0.385
iteration : 90/500  -  train loss : 0.268 /   test loss : 0.383
iteration : 100/500  -  train loss : 0.252 /   test loss : 0.383
iteration : 110/500  -  train loss : 0.243 /   test loss : 0.389
iteration : 120/500  -  train loss : 0.234 /   test loss : 0.391
iteration : 130/500  -  train loss : 0.223 /   test loss : 0.39
iteration : 140/500  -  train loss : 0.219 /   test loss : 0.394
iteration : 150/500  -  train loss : 0.202 /   test loss : 0.387
iteration : 160/500  -  train loss : 0.187 /   test loss : 0.378
iteration : 170/500  -  train loss : 0.18 /   test loss : 0.375
iteration : 180/500  -  train loss : 0.17 /   test loss : 0.374
iteration : 190/500  -  train loss : 0.166 /   test loss : 0.372
iteration : 200/500  -  train loss : 0.158 /   test loss : 0.371
iteration : 210/500  -  train loss : 0.153 /   test loss : 0.372
iteration : 220/500  -  train loss : 0.146 /   test loss : 0.374
iteration : 230/500  -  train loss : 0.142 /   test loss : 0.376
iteration : 240/500  -  train loss : 0.133 /   test loss : 0.372
iteration : 250/500  -  train loss : 0.142 /   test loss : 0.381
iteration : 260/500  -  train loss : 0.144 /   test loss : 0.386
iteration : 270/500  -  train loss : 0.141 /   test loss : 0.389
iteration : 280/500  -  train loss : 0.131 /   test loss : 0.386
iteration : 290/500  -  train loss : 0.129 /   test loss : 0.383
iteration : 300/500  -  train loss : 0.119 /   test loss : 0.376
iteration : 310/500  -  train loss : 0.114 /   test loss : 0.372
iteration : 320/500  -  train loss : 0.123 /   test loss : 0.38
iteration : 330/500  -  train loss : 0.117 /   test loss : 0.378
iteration : 340/500  -  train loss : 0.115 /   test loss : 0.381
iteration : 350/500  -  train loss : 0.112 /   test loss : 0.381
iteration : 360/500  -  train loss : 0.115 /   test loss : 0.382
iteration : 370/500  -  train loss : 0.108 /   test loss : 0.38
iteration : 380/500  -  train loss : 0.115 /   test loss : 0.384
iteration : 390/500  -  train loss : 0.117 /   test loss : 0.383
iteration : 400/500  -  train loss : 0.11 /   test loss : 0.38
iteration : 410/500  -  train loss : 0.111 /   test loss : 0.385
iteration : 420/500  -  train loss : 0.109 /   test loss : 0.384
iteration : 430/500  -  train loss : 0.106 /   test loss : 0.382
iteration : 440/500  -  train loss : 0.102 /   test loss : 0.382
iteration : 450/500  -  train loss : 0.096 /   test loss : 0.378
iteration : 460/500  -  train loss : 0.095 /   test loss : 0.378
iteration : 470/500  -  train loss : 0.092 /   test loss : 0.381
iteration : 480/500  -  train loss : 0.094 /   test loss : 0.379
iteration : 490/500  -  train loss : 0.097 /   test loss : 0.379
iteration : 500/500  -  train loss : 0.097 /   test loss : 0.378

Training complete   //   Running time : 166  ------------


[Gene 3] Model 3 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 18753])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 18753])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 1.044 /   test loss : 0.392
iteration : 10/500  -  train loss : 0.691 /   test loss : 0.254
iteration : 20/500  -  train loss : 0.508 /   test loss : 0.195
iteration : 30/500  -  train loss : 0.422 /   test loss : 0.173
iteration : 40/500  -  train loss : 0.366 /   test loss : 0.168
iteration : 50/500  -  train loss : 0.324 /   test loss : 0.157
iteration : 60/500  -  train loss : 0.298 /   test loss : 0.149
iteration : 70/500  -  train loss : 0.269 /   test loss : 0.159
iteration : 80/500  -  train loss : 0.251 /   test loss : 0.157
iteration : 90/500  -  train loss : 0.236 /   test loss : 0.163
iteration : 100/500  -  train loss : 0.221 /   test loss : 0.161
iteration : 110/500  -  train loss : 0.203 /   test loss : 0.168
iteration : 120/500  -  train loss : 0.186 /   test loss : 0.165
iteration : 130/500  -  train loss : 0.171 /   test loss : 0.16
iteration : 140/500  -  train loss : 0.165 /   test loss : 0.165
iteration : 150/500  -  train loss : 0.152 /   test loss : 0.165
iteration : 160/500  -  train loss : 0.139 /   test loss : 0.164
iteration : 170/500  -  train loss : 0.13 /   test loss : 0.167
iteration : 180/500  -  train loss : 0.124 /   test loss : 0.159
iteration : 190/500  -  train loss : 0.132 /   test loss : 0.162
iteration : 200/500  -  train loss : 0.124 /   test loss : 0.168
iteration : 210/500  -  train loss : 0.116 /   test loss : 0.17
iteration : 220/500  -  train loss : 0.109 /   test loss : 0.159
iteration : 230/500  -  train loss : 0.105 /   test loss : 0.162
iteration : 240/500  -  train loss : 0.099 /   test loss : 0.164
iteration : 250/500  -  train loss : 0.103 /   test loss : 0.16
iteration : 260/500  -  train loss : 0.094 /   test loss : 0.163
iteration : 270/500  -  train loss : 0.091 /   test loss : 0.16
iteration : 280/500  -  train loss : 0.094 /   test loss : 0.16
iteration : 290/500  -  train loss : 0.093 /   test loss : 0.166
iteration : 300/500  -  train loss : 0.088 /   test loss : 0.166
iteration : 310/500  -  train loss : 0.085 /   test loss : 0.168
iteration : 320/500  -  train loss : 0.08 /   test loss : 0.166
iteration : 330/500  -  train loss : 0.081 /   test loss : 0.165
iteration : 340/500  -  train loss : 0.078 /   test loss : 0.155
iteration : 350/500  -  train loss : 0.077 /   test loss : 0.154
iteration : 360/500  -  train loss : 0.074 /   test loss : 0.159
iteration : 370/500  -  train loss : 0.071 /   test loss : 0.166
iteration : 380/500  -  train loss : 0.063 /   test loss : 0.165
iteration : 390/500  -  train loss : 0.068 /   test loss : 0.16
iteration : 400/500  -  train loss : 0.066 /   test loss : 0.162
iteration : 410/500  -  train loss : 0.065 /   test loss : 0.166
iteration : 420/500  -  train loss : 0.069 /   test loss : 0.16
iteration : 430/500  -  train loss : 0.068 /   test loss : 0.162
iteration : 440/500  -  train loss : 0.063 /   test loss : 0.166
iteration : 450/500  -  train loss : 0.059 /   test loss : 0.164
iteration : 460/500  -  train loss : 0.054 /   test loss : 0.162
iteration : 470/500  -  train loss : 0.048 /   test loss : 0.162
iteration : 480/500  -  train loss : 0.054 /   test loss : 0.158
iteration : 490/500  -  train loss : 0.053 /   test loss : 0.157
iteration : 500/500  -  train loss : 0.052 /   test loss : 0.155

Training complete   //   Running time : 140  ------------


[Gene 3] Model 3 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 18753])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 18753])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.605 /   test loss : 2.179
iteration : 10/500  -  train loss : 0.368 /   test loss : 1.711
iteration : 20/500  -  train loss : 0.259 /   test loss : 1.441
iteration : 30/500  -  train loss : 0.215 /   test loss : 1.338
iteration : 40/500  -  train loss : 0.189 /   test loss : 1.288
iteration : 50/500  -  train loss : 0.17 /   test loss : 1.298
iteration : 60/500  -  train loss : 0.16 /   test loss : 1.299
iteration : 70/500  -  train loss : 0.146 /   test loss : 1.259
iteration : 80/500  -  train loss : 0.14 /   test loss : 1.258
iteration : 90/500  -  train loss : 0.135 /   test loss : 1.262
iteration : 100/500  -  train loss : 0.127 /   test loss : 1.266
iteration : 110/500  -  train loss : 0.12 /   test loss : 1.259
iteration : 120/500  -  train loss : 0.111 /   test loss : 1.245
iteration : 130/500  -  train loss : 0.107 /   test loss : 1.248
iteration : 140/500  -  train loss : 0.104 /   test loss : 1.242
iteration : 150/500  -  train loss : 0.1 /   test loss : 1.246
iteration : 160/500  -  train loss : 0.097 /   test loss : 1.243
iteration : 170/500  -  train loss : 0.092 /   test loss : 1.215
iteration : 180/500  -  train loss : 0.085 /   test loss : 1.192
iteration : 190/500  -  train loss : 0.085 /   test loss : 1.207
iteration : 200/500  -  train loss : 0.08 /   test loss : 1.191
iteration : 210/500  -  train loss : 0.078 /   test loss : 1.191
iteration : 220/500  -  train loss : 0.078 /   test loss : 1.206
iteration : 230/500  -  train loss : 0.074 /   test loss : 1.196
iteration : 240/500  -  train loss : 0.073 /   test loss : 1.214
iteration : 250/500  -  train loss : 0.071 /   test loss : 1.218
iteration : 260/500  -  train loss : 0.069 /   test loss : 1.206
iteration : 270/500  -  train loss : 0.066 /   test loss : 1.192
iteration : 280/500  -  train loss : 0.063 /   test loss : 1.194
iteration : 290/500  -  train loss : 0.062 /   test loss : 1.189
iteration : 300/500  -  train loss : 0.06 /   test loss : 1.175
iteration : 310/500  -  train loss : 0.058 /   test loss : 1.158
iteration : 320/500  -  train loss : 0.057 /   test loss : 1.151
iteration : 330/500  -  train loss : 0.058 /   test loss : 1.162
iteration : 340/500  -  train loss : 0.058 /   test loss : 1.163
iteration : 350/500  -  train loss : 0.061 /   test loss : 1.174
iteration : 360/500  -  train loss : 0.055 /   test loss : 1.143
iteration : 370/500  -  train loss : 0.049 /   test loss : 1.115
iteration : 380/500  -  train loss : 0.047 /   test loss : 1.103
iteration : 390/500  -  train loss : 0.045 /   test loss : 1.098
iteration : 400/500  -  train loss : 0.044 /   test loss : 1.102
iteration : 410/500  -  train loss : 0.045 /   test loss : 1.109
iteration : 420/500  -  train loss : 0.046 /   test loss : 1.123
iteration : 430/500  -  train loss : 0.048 /   test loss : 1.138
iteration : 440/500  -  train loss : 0.048 /   test loss : 1.148
iteration : 450/500  -  train loss : 0.046 /   test loss : 1.135
iteration : 460/500  -  train loss : 0.042 /   test loss : 1.101
iteration : 470/500  -  train loss : 0.039 /   test loss : 1.091
iteration : 480/500  -  train loss : 0.046 /   test loss : 1.131
iteration : 490/500  -  train loss : 0.045 /   test loss : 1.134
iteration : 500/500  -  train loss : 0.041 /   test loss : 1.116

Training complete   //   Running time : 138  ------------


[Gene 3] Model 3 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 18753])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 18753])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 1.03 /   test loss : 0.44
iteration : 10/500  -  train loss : 0.681 /   test loss : 0.349
iteration : 20/500  -  train loss : 0.476 /   test loss : 0.299
iteration : 30/500  -  train loss : 0.393 /   test loss : 0.286
iteration : 40/500  -  train loss : 0.342 /   test loss : 0.276
iteration : 50/500  -  train loss : 0.31 /   test loss : 0.268
iteration : 60/500  -  train loss : 0.288 /   test loss : 0.264
iteration : 70/500  -  train loss : 0.26 /   test loss : 0.266
iteration : 80/500  -  train loss : 0.243 /   test loss : 0.268
iteration : 90/500  -  train loss : 0.226 /   test loss : 0.268
iteration : 100/500  -  train loss : 0.207 /   test loss : 0.266
iteration : 110/500  -  train loss : 0.192 /   test loss : 0.263
iteration : 120/500  -  train loss : 0.179 /   test loss : 0.261
iteration : 130/500  -  train loss : 0.166 /   test loss : 0.259
iteration : 140/500  -  train loss : 0.153 /   test loss : 0.258
iteration : 150/500  -  train loss : 0.139 /   test loss : 0.256
iteration : 160/500  -  train loss : 0.136 /   test loss : 0.259
iteration : 170/500  -  train loss : 0.129 /   test loss : 0.261
iteration : 180/500  -  train loss : 0.117 /   test loss : 0.259
iteration : 190/500  -  train loss : 0.114 /   test loss : 0.262
iteration : 200/500  -  train loss : 0.11 /   test loss : 0.262
iteration : 210/500  -  train loss : 0.108 /   test loss : 0.261
iteration : 220/500  -  train loss : 0.102 /   test loss : 0.261
iteration : 230/500  -  train loss : 0.096 /   test loss : 0.261
iteration : 240/500  -  train loss : 0.091 /   test loss : 0.264
iteration : 250/500  -  train loss : 0.087 /   test loss : 0.261
iteration : 260/500  -  train loss : 0.087 /   test loss : 0.26
iteration : 270/500  -  train loss : 0.086 /   test loss : 0.258
iteration : 280/500  -  train loss : 0.089 /   test loss : 0.259
iteration : 290/500  -  train loss : 0.082 /   test loss : 0.258
iteration : 300/500  -  train loss : 0.073 /   test loss : 0.258
iteration : 310/500  -  train loss : 0.067 /   test loss : 0.256
iteration : 320/500  -  train loss : 0.063 /   test loss : 0.257
iteration : 330/500  -  train loss : 0.07 /   test loss : 0.263
iteration : 340/500  -  train loss : 0.069 /   test loss : 0.263
iteration : 350/500  -  train loss : 0.072 /   test loss : 0.264
iteration : 360/500  -  train loss : 0.07 /   test loss : 0.261
iteration : 370/500  -  train loss : 0.059 /   test loss : 0.26
iteration : 380/500  -  train loss : 0.059 /   test loss : 0.263
iteration : 390/500  -  train loss : 0.057 /   test loss : 0.265
iteration : 400/500  -  train loss : 0.055 /   test loss : 0.261
iteration : 410/500  -  train loss : 0.055 /   test loss : 0.262
iteration : 420/500  -  train loss : 0.056 /   test loss : 0.261
iteration : 430/500  -  train loss : 0.054 /   test loss : 0.258
iteration : 440/500  -  train loss : 0.055 /   test loss : 0.26
iteration : 450/500  -  train loss : 0.051 /   test loss : 0.259
iteration : 460/500  -  train loss : 0.049 /   test loss : 0.256
iteration : 470/500  -  train loss : 0.046 /   test loss : 0.257
iteration : 480/500  -  train loss : 0.054 /   test loss : 0.261
iteration : 490/500  -  train loss : 0.052 /   test loss : 0.259
iteration : 500/500  -  train loss : 0.052 /   test loss : 0.26

Training complete   //   Running time : 139  ------------


[Gene 3] Model 3 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 18753])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 18753])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.88 /   test loss : 1.048
iteration : 10/500  -  train loss : 0.61 /   test loss : 0.735
iteration : 20/500  -  train loss : 0.447 /   test loss : 0.522
iteration : 30/500  -  train loss : 0.38 /   test loss : 0.479
iteration : 40/500  -  train loss : 0.333 /   test loss : 0.434
iteration : 50/500  -  train loss : 0.297 /   test loss : 0.419
iteration : 60/500  -  train loss : 0.279 /   test loss : 0.419
iteration : 70/500  -  train loss : 0.259 /   test loss : 0.402
iteration : 80/500  -  train loss : 0.244 /   test loss : 0.408
iteration : 90/500  -  train loss : 0.226 /   test loss : 0.399
iteration : 100/500  -  train loss : 0.206 /   test loss : 0.394
iteration : 110/500  -  train loss : 0.193 /   test loss : 0.391
iteration : 120/500  -  train loss : 0.185 /   test loss : 0.385
iteration : 130/500  -  train loss : 0.169 /   test loss : 0.374
iteration : 140/500  -  train loss : 0.155 /   test loss : 0.375
iteration : 150/500  -  train loss : 0.141 /   test loss : 0.368
iteration : 160/500  -  train loss : 0.132 /   test loss : 0.363
iteration : 170/500  -  train loss : 0.126 /   test loss : 0.363
iteration : 180/500  -  train loss : 0.114 /   test loss : 0.356
iteration : 190/500  -  train loss : 0.106 /   test loss : 0.354
iteration : 200/500  -  train loss : 0.096 /   test loss : 0.348
iteration : 210/500  -  train loss : 0.092 /   test loss : 0.349
iteration : 220/500  -  train loss : 0.094 /   test loss : 0.354
iteration : 230/500  -  train loss : 0.092 /   test loss : 0.356
iteration : 240/500  -  train loss : 0.085 /   test loss : 0.35
iteration : 250/500  -  train loss : 0.082 /   test loss : 0.353
iteration : 260/500  -  train loss : 0.082 /   test loss : 0.353
iteration : 270/500  -  train loss : 0.079 /   test loss : 0.35
iteration : 280/500  -  train loss : 0.084 /   test loss : 0.356
iteration : 290/500  -  train loss : 0.085 /   test loss : 0.358
iteration : 300/500  -  train loss : 0.08 /   test loss : 0.353
iteration : 310/500  -  train loss : 0.075 /   test loss : 0.353
iteration : 320/500  -  train loss : 0.075 /   test loss : 0.358
iteration : 330/500  -  train loss : 0.081 /   test loss : 0.365
iteration : 340/500  -  train loss : 0.075 /   test loss : 0.357
iteration : 350/500  -  train loss : 0.072 /   test loss : 0.353
iteration : 360/500  -  train loss : 0.074 /   test loss : 0.354
iteration : 370/500  -  train loss : 0.069 /   test loss : 0.346
iteration : 380/500  -  train loss : 0.075 /   test loss : 0.358
iteration : 390/500  -  train loss : 0.07 /   test loss : 0.356
iteration : 400/500  -  train loss : 0.066 /   test loss : 0.355
iteration : 410/500  -  train loss : 0.064 /   test loss : 0.352
iteration : 420/500  -  train loss : 0.056 /   test loss : 0.347
iteration : 430/500  -  train loss : 0.053 /   test loss : 0.345
iteration : 440/500  -  train loss : 0.057 /   test loss : 0.344
iteration : 450/500  -  train loss : 0.058 /   test loss : 0.343
iteration : 460/500  -  train loss : 0.056 /   test loss : 0.339
iteration : 470/500  -  train loss : 0.05 /   test loss : 0.333
iteration : 480/500  -  train loss : 0.057 /   test loss : 0.341
iteration : 490/500  -  train loss : 0.055 /   test loss : 0.337
iteration : 500/500  -  train loss : 0.051 /   test loss : 0.334

Training complete   //   Running time : 138  ------------


[Gene 3] Model 3 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([120, 18753])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 18753])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 1.011 /   test loss : 0.569
iteration : 10/500  -  train loss : 0.656 /   test loss : 0.374
iteration : 20/500  -  train loss : 0.506 /   test loss : 0.304
iteration : 30/500  -  train loss : 0.421 /   test loss : 0.276
iteration : 40/500  -  train loss : 0.371 /   test loss : 0.265
iteration : 50/500  -  train loss : 0.329 /   test loss : 0.248
iteration : 60/500  -  train loss : 0.295 /   test loss : 0.232
iteration : 70/500  -  train loss : 0.277 /   test loss : 0.232
iteration : 80/500  -  train loss : 0.254 /   test loss : 0.234
iteration : 90/500  -  train loss : 0.235 /   test loss : 0.227
iteration : 100/500  -  train loss : 0.215 /   test loss : 0.22
iteration : 110/500  -  train loss : 0.199 /   test loss : 0.224
iteration : 120/500  -  train loss : 0.182 /   test loss : 0.224
iteration : 130/500  -  train loss : 0.168 /   test loss : 0.215
iteration : 140/500  -  train loss : 0.161 /   test loss : 0.219
iteration : 150/500  -  train loss : 0.161 /   test loss : 0.222
iteration : 160/500  -  train loss : 0.149 /   test loss : 0.224
iteration : 170/500  -  train loss : 0.135 /   test loss : 0.22
iteration : 180/500  -  train loss : 0.125 /   test loss : 0.217
iteration : 190/500  -  train loss : 0.121 /   test loss : 0.219
iteration : 200/500  -  train loss : 0.114 /   test loss : 0.218
iteration : 210/500  -  train loss : 0.103 /   test loss : 0.21
iteration : 220/500  -  train loss : 0.095 /   test loss : 0.208
iteration : 230/500  -  train loss : 0.091 /   test loss : 0.208
iteration : 240/500  -  train loss : 0.087 /   test loss : 0.211
iteration : 250/500  -  train loss : 0.09 /   test loss : 0.218
iteration : 260/500  -  train loss : 0.089 /   test loss : 0.221
iteration : 270/500  -  train loss : 0.085 /   test loss : 0.218
iteration : 280/500  -  train loss : 0.08 /   test loss : 0.212
iteration : 290/500  -  train loss : 0.082 /   test loss : 0.218
iteration : 300/500  -  train loss : 0.074 /   test loss : 0.22
iteration : 310/500  -  train loss : 0.072 /   test loss : 0.223
iteration : 320/500  -  train loss : 0.068 /   test loss : 0.219
iteration : 330/500  -  train loss : 0.069 /   test loss : 0.22
iteration : 340/500  -  train loss : 0.071 /   test loss : 0.221
iteration : 350/500  -  train loss : 0.066 /   test loss : 0.22
iteration : 360/500  -  train loss : 0.063 /   test loss : 0.217
iteration : 370/500  -  train loss : 0.061 /   test loss : 0.221
iteration : 380/500  -  train loss : 0.062 /   test loss : 0.221
iteration : 390/500  -  train loss : 0.062 /   test loss : 0.223
iteration : 400/500  -  train loss : 0.063 /   test loss : 0.224
iteration : 410/500  -  train loss : 0.064 /   test loss : 0.226
iteration : 420/500  -  train loss : 0.064 /   test loss : 0.227
iteration : 430/500  -  train loss : 0.064 /   test loss : 0.226
iteration : 440/500  -  train loss : 0.061 /   test loss : 0.222
iteration : 450/500  -  train loss : 0.061 /   test loss : 0.222
iteration : 460/500  -  train loss : 0.062 /   test loss : 0.22
iteration : 470/500  -  train loss : 0.061 /   test loss : 0.217
iteration : 480/500  -  train loss : 0.057 /   test loss : 0.219
iteration : 490/500  -  train loss : 0.058 /   test loss : 0.223
iteration : 500/500  -  train loss : 0.055 /   test loss : 0.221

Training complete   //   Running time : 137  ------------


[Gene 4] Model 3 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 23718])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23718])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.693 /   test loss : 0.328
iteration : 10/500  -  train loss : 0.589 /   test loss : 0.281
iteration : 20/500  -  train loss : 0.503 /   test loss : 0.279
iteration : 30/500  -  train loss : 0.46 /   test loss : 0.276
iteration : 40/500  -  train loss : 0.437 /   test loss : 0.268
iteration : 50/500  -  train loss : 0.414 /   test loss : 0.266
iteration : 60/500  -  train loss : 0.398 /   test loss : 0.269
iteration : 70/500  -  train loss : 0.384 /   test loss : 0.275
iteration : 80/500  -  train loss : 0.374 /   test loss : 0.276
iteration : 90/500  -  train loss : 0.363 /   test loss : 0.279
iteration : 100/500  -  train loss : 0.346 /   test loss : 0.275
iteration : 110/500  -  train loss : 0.332 /   test loss : 0.271
iteration : 120/500  -  train loss : 0.318 /   test loss : 0.272
iteration : 130/500  -  train loss : 0.304 /   test loss : 0.269
iteration : 140/500  -  train loss : 0.293 /   test loss : 0.279
iteration : 150/500  -  train loss : 0.281 /   test loss : 0.275
iteration : 160/500  -  train loss : 0.265 /   test loss : 0.265
iteration : 170/500  -  train loss : 0.251 /   test loss : 0.27
iteration : 180/500  -  train loss : 0.237 /   test loss : 0.268
iteration : 190/500  -  train loss : 0.225 /   test loss : 0.264
iteration : 200/500  -  train loss : 0.216 /   test loss : 0.268
iteration : 210/500  -  train loss : 0.204 /   test loss : 0.265
iteration : 220/500  -  train loss : 0.193 /   test loss : 0.257
iteration : 230/500  -  train loss : 0.188 /   test loss : 0.261
iteration : 240/500  -  train loss : 0.178 /   test loss : 0.261
iteration : 250/500  -  train loss : 0.166 /   test loss : 0.262
iteration : 260/500  -  train loss : 0.156 /   test loss : 0.263
iteration : 270/500  -  train loss : 0.15 /   test loss : 0.269
iteration : 280/500  -  train loss : 0.143 /   test loss : 0.267
iteration : 290/500  -  train loss : 0.138 /   test loss : 0.267
iteration : 300/500  -  train loss : 0.133 /   test loss : 0.267
iteration : 310/500  -  train loss : 0.129 /   test loss : 0.267
iteration : 320/500  -  train loss : 0.126 /   test loss : 0.262
iteration : 330/500  -  train loss : 0.127 /   test loss : 0.263
iteration : 340/500  -  train loss : 0.128 /   test loss : 0.265
iteration : 350/500  -  train loss : 0.12 /   test loss : 0.264
iteration : 360/500  -  train loss : 0.111 /   test loss : 0.265
iteration : 370/500  -  train loss : 0.114 /   test loss : 0.265
iteration : 380/500  -  train loss : 0.114 /   test loss : 0.258
iteration : 390/500  -  train loss : 0.113 /   test loss : 0.263
iteration : 400/500  -  train loss : 0.112 /   test loss : 0.262
iteration : 410/500  -  train loss : 0.11 /   test loss : 0.267
iteration : 420/500  -  train loss : 0.103 /   test loss : 0.265
iteration : 430/500  -  train loss : 0.102 /   test loss : 0.268
iteration : 440/500  -  train loss : 0.101 /   test loss : 0.261
iteration : 450/500  -  train loss : 0.102 /   test loss : 0.266
iteration : 460/500  -  train loss : 0.098 /   test loss : 0.27
iteration : 470/500  -  train loss : 0.09 /   test loss : 0.263
iteration : 480/500  -  train loss : 0.091 /   test loss : 0.265
iteration : 490/500  -  train loss : 0.095 /   test loss : 0.266
iteration : 500/500  -  train loss : 0.096 /   test loss : 0.267

Training complete   //   Running time : 178  ------------


[Gene 4] Model 3 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 23718])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23718])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.526 /   test loss : 1.016
iteration : 10/500  -  train loss : 0.426 /   test loss : 0.993
iteration : 20/500  -  train loss : 0.362 /   test loss : 0.978
iteration : 30/500  -  train loss : 0.324 /   test loss : 0.978
iteration : 40/500  -  train loss : 0.305 /   test loss : 0.983
iteration : 50/500  -  train loss : 0.291 /   test loss : 0.98
iteration : 60/500  -  train loss : 0.286 /   test loss : 0.988
iteration : 70/500  -  train loss : 0.28 /   test loss : 0.993
iteration : 80/500  -  train loss : 0.273 /   test loss : 0.982
iteration : 90/500  -  train loss : 0.264 /   test loss : 0.975
iteration : 100/500  -  train loss : 0.255 /   test loss : 0.971
iteration : 110/500  -  train loss : 0.247 /   test loss : 0.968
iteration : 120/500  -  train loss : 0.235 /   test loss : 0.97
iteration : 130/500  -  train loss : 0.226 /   test loss : 0.966
iteration : 140/500  -  train loss : 0.217 /   test loss : 0.962
iteration : 150/500  -  train loss : 0.207 /   test loss : 0.957
iteration : 160/500  -  train loss : 0.203 /   test loss : 0.953
iteration : 170/500  -  train loss : 0.193 /   test loss : 0.961
iteration : 180/500  -  train loss : 0.186 /   test loss : 0.971
iteration : 190/500  -  train loss : 0.176 /   test loss : 0.961
iteration : 200/500  -  train loss : 0.172 /   test loss : 0.958
iteration : 210/500  -  train loss : 0.166 /   test loss : 0.961
iteration : 220/500  -  train loss : 0.161 /   test loss : 0.956
iteration : 230/500  -  train loss : 0.158 /   test loss : 0.96
iteration : 240/500  -  train loss : 0.155 /   test loss : 0.952
iteration : 250/500  -  train loss : 0.147 /   test loss : 0.948
iteration : 260/500  -  train loss : 0.143 /   test loss : 0.954
iteration : 270/500  -  train loss : 0.133 /   test loss : 0.952
iteration : 280/500  -  train loss : 0.127 /   test loss : 0.945
iteration : 290/500  -  train loss : 0.125 /   test loss : 0.942
iteration : 300/500  -  train loss : 0.121 /   test loss : 0.933
iteration : 310/500  -  train loss : 0.122 /   test loss : 0.938
iteration : 320/500  -  train loss : 0.122 /   test loss : 0.935
iteration : 330/500  -  train loss : 0.121 /   test loss : 0.936
iteration : 340/500  -  train loss : 0.115 /   test loss : 0.936
iteration : 350/500  -  train loss : 0.113 /   test loss : 0.931
iteration : 360/500  -  train loss : 0.11 /   test loss : 0.934
iteration : 370/500  -  train loss : 0.112 /   test loss : 0.933
iteration : 380/500  -  train loss : 0.105 /   test loss : 0.928
iteration : 390/500  -  train loss : 0.098 /   test loss : 0.926
iteration : 400/500  -  train loss : 0.096 /   test loss : 0.928
iteration : 410/500  -  train loss : 0.097 /   test loss : 0.932
iteration : 420/500  -  train loss : 0.098 /   test loss : 0.928
iteration : 430/500  -  train loss : 0.098 /   test loss : 0.928
iteration : 440/500  -  train loss : 0.094 /   test loss : 0.924
iteration : 450/500  -  train loss : 0.088 /   test loss : 0.928
iteration : 460/500  -  train loss : 0.089 /   test loss : 0.935
iteration : 470/500  -  train loss : 0.086 /   test loss : 0.929
iteration : 480/500  -  train loss : 0.085 /   test loss : 0.925
iteration : 490/500  -  train loss : 0.087 /   test loss : 0.929
iteration : 500/500  -  train loss : 0.089 /   test loss : 0.922

Training complete   //   Running time : 173  ------------


[Gene 4] Model 3 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 23718])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23718])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.624 /   test loss : 0.591
iteration : 10/500  -  train loss : 0.521 /   test loss : 0.581
iteration : 20/500  -  train loss : 0.453 /   test loss : 0.558
iteration : 30/500  -  train loss : 0.418 /   test loss : 0.544
iteration : 40/500  -  train loss : 0.391 /   test loss : 0.527
iteration : 50/500  -  train loss : 0.374 /   test loss : 0.519
iteration : 60/500  -  train loss : 0.366 /   test loss : 0.527
iteration : 70/500  -  train loss : 0.352 /   test loss : 0.522
iteration : 80/500  -  train loss : 0.337 /   test loss : 0.525
iteration : 90/500  -  train loss : 0.323 /   test loss : 0.524
iteration : 100/500  -  train loss : 0.309 /   test loss : 0.526
iteration : 110/500  -  train loss : 0.295 /   test loss : 0.518
iteration : 120/500  -  train loss : 0.281 /   test loss : 0.516
iteration : 130/500  -  train loss : 0.27 /   test loss : 0.505
iteration : 140/500  -  train loss : 0.261 /   test loss : 0.509
iteration : 150/500  -  train loss : 0.249 /   test loss : 0.501
iteration : 160/500  -  train loss : 0.234 /   test loss : 0.518
iteration : 170/500  -  train loss : 0.223 /   test loss : 0.509
iteration : 180/500  -  train loss : 0.212 /   test loss : 0.497
iteration : 190/500  -  train loss : 0.205 /   test loss : 0.506
iteration : 200/500  -  train loss : 0.202 /   test loss : 0.508
iteration : 210/500  -  train loss : 0.194 /   test loss : 0.508
iteration : 220/500  -  train loss : 0.184 /   test loss : 0.505
iteration : 230/500  -  train loss : 0.176 /   test loss : 0.5
iteration : 240/500  -  train loss : 0.166 /   test loss : 0.503
iteration : 250/500  -  train loss : 0.159 /   test loss : 0.499
iteration : 260/500  -  train loss : 0.153 /   test loss : 0.489
iteration : 270/500  -  train loss : 0.143 /   test loss : 0.491
iteration : 280/500  -  train loss : 0.135 /   test loss : 0.489
iteration : 290/500  -  train loss : 0.133 /   test loss : 0.495
iteration : 300/500  -  train loss : 0.128 /   test loss : 0.492
iteration : 310/500  -  train loss : 0.128 /   test loss : 0.497
iteration : 320/500  -  train loss : 0.123 /   test loss : 0.493
iteration : 330/500  -  train loss : 0.122 /   test loss : 0.491
iteration : 340/500  -  train loss : 0.12 /   test loss : 0.482
iteration : 350/500  -  train loss : 0.114 /   test loss : 0.485
iteration : 360/500  -  train loss : 0.11 /   test loss : 0.492
iteration : 370/500  -  train loss : 0.111 /   test loss : 0.488
iteration : 380/500  -  train loss : 0.109 /   test loss : 0.492
iteration : 390/500  -  train loss : 0.106 /   test loss : 0.485
iteration : 400/500  -  train loss : 0.106 /   test loss : 0.49
iteration : 410/500  -  train loss : 0.108 /   test loss : 0.488
iteration : 420/500  -  train loss : 0.101 /   test loss : 0.48
iteration : 430/500  -  train loss : 0.097 /   test loss : 0.476
iteration : 440/500  -  train loss : 0.089 /   test loss : 0.479
iteration : 450/500  -  train loss : 0.085 /   test loss : 0.479
iteration : 460/500  -  train loss : 0.088 /   test loss : 0.48
iteration : 470/500  -  train loss : 0.089 /   test loss : 0.483
iteration : 480/500  -  train loss : 0.087 /   test loss : 0.48
iteration : 490/500  -  train loss : 0.088 /   test loss : 0.481
iteration : 500/500  -  train loss : 0.086 /   test loss : 0.482

Training complete   //   Running time : 174  ------------


[Gene 4] Model 3 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 23718])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 23718])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.56 /   test loss : 0.858
iteration : 10/500  -  train loss : 0.466 /   test loss : 0.803
iteration : 20/500  -  train loss : 0.407 /   test loss : 0.831
iteration : 30/500  -  train loss : 0.376 /   test loss : 0.798
iteration : 40/500  -  train loss : 0.351 /   test loss : 0.842
iteration : 50/500  -  train loss : 0.333 /   test loss : 0.813
iteration : 60/500  -  train loss : 0.32 /   test loss : 0.796
iteration : 70/500  -  train loss : 0.305 /   test loss : 0.785
iteration : 80/500  -  train loss : 0.291 /   test loss : 0.789
iteration : 90/500  -  train loss : 0.275 /   test loss : 0.788
iteration : 100/500  -  train loss : 0.264 /   test loss : 0.794
iteration : 110/500  -  train loss : 0.248 /   test loss : 0.79
iteration : 120/500  -  train loss : 0.237 /   test loss : 0.792
iteration : 130/500  -  train loss : 0.229 /   test loss : 0.783
iteration : 140/500  -  train loss : 0.222 /   test loss : 0.793
iteration : 150/500  -  train loss : 0.213 /   test loss : 0.8
iteration : 160/500  -  train loss : 0.198 /   test loss : 0.796
iteration : 170/500  -  train loss : 0.194 /   test loss : 0.802
iteration : 180/500  -  train loss : 0.184 /   test loss : 0.798
iteration : 190/500  -  train loss : 0.175 /   test loss : 0.791
iteration : 200/500  -  train loss : 0.167 /   test loss : 0.802
iteration : 210/500  -  train loss : 0.157 /   test loss : 0.795
iteration : 220/500  -  train loss : 0.146 /   test loss : 0.807
iteration : 230/500  -  train loss : 0.141 /   test loss : 0.795
iteration : 240/500  -  train loss : 0.136 /   test loss : 0.781
iteration : 250/500  -  train loss : 0.132 /   test loss : 0.783
iteration : 260/500  -  train loss : 0.129 /   test loss : 0.787
iteration : 270/500  -  train loss : 0.121 /   test loss : 0.779
iteration : 280/500  -  train loss : 0.116 /   test loss : 0.784
iteration : 290/500  -  train loss : 0.115 /   test loss : 0.785
iteration : 300/500  -  train loss : 0.11 /   test loss : 0.8
iteration : 310/500  -  train loss : 0.113 /   test loss : 0.79
iteration : 320/500  -  train loss : 0.104 /   test loss : 0.779
iteration : 330/500  -  train loss : 0.098 /   test loss : 0.778
iteration : 340/500  -  train loss : 0.101 /   test loss : 0.791
iteration : 350/500  -  train loss : 0.106 /   test loss : 0.789
iteration : 360/500  -  train loss : 0.101 /   test loss : 0.794
iteration : 370/500  -  train loss : 0.099 /   test loss : 0.798
iteration : 380/500  -  train loss : 0.097 /   test loss : 0.79
iteration : 390/500  -  train loss : 0.093 /   test loss : 0.775
iteration : 400/500  -  train loss : 0.089 /   test loss : 0.781
iteration : 410/500  -  train loss : 0.089 /   test loss : 0.783
iteration : 420/500  -  train loss : 0.084 /   test loss : 0.785
iteration : 430/500  -  train loss : 0.083 /   test loss : 0.788
iteration : 440/500  -  train loss : 0.08 /   test loss : 0.784
iteration : 450/500  -  train loss : 0.078 /   test loss : 0.785
iteration : 460/500  -  train loss : 0.076 /   test loss : 0.79
iteration : 470/500  -  train loss : 0.071 /   test loss : 0.782
iteration : 480/500  -  train loss : 0.067 /   test loss : 0.779
iteration : 490/500  -  train loss : 0.07 /   test loss : 0.787
iteration : 500/500  -  train loss : 0.073 /   test loss : 0.788

Training complete   //   Running time : 174  ------------


[Gene 4] Model 3 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([120, 23718])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 23718])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.686 /   test loss : 0.37
iteration : 10/500  -  train loss : 0.566 /   test loss : 0.343
iteration : 20/500  -  train loss : 0.496 /   test loss : 0.314
iteration : 30/500  -  train loss : 0.455 /   test loss : 0.307
iteration : 40/500  -  train loss : 0.431 /   test loss : 0.306
iteration : 50/500  -  train loss : 0.415 /   test loss : 0.315
iteration : 60/500  -  train loss : 0.4 /   test loss : 0.315
iteration : 70/500  -  train loss : 0.388 /   test loss : 0.312
iteration : 80/500  -  train loss : 0.376 /   test loss : 0.317
iteration : 90/500  -  train loss : 0.359 /   test loss : 0.315
iteration : 100/500  -  train loss : 0.344 /   test loss : 0.317
iteration : 110/500  -  train loss : 0.337 /   test loss : 0.308
iteration : 120/500  -  train loss : 0.317 /   test loss : 0.31
iteration : 130/500  -  train loss : 0.301 /   test loss : 0.309
iteration : 140/500  -  train loss : 0.291 /   test loss : 0.304
iteration : 150/500  -  train loss : 0.275 /   test loss : 0.304
iteration : 160/500  -  train loss : 0.256 /   test loss : 0.301
iteration : 170/500  -  train loss : 0.246 /   test loss : 0.296
iteration : 180/500  -  train loss : 0.243 /   test loss : 0.293
iteration : 190/500  -  train loss : 0.235 /   test loss : 0.295
iteration : 200/500  -  train loss : 0.222 /   test loss : 0.295
iteration : 210/500  -  train loss : 0.212 /   test loss : 0.296
iteration : 220/500  -  train loss : 0.207 /   test loss : 0.293
iteration : 230/500  -  train loss : 0.198 /   test loss : 0.293
iteration : 240/500  -  train loss : 0.189 /   test loss : 0.294
iteration : 250/500  -  train loss : 0.18 /   test loss : 0.29
iteration : 260/500  -  train loss : 0.169 /   test loss : 0.292
iteration : 270/500  -  train loss : 0.166 /   test loss : 0.29
iteration : 280/500  -  train loss : 0.169 /   test loss : 0.296
iteration : 290/500  -  train loss : 0.163 /   test loss : 0.299
iteration : 300/500  -  train loss : 0.15 /   test loss : 0.292
iteration : 310/500  -  train loss : 0.146 /   test loss : 0.285
iteration : 320/500  -  train loss : 0.145 /   test loss : 0.288
iteration : 330/500  -  train loss : 0.139 /   test loss : 0.293
iteration : 340/500  -  train loss : 0.134 /   test loss : 0.291
iteration : 350/500  -  train loss : 0.127 /   test loss : 0.289
iteration : 360/500  -  train loss : 0.13 /   test loss : 0.292
iteration : 370/500  -  train loss : 0.13 /   test loss : 0.287
iteration : 380/500  -  train loss : 0.126 /   test loss : 0.286
iteration : 390/500  -  train loss : 0.124 /   test loss : 0.289
iteration : 400/500  -  train loss : 0.118 /   test loss : 0.286
iteration : 410/500  -  train loss : 0.117 /   test loss : 0.287
iteration : 420/500  -  train loss : 0.116 /   test loss : 0.285
iteration : 430/500  -  train loss : 0.109 /   test loss : 0.284
iteration : 440/500  -  train loss : 0.105 /   test loss : 0.285
iteration : 450/500  -  train loss : 0.105 /   test loss : 0.285
iteration : 460/500  -  train loss : 0.1 /   test loss : 0.287
iteration : 470/500  -  train loss : 0.101 /   test loss : 0.286
iteration : 480/500  -  train loss : 0.102 /   test loss : 0.287
iteration : 490/500  -  train loss : 0.099 /   test loss : 0.285
iteration : 500/500  -  train loss : 0.101 /   test loss : 0.285

Training complete   //   Running time : 171  ------------


[Gene 5] Model 3 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 21013])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 21013])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.877 /   test loss : 1.779
iteration : 10/500  -  train loss : 0.506 /   test loss : 1.163
iteration : 20/500  -  train loss : 0.424 /   test loss : 0.903
iteration : 30/500  -  train loss : 0.391 /   test loss : 0.949
iteration : 40/500  -  train loss : 0.388 /   test loss : 0.999
iteration : 50/500  -  train loss : 0.383 /   test loss : 1.05
iteration : 60/500  -  train loss : 0.355 /   test loss : 0.951
iteration : 70/500  -  train loss : 0.346 /   test loss : 1.005
iteration : 80/500  -  train loss : 0.331 /   test loss : 0.984
iteration : 90/500  -  train loss : 0.321 /   test loss : 1.014
iteration : 100/500  -  train loss : 0.318 /   test loss : 1.031
iteration : 110/500  -  train loss : 0.316 /   test loss : 1.058
iteration : 120/500  -  train loss : 0.314 /   test loss : 1.058
iteration : 130/500  -  train loss : 0.296 /   test loss : 1.05
iteration : 140/500  -  train loss : 0.278 /   test loss : 1.018
iteration : 150/500  -  train loss : 0.274 /   test loss : 1.029
iteration : 160/500  -  train loss : 0.264 /   test loss : 1.023
iteration : 170/500  -  train loss : 0.252 /   test loss : 1.009
iteration : 180/500  -  train loss : 0.241 /   test loss : 1.009
iteration : 190/500  -  train loss : 0.234 /   test loss : 1.019
iteration : 200/500  -  train loss : 0.22 /   test loss : 0.998
iteration : 210/500  -  train loss : 0.211 /   test loss : 1.004
iteration : 220/500  -  train loss : 0.204 /   test loss : 1.008
iteration : 230/500  -  train loss : 0.198 /   test loss : 1.009
iteration : 240/500  -  train loss : 0.192 /   test loss : 1.022
iteration : 250/500  -  train loss : 0.184 /   test loss : 1.022
iteration : 260/500  -  train loss : 0.177 /   test loss : 1.012
iteration : 270/500  -  train loss : 0.17 /   test loss : 1.018
iteration : 280/500  -  train loss : 0.165 /   test loss : 1.042
iteration : 290/500  -  train loss : 0.163 /   test loss : 1.05
iteration : 300/500  -  train loss : 0.156 /   test loss : 1.049
iteration : 310/500  -  train loss : 0.149 /   test loss : 1.039
iteration : 320/500  -  train loss : 0.14 /   test loss : 1.038
iteration : 330/500  -  train loss : 0.137 /   test loss : 1.038
iteration : 340/500  -  train loss : 0.139 /   test loss : 1.064
iteration : 350/500  -  train loss : 0.137 /   test loss : 1.077
iteration : 360/500  -  train loss : 0.132 /   test loss : 1.072
iteration : 370/500  -  train loss : 0.122 /   test loss : 1.056
iteration : 380/500  -  train loss : 0.122 /   test loss : 1.058
iteration : 390/500  -  train loss : 0.123 /   test loss : 1.081
iteration : 400/500  -  train loss : 0.127 /   test loss : 1.092
iteration : 410/500  -  train loss : 0.118 /   test loss : 1.079
iteration : 420/500  -  train loss : 0.111 /   test loss : 1.073
iteration : 430/500  -  train loss : 0.109 /   test loss : 1.083
iteration : 440/500  -  train loss : 0.106 /   test loss : 1.089
iteration : 450/500  -  train loss : 0.1 /   test loss : 1.065
iteration : 460/500  -  train loss : 0.098 /   test loss : 1.066
iteration : 470/500  -  train loss : 0.098 /   test loss : 1.079
iteration : 480/500  -  train loss : 0.099 /   test loss : 1.092
iteration : 490/500  -  train loss : 0.089 /   test loss : 1.072
iteration : 500/500  -  train loss : 0.084 /   test loss : 1.064

Training complete   //   Running time : 155  ------------


[Gene 5] Model 3 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 21013])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 21013])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 1.176 /   test loss : 0.517
iteration : 10/500  -  train loss : 0.652 /   test loss : 0.159
iteration : 20/500  -  train loss : 0.56 /   test loss : 0.175
iteration : 30/500  -  train loss : 0.528 /   test loss : 0.164
iteration : 40/500  -  train loss : 0.512 /   test loss : 0.166
iteration : 50/500  -  train loss : 0.509 /   test loss : 0.15
iteration : 60/500  -  train loss : 0.482 /   test loss : 0.182
iteration : 70/500  -  train loss : 0.473 /   test loss : 0.166
iteration : 80/500  -  train loss : 0.451 /   test loss : 0.182
iteration : 90/500  -  train loss : 0.434 /   test loss : 0.17
iteration : 100/500  -  train loss : 0.429 /   test loss : 0.179
iteration : 110/500  -  train loss : 0.42 /   test loss : 0.189
iteration : 120/500  -  train loss : 0.414 /   test loss : 0.191
iteration : 130/500  -  train loss : 0.394 /   test loss : 0.188
iteration : 140/500  -  train loss : 0.378 /   test loss : 0.191
iteration : 150/500  -  train loss : 0.366 /   test loss : 0.188
iteration : 160/500  -  train loss : 0.357 /   test loss : 0.186
iteration : 170/500  -  train loss : 0.335 /   test loss : 0.202
iteration : 180/500  -  train loss : 0.322 /   test loss : 0.207
iteration : 190/500  -  train loss : 0.31 /   test loss : 0.21
iteration : 200/500  -  train loss : 0.306 /   test loss : 0.201
iteration : 210/500  -  train loss : 0.3 /   test loss : 0.204
iteration : 220/500  -  train loss : 0.291 /   test loss : 0.205
iteration : 230/500  -  train loss : 0.285 /   test loss : 0.205
iteration : 240/500  -  train loss : 0.269 /   test loss : 0.216
iteration : 250/500  -  train loss : 0.258 /   test loss : 0.207
iteration : 260/500  -  train loss : 0.255 /   test loss : 0.211
iteration : 270/500  -  train loss : 0.253 /   test loss : 0.21
iteration : 280/500  -  train loss : 0.241 /   test loss : 0.213
iteration : 290/500  -  train loss : 0.237 /   test loss : 0.212
iteration : 300/500  -  train loss : 0.228 /   test loss : 0.215
iteration : 310/500  -  train loss : 0.219 /   test loss : 0.219
iteration : 320/500  -  train loss : 0.218 /   test loss : 0.214
iteration : 330/500  -  train loss : 0.221 /   test loss : 0.212
iteration : 340/500  -  train loss : 0.207 /   test loss : 0.224
iteration : 350/500  -  train loss : 0.204 /   test loss : 0.234
iteration : 360/500  -  train loss : 0.202 /   test loss : 0.231
iteration : 370/500  -  train loss : 0.193 /   test loss : 0.226
iteration : 380/500  -  train loss : 0.186 /   test loss : 0.229
iteration : 390/500  -  train loss : 0.185 /   test loss : 0.229
iteration : 400/500  -  train loss : 0.18 /   test loss : 0.225
iteration : 410/500  -  train loss : 0.168 /   test loss : 0.222
iteration : 420/500  -  train loss : 0.163 /   test loss : 0.226
iteration : 430/500  -  train loss : 0.165 /   test loss : 0.227
iteration : 440/500  -  train loss : 0.161 /   test loss : 0.224
iteration : 450/500  -  train loss : 0.154 /   test loss : 0.228
iteration : 460/500  -  train loss : 0.15 /   test loss : 0.232
iteration : 470/500  -  train loss : 0.143 /   test loss : 0.235
iteration : 480/500  -  train loss : 0.144 /   test loss : 0.232
iteration : 490/500  -  train loss : 0.141 /   test loss : 0.23
iteration : 500/500  -  train loss : 0.143 /   test loss : 0.233

Training complete   //   Running time : 154  ------------


[Gene 5] Model 3 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 21013])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 21013])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 1.141 /   test loss : 0.625
iteration : 10/500  -  train loss : 0.613 /   test loss : 0.329
iteration : 20/500  -  train loss : 0.531 /   test loss : 0.323
iteration : 30/500  -  train loss : 0.511 /   test loss : 0.329
iteration : 40/500  -  train loss : 0.503 /   test loss : 0.335
iteration : 50/500  -  train loss : 0.497 /   test loss : 0.345
iteration : 60/500  -  train loss : 0.464 /   test loss : 0.333
iteration : 70/500  -  train loss : 0.451 /   test loss : 0.326
iteration : 80/500  -  train loss : 0.441 /   test loss : 0.327
iteration : 90/500  -  train loss : 0.431 /   test loss : 0.326
iteration : 100/500  -  train loss : 0.421 /   test loss : 0.323
iteration : 110/500  -  train loss : 0.415 /   test loss : 0.323
iteration : 120/500  -  train loss : 0.402 /   test loss : 0.319
iteration : 130/500  -  train loss : 0.389 /   test loss : 0.322
iteration : 140/500  -  train loss : 0.379 /   test loss : 0.323
iteration : 150/500  -  train loss : 0.369 /   test loss : 0.318
iteration : 160/500  -  train loss : 0.361 /   test loss : 0.318
iteration : 170/500  -  train loss : 0.342 /   test loss : 0.312
iteration : 180/500  -  train loss : 0.324 /   test loss : 0.309
iteration : 190/500  -  train loss : 0.316 /   test loss : 0.314
iteration : 200/500  -  train loss : 0.318 /   test loss : 0.321
iteration : 210/500  -  train loss : 0.315 /   test loss : 0.324
iteration : 220/500  -  train loss : 0.295 /   test loss : 0.319
iteration : 230/500  -  train loss : 0.284 /   test loss : 0.316
iteration : 240/500  -  train loss : 0.278 /   test loss : 0.315
iteration : 250/500  -  train loss : 0.272 /   test loss : 0.316
iteration : 260/500  -  train loss : 0.27 /   test loss : 0.316
iteration : 270/500  -  train loss : 0.266 /   test loss : 0.32
iteration : 280/500  -  train loss : 0.257 /   test loss : 0.316
iteration : 290/500  -  train loss : 0.253 /   test loss : 0.32
iteration : 300/500  -  train loss : 0.24 /   test loss : 0.316
iteration : 310/500  -  train loss : 0.23 /   test loss : 0.313
iteration : 320/500  -  train loss : 0.222 /   test loss : 0.313
iteration : 330/500  -  train loss : 0.218 /   test loss : 0.316
iteration : 340/500  -  train loss : 0.213 /   test loss : 0.318
iteration : 350/500  -  train loss : 0.203 /   test loss : 0.316
iteration : 360/500  -  train loss : 0.204 /   test loss : 0.316
iteration : 370/500  -  train loss : 0.2 /   test loss : 0.317
iteration : 380/500  -  train loss : 0.195 /   test loss : 0.319
iteration : 390/500  -  train loss : 0.185 /   test loss : 0.319
iteration : 400/500  -  train loss : 0.179 /   test loss : 0.315
iteration : 410/500  -  train loss : 0.17 /   test loss : 0.315
iteration : 420/500  -  train loss : 0.17 /   test loss : 0.315
iteration : 430/500  -  train loss : 0.173 /   test loss : 0.32
iteration : 440/500  -  train loss : 0.159 /   test loss : 0.32
iteration : 450/500  -  train loss : 0.159 /   test loss : 0.324
iteration : 460/500  -  train loss : 0.158 /   test loss : 0.326
iteration : 470/500  -  train loss : 0.144 /   test loss : 0.322
iteration : 480/500  -  train loss : 0.144 /   test loss : 0.323
iteration : 490/500  -  train loss : 0.144 /   test loss : 0.322
iteration : 500/500  -  train loss : 0.14 /   test loss : 0.323

Training complete   //   Running time : 155  ------------


[Gene 5] Model 3 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 21013])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 21013])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 1.174 /   test loss : 0.531
iteration : 10/500  -  train loss : 0.653 /   test loss : 0.168
iteration : 20/500  -  train loss : 0.553 /   test loss : 0.192
iteration : 30/500  -  train loss : 0.533 /   test loss : 0.187
iteration : 40/500  -  train loss : 0.527 /   test loss : 0.187
iteration : 50/500  -  train loss : 0.511 /   test loss : 0.16
iteration : 60/500  -  train loss : 0.474 /   test loss : 0.186
iteration : 70/500  -  train loss : 0.47 /   test loss : 0.169
iteration : 80/500  -  train loss : 0.45 /   test loss : 0.184
iteration : 90/500  -  train loss : 0.437 /   test loss : 0.197
iteration : 100/500  -  train loss : 0.42 /   test loss : 0.215
iteration : 110/500  -  train loss : 0.411 /   test loss : 0.191
iteration : 120/500  -  train loss : 0.409 /   test loss : 0.175
iteration : 130/500  -  train loss : 0.392 /   test loss : 0.196
iteration : 140/500  -  train loss : 0.374 /   test loss : 0.2
iteration : 150/500  -  train loss : 0.363 /   test loss : 0.203
iteration : 160/500  -  train loss : 0.356 /   test loss : 0.198
iteration : 170/500  -  train loss : 0.342 /   test loss : 0.209
iteration : 180/500  -  train loss : 0.327 /   test loss : 0.212
iteration : 190/500  -  train loss : 0.313 /   test loss : 0.205
iteration : 200/500  -  train loss : 0.308 /   test loss : 0.208
iteration : 210/500  -  train loss : 0.304 /   test loss : 0.209
iteration : 220/500  -  train loss : 0.288 /   test loss : 0.213
iteration : 230/500  -  train loss : 0.294 /   test loss : 0.211
iteration : 240/500  -  train loss : 0.291 /   test loss : 0.216
iteration : 250/500  -  train loss : 0.275 /   test loss : 0.219
iteration : 260/500  -  train loss : 0.269 /   test loss : 0.218
iteration : 270/500  -  train loss : 0.258 /   test loss : 0.219
iteration : 280/500  -  train loss : 0.248 /   test loss : 0.215
iteration : 290/500  -  train loss : 0.243 /   test loss : 0.225
iteration : 300/500  -  train loss : 0.237 /   test loss : 0.225
iteration : 310/500  -  train loss : 0.234 /   test loss : 0.231
iteration : 320/500  -  train loss : 0.227 /   test loss : 0.225
iteration : 330/500  -  train loss : 0.218 /   test loss : 0.23
iteration : 340/500  -  train loss : 0.207 /   test loss : 0.239
iteration : 350/500  -  train loss : 0.198 /   test loss : 0.255
iteration : 360/500  -  train loss : 0.19 /   test loss : 0.234
iteration : 370/500  -  train loss : 0.192 /   test loss : 0.228
iteration : 380/500  -  train loss : 0.189 /   test loss : 0.233
iteration : 390/500  -  train loss : 0.184 /   test loss : 0.23
iteration : 400/500  -  train loss : 0.174 /   test loss : 0.229
iteration : 410/500  -  train loss : 0.165 /   test loss : 0.238
iteration : 420/500  -  train loss : 0.163 /   test loss : 0.235
iteration : 430/500  -  train loss : 0.168 /   test loss : 0.233
iteration : 440/500  -  train loss : 0.157 /   test loss : 0.239
iteration : 450/500  -  train loss : 0.152 /   test loss : 0.243
iteration : 460/500  -  train loss : 0.152 /   test loss : 0.242
iteration : 470/500  -  train loss : 0.144 /   test loss : 0.241
iteration : 480/500  -  train loss : 0.141 /   test loss : 0.244
iteration : 490/500  -  train loss : 0.136 /   test loss : 0.237
iteration : 500/500  -  train loss : 0.133 /   test loss : 0.236

Training complete   //   Running time : 154  ------------


[Gene 5] Model 3 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([120, 21013])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 21013])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.854 /   test loss : 1.763
iteration : 10/500  -  train loss : 0.384 /   test loss : 1.279
iteration : 20/500  -  train loss : 0.316 /   test loss : 1.189
iteration : 30/500  -  train loss : 0.3 /   test loss : 1.198
iteration : 40/500  -  train loss : 0.296 /   test loss : 1.203
iteration : 50/500  -  train loss : 0.284 /   test loss : 1.227
iteration : 60/500  -  train loss : 0.286 /   test loss : 1.265
iteration : 70/500  -  train loss : 0.275 /   test loss : 1.271
iteration : 80/500  -  train loss : 0.273 /   test loss : 1.264
iteration : 90/500  -  train loss : 0.263 /   test loss : 1.254
iteration : 100/500  -  train loss : 0.252 /   test loss : 1.262
iteration : 110/500  -  train loss : 0.25 /   test loss : 1.259
iteration : 120/500  -  train loss : 0.236 /   test loss : 1.241
iteration : 130/500  -  train loss : 0.229 /   test loss : 1.233
iteration : 140/500  -  train loss : 0.222 /   test loss : 1.24
iteration : 150/500  -  train loss : 0.228 /   test loss : 1.261
iteration : 160/500  -  train loss : 0.22 /   test loss : 1.246
iteration : 170/500  -  train loss : 0.214 /   test loss : 1.246
iteration : 180/500  -  train loss : 0.211 /   test loss : 1.258
iteration : 190/500  -  train loss : 0.202 /   test loss : 1.246
iteration : 200/500  -  train loss : 0.199 /   test loss : 1.262
iteration : 210/500  -  train loss : 0.198 /   test loss : 1.261
iteration : 220/500  -  train loss : 0.188 /   test loss : 1.244
iteration : 230/500  -  train loss : 0.182 /   test loss : 1.256
iteration : 240/500  -  train loss : 0.175 /   test loss : 1.246
iteration : 250/500  -  train loss : 0.174 /   test loss : 1.25
iteration : 260/500  -  train loss : 0.168 /   test loss : 1.247
iteration : 270/500  -  train loss : 0.165 /   test loss : 1.255
iteration : 280/500  -  train loss : 0.171 /   test loss : 1.281
iteration : 290/500  -  train loss : 0.172 /   test loss : 1.284
iteration : 300/500  -  train loss : 0.163 /   test loss : 1.258
iteration : 310/500  -  train loss : 0.156 /   test loss : 1.259
iteration : 320/500  -  train loss : 0.148 /   test loss : 1.255
iteration : 330/500  -  train loss : 0.145 /   test loss : 1.258
iteration : 340/500  -  train loss : 0.143 /   test loss : 1.265
iteration : 350/500  -  train loss : 0.138 /   test loss : 1.265
iteration : 360/500  -  train loss : 0.131 /   test loss : 1.25
iteration : 370/500  -  train loss : 0.134 /   test loss : 1.271
iteration : 380/500  -  train loss : 0.133 /   test loss : 1.266
iteration : 390/500  -  train loss : 0.13 /   test loss : 1.261
iteration : 400/500  -  train loss : 0.127 /   test loss : 1.256
iteration : 410/500  -  train loss : 0.127 /   test loss : 1.264
iteration : 420/500  -  train loss : 0.12 /   test loss : 1.253
iteration : 430/500  -  train loss : 0.121 /   test loss : 1.264
iteration : 440/500  -  train loss : 0.12 /   test loss : 1.268
iteration : 450/500  -  train loss : 0.114 /   test loss : 1.248
iteration : 460/500  -  train loss : 0.111 /   test loss : 1.243
iteration : 470/500  -  train loss : 0.106 /   test loss : 1.248
iteration : 480/500  -  train loss : 0.1 /   test loss : 1.236
iteration : 490/500  -  train loss : 0.108 /   test loss : 1.26
iteration : 500/500  -  train loss : 0.104 /   test loss : 1.255

Training complete   //   Running time : 152  ------------


[Gene 6] Model 3 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 27389])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 27389])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 1.142 /   test loss : 1.789
iteration : 10/500  -  train loss : 0.903 /   test loss : 1.635
iteration : 20/500  -  train loss : 0.764 /   test loss : 1.56
iteration : 30/500  -  train loss : 0.684 /   test loss : 1.508
iteration : 40/500  -  train loss : 0.625 /   test loss : 1.467
iteration : 50/500  -  train loss : 0.589 /   test loss : 1.467
iteration : 60/500  -  train loss : 0.563 /   test loss : 1.471
iteration : 70/500  -  train loss : 0.526 /   test loss : 1.446
iteration : 80/500  -  train loss : 0.499 /   test loss : 1.438
iteration : 90/500  -  train loss : 0.457 /   test loss : 1.4
iteration : 100/500  -  train loss : 0.411 /   test loss : 1.368
iteration : 110/500  -  train loss : 0.375 /   test loss : 1.363
iteration : 120/500  -  train loss : 0.342 /   test loss : 1.341
iteration : 130/500  -  train loss : 0.325 /   test loss : 1.342
iteration : 140/500  -  train loss : 0.302 /   test loss : 1.308
iteration : 150/500  -  train loss : 0.279 /   test loss : 1.307
iteration : 160/500  -  train loss : 0.26 /   test loss : 1.311
iteration : 170/500  -  train loss : 0.25 /   test loss : 1.303
iteration : 180/500  -  train loss : 0.241 /   test loss : 1.303
iteration : 190/500  -  train loss : 0.213 /   test loss : 1.283
iteration : 200/500  -  train loss : 0.198 /   test loss : 1.278
iteration : 210/500  -  train loss : 0.187 /   test loss : 1.273
iteration : 220/500  -  train loss : 0.179 /   test loss : 1.271
iteration : 230/500  -  train loss : 0.181 /   test loss : 1.278
iteration : 240/500  -  train loss : 0.169 /   test loss : 1.272
iteration : 250/500  -  train loss : 0.157 /   test loss : 1.255
iteration : 260/500  -  train loss : 0.145 /   test loss : 1.256
iteration : 270/500  -  train loss : 0.139 /   test loss : 1.248
iteration : 280/500  -  train loss : 0.14 /   test loss : 1.26
iteration : 290/500  -  train loss : 0.133 /   test loss : 1.257
iteration : 300/500  -  train loss : 0.125 /   test loss : 1.241
iteration : 310/500  -  train loss : 0.132 /   test loss : 1.255
iteration : 320/500  -  train loss : 0.129 /   test loss : 1.266
iteration : 330/500  -  train loss : 0.124 /   test loss : 1.267
iteration : 340/500  -  train loss : 0.112 /   test loss : 1.248
iteration : 350/500  -  train loss : 0.104 /   test loss : 1.235
iteration : 360/500  -  train loss : 0.101 /   test loss : 1.251
iteration : 370/500  -  train loss : 0.104 /   test loss : 1.253
iteration : 380/500  -  train loss : 0.101 /   test loss : 1.26
iteration : 390/500  -  train loss : 0.099 /   test loss : 1.254
iteration : 400/500  -  train loss : 0.101 /   test loss : 1.25
iteration : 410/500  -  train loss : 0.095 /   test loss : 1.257
iteration : 420/500  -  train loss : 0.099 /   test loss : 1.261
iteration : 430/500  -  train loss : 0.096 /   test loss : 1.271
iteration : 440/500  -  train loss : 0.097 /   test loss : 1.251
iteration : 450/500  -  train loss : 0.101 /   test loss : 1.262
iteration : 460/500  -  train loss : 0.094 /   test loss : 1.257
iteration : 470/500  -  train loss : 0.091 /   test loss : 1.259
iteration : 480/500  -  train loss : 0.085 /   test loss : 1.256
iteration : 490/500  -  train loss : 0.081 /   test loss : 1.23
iteration : 500/500  -  train loss : 0.077 /   test loss : 1.232

Training complete   //   Running time : 215  ------------


[Gene 6] Model 3 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 27389])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 27389])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 1.396 /   test loss : 0.743
iteration : 10/500  -  train loss : 1.134 /   test loss : 0.64
iteration : 20/500  -  train loss : 0.949 /   test loss : 0.588
iteration : 30/500  -  train loss : 0.832 /   test loss : 0.617
iteration : 40/500  -  train loss : 0.755 /   test loss : 0.566
iteration : 50/500  -  train loss : 0.699 /   test loss : 0.582
iteration : 60/500  -  train loss : 0.657 /   test loss : 0.585
iteration : 70/500  -  train loss : 0.611 /   test loss : 0.552
iteration : 80/500  -  train loss : 0.557 /   test loss : 0.531
iteration : 90/500  -  train loss : 0.5 /   test loss : 0.522
iteration : 100/500  -  train loss : 0.458 /   test loss : 0.491
iteration : 110/500  -  train loss : 0.434 /   test loss : 0.507
iteration : 120/500  -  train loss : 0.391 /   test loss : 0.49
iteration : 130/500  -  train loss : 0.365 /   test loss : 0.485
iteration : 140/500  -  train loss : 0.342 /   test loss : 0.482
iteration : 150/500  -  train loss : 0.315 /   test loss : 0.489
iteration : 160/500  -  train loss : 0.28 /   test loss : 0.473
iteration : 170/500  -  train loss : 0.256 /   test loss : 0.461
iteration : 180/500  -  train loss : 0.247 /   test loss : 0.458
iteration : 190/500  -  train loss : 0.229 /   test loss : 0.458
iteration : 200/500  -  train loss : 0.219 /   test loss : 0.461
iteration : 210/500  -  train loss : 0.207 /   test loss : 0.46
iteration : 220/500  -  train loss : 0.204 /   test loss : 0.469
iteration : 230/500  -  train loss : 0.19 /   test loss : 0.459
iteration : 240/500  -  train loss : 0.175 /   test loss : 0.467
iteration : 250/500  -  train loss : 0.163 /   test loss : 0.454
iteration : 260/500  -  train loss : 0.162 /   test loss : 0.458
iteration : 270/500  -  train loss : 0.16 /   test loss : 0.457
iteration : 280/500  -  train loss : 0.169 /   test loss : 0.464
iteration : 290/500  -  train loss : 0.166 /   test loss : 0.461
iteration : 300/500  -  train loss : 0.151 /   test loss : 0.456
iteration : 310/500  -  train loss : 0.153 /   test loss : 0.461
iteration : 320/500  -  train loss : 0.144 /   test loss : 0.46
iteration : 330/500  -  train loss : 0.134 /   test loss : 0.452
iteration : 340/500  -  train loss : 0.12 /   test loss : 0.445
iteration : 350/500  -  train loss : 0.116 /   test loss : 0.445
iteration : 360/500  -  train loss : 0.119 /   test loss : 0.463
iteration : 370/500  -  train loss : 0.106 /   test loss : 0.445
iteration : 380/500  -  train loss : 0.103 /   test loss : 0.44
iteration : 390/500  -  train loss : 0.105 /   test loss : 0.449
iteration : 400/500  -  train loss : 0.108 /   test loss : 0.458
iteration : 410/500  -  train loss : 0.107 /   test loss : 0.462
iteration : 420/500  -  train loss : 0.106 /   test loss : 0.465
iteration : 430/500  -  train loss : 0.107 /   test loss : 0.461
iteration : 440/500  -  train loss : 0.105 /   test loss : 0.458
iteration : 450/500  -  train loss : 0.101 /   test loss : 0.459
iteration : 460/500  -  train loss : 0.093 /   test loss : 0.448
iteration : 470/500  -  train loss : 0.091 /   test loss : 0.449
iteration : 480/500  -  train loss : 0.096 /   test loss : 0.456
iteration : 490/500  -  train loss : 0.091 /   test loss : 0.449
iteration : 500/500  -  train loss : 0.087 /   test loss : 0.454

Training complete   //   Running time : 200  ------------


[Gene 6] Model 3 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 27389])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 27389])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 1.151 /   test loss : 1.794
iteration : 10/500  -  train loss : 0.925 /   test loss : 1.669
iteration : 20/500  -  train loss : 0.755 /   test loss : 1.545
iteration : 30/500  -  train loss : 0.68 /   test loss : 1.506
iteration : 40/500  -  train loss : 0.619 /   test loss : 1.489
iteration : 50/500  -  train loss : 0.585 /   test loss : 1.472
iteration : 60/500  -  train loss : 0.547 /   test loss : 1.465
iteration : 70/500  -  train loss : 0.509 /   test loss : 1.427
iteration : 80/500  -  train loss : 0.473 /   test loss : 1.395
iteration : 90/500  -  train loss : 0.441 /   test loss : 1.388
iteration : 100/500  -  train loss : 0.399 /   test loss : 1.367
iteration : 110/500  -  train loss : 0.374 /   test loss : 1.365
iteration : 120/500  -  train loss : 0.335 /   test loss : 1.352
iteration : 130/500  -  train loss : 0.306 /   test loss : 1.319
iteration : 140/500  -  train loss : 0.29 /   test loss : 1.325
iteration : 150/500  -  train loss : 0.273 /   test loss : 1.323
iteration : 160/500  -  train loss : 0.248 /   test loss : 1.308
iteration : 170/500  -  train loss : 0.235 /   test loss : 1.297
iteration : 180/500  -  train loss : 0.226 /   test loss : 1.29
iteration : 190/500  -  train loss : 0.205 /   test loss : 1.283
iteration : 200/500  -  train loss : 0.19 /   test loss : 1.29
iteration : 210/500  -  train loss : 0.186 /   test loss : 1.307
iteration : 220/500  -  train loss : 0.176 /   test loss : 1.29
iteration : 230/500  -  train loss : 0.16 /   test loss : 1.287
iteration : 240/500  -  train loss : 0.149 /   test loss : 1.258
iteration : 250/500  -  train loss : 0.145 /   test loss : 1.269
iteration : 260/500  -  train loss : 0.138 /   test loss : 1.279
iteration : 270/500  -  train loss : 0.135 /   test loss : 1.274
iteration : 280/500  -  train loss : 0.135 /   test loss : 1.281
iteration : 290/500  -  train loss : 0.123 /   test loss : 1.263
iteration : 300/500  -  train loss : 0.121 /   test loss : 1.264
iteration : 310/500  -  train loss : 0.121 /   test loss : 1.264
iteration : 320/500  -  train loss : 0.113 /   test loss : 1.264
iteration : 330/500  -  train loss : 0.113 /   test loss : 1.263
iteration : 340/500  -  train loss : 0.109 /   test loss : 1.253
iteration : 350/500  -  train loss : 0.1 /   test loss : 1.253
iteration : 360/500  -  train loss : 0.091 /   test loss : 1.235
iteration : 370/500  -  train loss : 0.097 /   test loss : 1.256
iteration : 380/500  -  train loss : 0.101 /   test loss : 1.261
iteration : 390/500  -  train loss : 0.101 /   test loss : 1.268
iteration : 400/500  -  train loss : 0.102 /   test loss : 1.265
iteration : 410/500  -  train loss : 0.094 /   test loss : 1.251
iteration : 420/500  -  train loss : 0.103 /   test loss : 1.228
iteration : 430/500  -  train loss : 0.099 /   test loss : 1.248
iteration : 440/500  -  train loss : 0.092 /   test loss : 1.245
iteration : 450/500  -  train loss : 0.091 /   test loss : 1.249
iteration : 460/500  -  train loss : 0.094 /   test loss : 1.231
iteration : 470/500  -  train loss : 0.091 /   test loss : 1.25
iteration : 480/500  -  train loss : 0.088 /   test loss : 1.232
iteration : 490/500  -  train loss : 0.093 /   test loss : 1.22
iteration : 500/500  -  train loss : 0.09 /   test loss : 1.246

Training complete   //   Running time : 200  ------------


[Gene 6] Model 3 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 27389])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 27389])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 1.186 /   test loss : 1.624
iteration : 10/500  -  train loss : 0.953 /   test loss : 1.469
iteration : 20/500  -  train loss : 0.793 /   test loss : 1.375
iteration : 30/500  -  train loss : 0.705 /   test loss : 1.351
iteration : 40/500  -  train loss : 0.64 /   test loss : 1.341
iteration : 50/500  -  train loss : 0.599 /   test loss : 1.327
iteration : 60/500  -  train loss : 0.562 /   test loss : 1.327
iteration : 70/500  -  train loss : 0.517 /   test loss : 1.306
iteration : 80/500  -  train loss : 0.484 /   test loss : 1.318
iteration : 90/500  -  train loss : 0.447 /   test loss : 1.319
iteration : 100/500  -  train loss : 0.404 /   test loss : 1.288
iteration : 110/500  -  train loss : 0.374 /   test loss : 1.277
iteration : 120/500  -  train loss : 0.338 /   test loss : 1.286
iteration : 130/500  -  train loss : 0.304 /   test loss : 1.27
iteration : 140/500  -  train loss : 0.289 /   test loss : 1.271
iteration : 150/500  -  train loss : 0.269 /   test loss : 1.266
iteration : 160/500  -  train loss : 0.254 /   test loss : 1.247
iteration : 170/500  -  train loss : 0.231 /   test loss : 1.281
iteration : 180/500  -  train loss : 0.216 /   test loss : 1.298
iteration : 190/500  -  train loss : 0.203 /   test loss : 1.29
iteration : 200/500  -  train loss : 0.188 /   test loss : 1.289
iteration : 210/500  -  train loss : 0.173 /   test loss : 1.284
iteration : 220/500  -  train loss : 0.169 /   test loss : 1.28
iteration : 230/500  -  train loss : 0.159 /   test loss : 1.281
iteration : 240/500  -  train loss : 0.142 /   test loss : 1.283
iteration : 250/500  -  train loss : 0.129 /   test loss : 1.285
iteration : 260/500  -  train loss : 0.128 /   test loss : 1.288
iteration : 270/500  -  train loss : 0.126 /   test loss : 1.289
iteration : 280/500  -  train loss : 0.116 /   test loss : 1.299
iteration : 290/500  -  train loss : 0.114 /   test loss : 1.328
iteration : 300/500  -  train loss : 0.117 /   test loss : 1.301
iteration : 310/500  -  train loss : 0.121 /   test loss : 1.32
iteration : 320/500  -  train loss : 0.12 /   test loss : 1.329
iteration : 330/500  -  train loss : 0.108 /   test loss : 1.31
iteration : 340/500  -  train loss : 0.099 /   test loss : 1.312
iteration : 350/500  -  train loss : 0.097 /   test loss : 1.314
iteration : 360/500  -  train loss : 0.093 /   test loss : 1.302
iteration : 370/500  -  train loss : 0.09 /   test loss : 1.33
iteration : 380/500  -  train loss : 0.09 /   test loss : 1.337
iteration : 390/500  -  train loss : 0.088 /   test loss : 1.332
iteration : 400/500  -  train loss : 0.096 /   test loss : 1.344
iteration : 410/500  -  train loss : 0.093 /   test loss : 1.315
iteration : 420/500  -  train loss : 0.084 /   test loss : 1.311
iteration : 430/500  -  train loss : 0.088 /   test loss : 1.339
iteration : 440/500  -  train loss : 0.094 /   test loss : 1.329
iteration : 450/500  -  train loss : 0.09 /   test loss : 1.337
iteration : 460/500  -  train loss : 0.08 /   test loss : 1.304
iteration : 470/500  -  train loss : 0.075 /   test loss : 1.341
iteration : 480/500  -  train loss : 0.079 /   test loss : 1.327
iteration : 490/500  -  train loss : 0.089 /   test loss : 1.32
iteration : 500/500  -  train loss : 0.082 /   test loss : 1.333

Training complete   //   Running time : 200  ------------


[Gene 6] Model 3 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([120, 27389])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 27389])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 1.474 /   test loss : 0.526
iteration : 10/500  -  train loss : 1.175 /   test loss : 0.452
iteration : 20/500  -  train loss : 0.974 /   test loss : 0.409
iteration : 30/500  -  train loss : 0.864 /   test loss : 0.424
iteration : 40/500  -  train loss : 0.793 /   test loss : 0.387
iteration : 50/500  -  train loss : 0.739 /   test loss : 0.391
iteration : 60/500  -  train loss : 0.697 /   test loss : 0.37
iteration : 70/500  -  train loss : 0.654 /   test loss : 0.393
iteration : 80/500  -  train loss : 0.608 /   test loss : 0.396
iteration : 90/500  -  train loss : 0.566 /   test loss : 0.385
iteration : 100/500  -  train loss : 0.517 /   test loss : 0.378
iteration : 110/500  -  train loss : 0.457 /   test loss : 0.388
iteration : 120/500  -  train loss : 0.409 /   test loss : 0.368
iteration : 130/500  -  train loss : 0.375 /   test loss : 0.35
iteration : 140/500  -  train loss : 0.35 /   test loss : 0.341
iteration : 150/500  -  train loss : 0.32 /   test loss : 0.352
iteration : 160/500  -  train loss : 0.294 /   test loss : 0.367
iteration : 170/500  -  train loss : 0.27 /   test loss : 0.363
iteration : 180/500  -  train loss : 0.254 /   test loss : 0.357
iteration : 190/500  -  train loss : 0.242 /   test loss : 0.344
iteration : 200/500  -  train loss : 0.225 /   test loss : 0.333
iteration : 210/500  -  train loss : 0.213 /   test loss : 0.318
iteration : 220/500  -  train loss : 0.206 /   test loss : 0.345
iteration : 230/500  -  train loss : 0.193 /   test loss : 0.346
iteration : 240/500  -  train loss : 0.186 /   test loss : 0.332
iteration : 250/500  -  train loss : 0.168 /   test loss : 0.332
iteration : 260/500  -  train loss : 0.161 /   test loss : 0.338
iteration : 270/500  -  train loss : 0.168 /   test loss : 0.353
iteration : 280/500  -  train loss : 0.162 /   test loss : 0.344
iteration : 290/500  -  train loss : 0.159 /   test loss : 0.323
iteration : 300/500  -  train loss : 0.158 /   test loss : 0.322
iteration : 310/500  -  train loss : 0.15 /   test loss : 0.323
iteration : 320/500  -  train loss : 0.137 /   test loss : 0.336
iteration : 330/500  -  train loss : 0.143 /   test loss : 0.329
iteration : 340/500  -  train loss : 0.122 /   test loss : 0.333
iteration : 350/500  -  train loss : 0.117 /   test loss : 0.316
iteration : 360/500  -  train loss : 0.121 /   test loss : 0.337
iteration : 370/500  -  train loss : 0.126 /   test loss : 0.311
iteration : 380/500  -  train loss : 0.112 /   test loss : 0.319
iteration : 390/500  -  train loss : 0.101 /   test loss : 0.316
iteration : 400/500  -  train loss : 0.112 /   test loss : 0.313
iteration : 410/500  -  train loss : 0.111 /   test loss : 0.322
iteration : 420/500  -  train loss : 0.106 /   test loss : 0.321
iteration : 430/500  -  train loss : 0.101 /   test loss : 0.325
iteration : 440/500  -  train loss : 0.094 /   test loss : 0.312
iteration : 450/500  -  train loss : 0.102 /   test loss : 0.309
iteration : 460/500  -  train loss : 0.108 /   test loss : 0.323
iteration : 470/500  -  train loss : 0.108 /   test loss : 0.312
iteration : 480/500  -  train loss : 0.093 /   test loss : 0.321
iteration : 490/500  -  train loss : 0.092 /   test loss : 0.311
iteration : 500/500  -  train loss : 0.104 /   test loss : 0.301

Training complete   //   Running time : 198  ------------


[Gene 7] Model 3 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 17331])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 17331])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.72 /   test loss : 0.522
iteration : 10/500  -  train loss : 0.555 /   test loss : 0.505
iteration : 20/500  -  train loss : 0.439 /   test loss : 0.509
iteration : 30/500  -  train loss : 0.369 /   test loss : 0.485
iteration : 40/500  -  train loss : 0.335 /   test loss : 0.467
iteration : 50/500  -  train loss : 0.306 /   test loss : 0.458
iteration : 60/500  -  train loss : 0.279 /   test loss : 0.454
iteration : 70/500  -  train loss : 0.254 /   test loss : 0.459
iteration : 80/500  -  train loss : 0.239 /   test loss : 0.454
iteration : 90/500  -  train loss : 0.223 /   test loss : 0.449
iteration : 100/500  -  train loss : 0.207 /   test loss : 0.454
iteration : 110/500  -  train loss : 0.199 /   test loss : 0.462
iteration : 120/500  -  train loss : 0.191 /   test loss : 0.463
iteration : 130/500  -  train loss : 0.18 /   test loss : 0.461
iteration : 140/500  -  train loss : 0.17 /   test loss : 0.454
iteration : 150/500  -  train loss : 0.162 /   test loss : 0.456
iteration : 160/500  -  train loss : 0.155 /   test loss : 0.457
iteration : 170/500  -  train loss : 0.146 /   test loss : 0.451
iteration : 180/500  -  train loss : 0.136 /   test loss : 0.448
iteration : 190/500  -  train loss : 0.131 /   test loss : 0.445
iteration : 200/500  -  train loss : 0.13 /   test loss : 0.446
iteration : 210/500  -  train loss : 0.125 /   test loss : 0.44
iteration : 220/500  -  train loss : 0.115 /   test loss : 0.44
iteration : 230/500  -  train loss : 0.108 /   test loss : 0.443
iteration : 240/500  -  train loss : 0.107 /   test loss : 0.444
iteration : 250/500  -  train loss : 0.104 /   test loss : 0.444
iteration : 260/500  -  train loss : 0.099 /   test loss : 0.44
iteration : 270/500  -  train loss : 0.097 /   test loss : 0.437
iteration : 280/500  -  train loss : 0.094 /   test loss : 0.432
iteration : 290/500  -  train loss : 0.091 /   test loss : 0.429
iteration : 300/500  -  train loss : 0.083 /   test loss : 0.43
iteration : 310/500  -  train loss : 0.081 /   test loss : 0.433
iteration : 320/500  -  train loss : 0.077 /   test loss : 0.436
iteration : 330/500  -  train loss : 0.075 /   test loss : 0.435
iteration : 340/500  -  train loss : 0.074 /   test loss : 0.433
iteration : 350/500  -  train loss : 0.071 /   test loss : 0.431
iteration : 360/500  -  train loss : 0.072 /   test loss : 0.43
iteration : 370/500  -  train loss : 0.071 /   test loss : 0.431
iteration : 380/500  -  train loss : 0.067 /   test loss : 0.43
iteration : 390/500  -  train loss : 0.062 /   test loss : 0.429
iteration : 400/500  -  train loss : 0.065 /   test loss : 0.435
iteration : 410/500  -  train loss : 0.068 /   test loss : 0.437
iteration : 420/500  -  train loss : 0.067 /   test loss : 0.428
iteration : 430/500  -  train loss : 0.065 /   test loss : 0.43
iteration : 440/500  -  train loss : 0.068 /   test loss : 0.435
iteration : 450/500  -  train loss : 0.071 /   test loss : 0.437
iteration : 460/500  -  train loss : 0.066 /   test loss : 0.438
iteration : 470/500  -  train loss : 0.063 /   test loss : 0.439
iteration : 480/500  -  train loss : 0.059 /   test loss : 0.439
iteration : 490/500  -  train loss : 0.059 /   test loss : 0.437
iteration : 500/500  -  train loss : 0.059 /   test loss : 0.435

Training complete   //   Running time : 133  ------------


[Gene 7] Model 3 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 17331])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 17331])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.753 /   test loss : 0.382
iteration : 10/500  -  train loss : 0.58 /   test loss : 0.41
iteration : 20/500  -  train loss : 0.46 /   test loss : 0.387
iteration : 30/500  -  train loss : 0.386 /   test loss : 0.391
iteration : 40/500  -  train loss : 0.348 /   test loss : 0.392
iteration : 50/500  -  train loss : 0.313 /   test loss : 0.395
iteration : 60/500  -  train loss : 0.289 /   test loss : 0.384
iteration : 70/500  -  train loss : 0.265 /   test loss : 0.392
iteration : 80/500  -  train loss : 0.245 /   test loss : 0.401
iteration : 90/500  -  train loss : 0.226 /   test loss : 0.391
iteration : 100/500  -  train loss : 0.209 /   test loss : 0.398
iteration : 110/500  -  train loss : 0.197 /   test loss : 0.387
iteration : 120/500  -  train loss : 0.184 /   test loss : 0.386
iteration : 130/500  -  train loss : 0.174 /   test loss : 0.385
iteration : 140/500  -  train loss : 0.164 /   test loss : 0.4
iteration : 150/500  -  train loss : 0.147 /   test loss : 0.404
iteration : 160/500  -  train loss : 0.143 /   test loss : 0.393
iteration : 170/500  -  train loss : 0.136 /   test loss : 0.398
iteration : 180/500  -  train loss : 0.126 /   test loss : 0.4
iteration : 190/500  -  train loss : 0.123 /   test loss : 0.392
iteration : 200/500  -  train loss : 0.128 /   test loss : 0.39
iteration : 210/500  -  train loss : 0.116 /   test loss : 0.394
iteration : 220/500  -  train loss : 0.108 /   test loss : 0.399
iteration : 230/500  -  train loss : 0.102 /   test loss : 0.403
iteration : 240/500  -  train loss : 0.095 /   test loss : 0.396
iteration : 250/500  -  train loss : 0.086 /   test loss : 0.399
iteration : 260/500  -  train loss : 0.087 /   test loss : 0.394
iteration : 270/500  -  train loss : 0.088 /   test loss : 0.387
iteration : 280/500  -  train loss : 0.083 /   test loss : 0.396
iteration : 290/500  -  train loss : 0.078 /   test loss : 0.394
iteration : 300/500  -  train loss : 0.074 /   test loss : 0.392
iteration : 310/500  -  train loss : 0.07 /   test loss : 0.393
iteration : 320/500  -  train loss : 0.064 /   test loss : 0.394
iteration : 330/500  -  train loss : 0.066 /   test loss : 0.394
iteration : 340/500  -  train loss : 0.066 /   test loss : 0.395
iteration : 350/500  -  train loss : 0.062 /   test loss : 0.405
iteration : 360/500  -  train loss : 0.064 /   test loss : 0.394
iteration : 370/500  -  train loss : 0.069 /   test loss : 0.393
iteration : 380/500  -  train loss : 0.063 /   test loss : 0.396
iteration : 390/500  -  train loss : 0.059 /   test loss : 0.4
iteration : 400/500  -  train loss : 0.061 /   test loss : 0.396
iteration : 410/500  -  train loss : 0.066 /   test loss : 0.391
iteration : 420/500  -  train loss : 0.064 /   test loss : 0.397
iteration : 430/500  -  train loss : 0.063 /   test loss : 0.395
iteration : 440/500  -  train loss : 0.066 /   test loss : 0.394
iteration : 450/500  -  train loss : 0.064 /   test loss : 0.396
iteration : 460/500  -  train loss : 0.062 /   test loss : 0.399
iteration : 470/500  -  train loss : 0.058 /   test loss : 0.399
iteration : 480/500  -  train loss : 0.053 /   test loss : 0.405
iteration : 490/500  -  train loss : 0.053 /   test loss : 0.399
iteration : 500/500  -  train loss : 0.054 /   test loss : 0.4

Training complete   //   Running time : 128  ------------


[Gene 7] Model 3 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 17331])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 17331])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.774 /   test loss : 0.304
iteration : 10/500  -  train loss : 0.608 /   test loss : 0.358
iteration : 20/500  -  train loss : 0.489 /   test loss : 0.236
iteration : 30/500  -  train loss : 0.411 /   test loss : 0.274
iteration : 40/500  -  train loss : 0.373 /   test loss : 0.248
iteration : 50/500  -  train loss : 0.341 /   test loss : 0.238
iteration : 60/500  -  train loss : 0.318 /   test loss : 0.236
iteration : 70/500  -  train loss : 0.296 /   test loss : 0.223
iteration : 80/500  -  train loss : 0.277 /   test loss : 0.229
iteration : 90/500  -  train loss : 0.257 /   test loss : 0.22
iteration : 100/500  -  train loss : 0.239 /   test loss : 0.236
iteration : 110/500  -  train loss : 0.227 /   test loss : 0.236
iteration : 120/500  -  train loss : 0.215 /   test loss : 0.225
iteration : 130/500  -  train loss : 0.204 /   test loss : 0.23
iteration : 140/500  -  train loss : 0.194 /   test loss : 0.223
iteration : 150/500  -  train loss : 0.18 /   test loss : 0.229
iteration : 160/500  -  train loss : 0.176 /   test loss : 0.225
iteration : 170/500  -  train loss : 0.163 /   test loss : 0.215
iteration : 180/500  -  train loss : 0.152 /   test loss : 0.22
iteration : 190/500  -  train loss : 0.148 /   test loss : 0.209
iteration : 200/500  -  train loss : 0.149 /   test loss : 0.206
iteration : 210/500  -  train loss : 0.14 /   test loss : 0.213
iteration : 220/500  -  train loss : 0.136 /   test loss : 0.208
iteration : 230/500  -  train loss : 0.127 /   test loss : 0.208
iteration : 240/500  -  train loss : 0.119 /   test loss : 0.202
iteration : 250/500  -  train loss : 0.108 /   test loss : 0.213
iteration : 260/500  -  train loss : 0.109 /   test loss : 0.204
iteration : 270/500  -  train loss : 0.108 /   test loss : 0.205
iteration : 280/500  -  train loss : 0.102 /   test loss : 0.216
iteration : 290/500  -  train loss : 0.095 /   test loss : 0.202
iteration : 300/500  -  train loss : 0.086 /   test loss : 0.197
iteration : 310/500  -  train loss : 0.083 /   test loss : 0.202
iteration : 320/500  -  train loss : 0.082 /   test loss : 0.195
iteration : 330/500  -  train loss : 0.084 /   test loss : 0.209
iteration : 340/500  -  train loss : 0.083 /   test loss : 0.193
iteration : 350/500  -  train loss : 0.078 /   test loss : 0.203
iteration : 360/500  -  train loss : 0.073 /   test loss : 0.192
iteration : 370/500  -  train loss : 0.076 /   test loss : 0.194
iteration : 380/500  -  train loss : 0.074 /   test loss : 0.199
iteration : 390/500  -  train loss : 0.072 /   test loss : 0.211
iteration : 400/500  -  train loss : 0.071 /   test loss : 0.201
iteration : 410/500  -  train loss : 0.068 /   test loss : 0.195
iteration : 420/500  -  train loss : 0.066 /   test loss : 0.207
iteration : 430/500  -  train loss : 0.07 /   test loss : 0.198
iteration : 440/500  -  train loss : 0.077 /   test loss : 0.198
iteration : 450/500  -  train loss : 0.079 /   test loss : 0.203
iteration : 460/500  -  train loss : 0.073 /   test loss : 0.203
iteration : 470/500  -  train loss : 0.072 /   test loss : 0.202
iteration : 480/500  -  train loss : 0.071 /   test loss : 0.209
iteration : 490/500  -  train loss : 0.071 /   test loss : 0.2
iteration : 500/500  -  train loss : 0.072 /   test loss : 0.211

Training complete   //   Running time : 128  ------------


[Gene 7] Model 3 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 17331])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 17331])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.501 /   test loss : 1.47
iteration : 10/500  -  train loss : 0.41 /   test loss : 1.323
iteration : 20/500  -  train loss : 0.345 /   test loss : 1.373
iteration : 30/500  -  train loss : 0.303 /   test loss : 1.265
iteration : 40/500  -  train loss : 0.274 /   test loss : 1.253
iteration : 50/500  -  train loss : 0.253 /   test loss : 1.258
iteration : 60/500  -  train loss : 0.238 /   test loss : 1.269
iteration : 70/500  -  train loss : 0.23 /   test loss : 1.32
iteration : 80/500  -  train loss : 0.216 /   test loss : 1.284
iteration : 90/500  -  train loss : 0.201 /   test loss : 1.278
iteration : 100/500  -  train loss : 0.189 /   test loss : 1.259
iteration : 110/500  -  train loss : 0.179 /   test loss : 1.256
iteration : 120/500  -  train loss : 0.174 /   test loss : 1.268
iteration : 130/500  -  train loss : 0.163 /   test loss : 1.299
iteration : 140/500  -  train loss : 0.155 /   test loss : 1.26
iteration : 150/500  -  train loss : 0.145 /   test loss : 1.251
iteration : 160/500  -  train loss : 0.137 /   test loss : 1.263
iteration : 170/500  -  train loss : 0.128 /   test loss : 1.261
iteration : 180/500  -  train loss : 0.118 /   test loss : 1.247
iteration : 190/500  -  train loss : 0.11 /   test loss : 1.254
iteration : 200/500  -  train loss : 0.107 /   test loss : 1.259
iteration : 210/500  -  train loss : 0.104 /   test loss : 1.248
iteration : 220/500  -  train loss : 0.097 /   test loss : 1.25
iteration : 230/500  -  train loss : 0.094 /   test loss : 1.232
iteration : 240/500  -  train loss : 0.09 /   test loss : 1.236
iteration : 250/500  -  train loss : 0.087 /   test loss : 1.252
iteration : 260/500  -  train loss : 0.084 /   test loss : 1.265
iteration : 270/500  -  train loss : 0.081 /   test loss : 1.24
iteration : 280/500  -  train loss : 0.079 /   test loss : 1.237
iteration : 290/500  -  train loss : 0.077 /   test loss : 1.226
iteration : 300/500  -  train loss : 0.072 /   test loss : 1.229
iteration : 310/500  -  train loss : 0.072 /   test loss : 1.23
iteration : 320/500  -  train loss : 0.07 /   test loss : 1.252
iteration : 330/500  -  train loss : 0.07 /   test loss : 1.251
iteration : 340/500  -  train loss : 0.07 /   test loss : 1.246
iteration : 350/500  -  train loss : 0.069 /   test loss : 1.245
iteration : 360/500  -  train loss : 0.068 /   test loss : 1.242
iteration : 370/500  -  train loss : 0.065 /   test loss : 1.246
iteration : 380/500  -  train loss : 0.061 /   test loss : 1.262
iteration : 390/500  -  train loss : 0.06 /   test loss : 1.252
iteration : 400/500  -  train loss : 0.057 /   test loss : 1.255
iteration : 410/500  -  train loss : 0.057 /   test loss : 1.249
iteration : 420/500  -  train loss : 0.055 /   test loss : 1.231
iteration : 430/500  -  train loss : 0.056 /   test loss : 1.244
iteration : 440/500  -  train loss : 0.056 /   test loss : 1.256
iteration : 450/500  -  train loss : 0.057 /   test loss : 1.238
iteration : 460/500  -  train loss : 0.053 /   test loss : 1.233
iteration : 470/500  -  train loss : 0.052 /   test loss : 1.226
iteration : 480/500  -  train loss : 0.052 /   test loss : 1.239
iteration : 490/500  -  train loss : 0.052 /   test loss : 1.249
iteration : 500/500  -  train loss : 0.051 /   test loss : 1.232

Training complete   //   Running time : 128  ------------


[Gene 7] Model 3 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([120, 17331])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 17331])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.659 /   test loss : 0.792
iteration : 10/500  -  train loss : 0.517 /   test loss : 0.72
iteration : 20/500  -  train loss : 0.412 /   test loss : 0.694
iteration : 30/500  -  train loss : 0.352 /   test loss : 0.659
iteration : 40/500  -  train loss : 0.315 /   test loss : 0.652
iteration : 50/500  -  train loss : 0.282 /   test loss : 0.639
iteration : 60/500  -  train loss : 0.262 /   test loss : 0.63
iteration : 70/500  -  train loss : 0.243 /   test loss : 0.623
iteration : 80/500  -  train loss : 0.223 /   test loss : 0.613
iteration : 90/500  -  train loss : 0.21 /   test loss : 0.616
iteration : 100/500  -  train loss : 0.198 /   test loss : 0.608
iteration : 110/500  -  train loss : 0.19 /   test loss : 0.617
iteration : 120/500  -  train loss : 0.183 /   test loss : 0.605
iteration : 130/500  -  train loss : 0.17 /   test loss : 0.596
iteration : 140/500  -  train loss : 0.162 /   test loss : 0.592
iteration : 150/500  -  train loss : 0.155 /   test loss : 0.596
iteration : 160/500  -  train loss : 0.142 /   test loss : 0.594
iteration : 170/500  -  train loss : 0.131 /   test loss : 0.595
iteration : 180/500  -  train loss : 0.129 /   test loss : 0.599
iteration : 190/500  -  train loss : 0.123 /   test loss : 0.595
iteration : 200/500  -  train loss : 0.119 /   test loss : 0.593
iteration : 210/500  -  train loss : 0.115 /   test loss : 0.587
iteration : 220/500  -  train loss : 0.112 /   test loss : 0.581
iteration : 230/500  -  train loss : 0.106 /   test loss : 0.587
iteration : 240/500  -  train loss : 0.103 /   test loss : 0.599
iteration : 250/500  -  train loss : 0.102 /   test loss : 0.594
iteration : 260/500  -  train loss : 0.096 /   test loss : 0.592
iteration : 270/500  -  train loss : 0.092 /   test loss : 0.597
iteration : 280/500  -  train loss : 0.092 /   test loss : 0.594
iteration : 290/500  -  train loss : 0.089 /   test loss : 0.589
iteration : 300/500  -  train loss : 0.083 /   test loss : 0.582
iteration : 310/500  -  train loss : 0.082 /   test loss : 0.587
iteration : 320/500  -  train loss : 0.079 /   test loss : 0.582
iteration : 330/500  -  train loss : 0.079 /   test loss : 0.583
iteration : 340/500  -  train loss : 0.076 /   test loss : 0.583
iteration : 350/500  -  train loss : 0.072 /   test loss : 0.579
iteration : 360/500  -  train loss : 0.072 /   test loss : 0.577
iteration : 370/500  -  train loss : 0.069 /   test loss : 0.578
iteration : 380/500  -  train loss : 0.067 /   test loss : 0.578
iteration : 390/500  -  train loss : 0.068 /   test loss : 0.58
iteration : 400/500  -  train loss : 0.065 /   test loss : 0.585
iteration : 410/500  -  train loss : 0.066 /   test loss : 0.589
iteration : 420/500  -  train loss : 0.069 /   test loss : 0.597
iteration : 430/500  -  train loss : 0.069 /   test loss : 0.587
iteration : 440/500  -  train loss : 0.063 /   test loss : 0.58
iteration : 450/500  -  train loss : 0.057 /   test loss : 0.568
iteration : 460/500  -  train loss : 0.058 /   test loss : 0.57
iteration : 470/500  -  train loss : 0.056 /   test loss : 0.57
iteration : 480/500  -  train loss : 0.056 /   test loss : 0.572
iteration : 490/500  -  train loss : 0.057 /   test loss : 0.572
iteration : 500/500  -  train loss : 0.058 /   test loss : 0.572

Training complete   //   Running time : 127  ------------


[Gene 8] Model 3 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 22963])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22963])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.339 /   test loss : 0.334
iteration : 10/500  -  train loss : 0.202 /   test loss : 0.272
iteration : 20/500  -  train loss : 0.16 /   test loss : 0.249
iteration : 30/500  -  train loss : 0.137 /   test loss : 0.239
iteration : 40/500  -  train loss : 0.131 /   test loss : 0.253
iteration : 50/500  -  train loss : 0.121 /   test loss : 0.245
iteration : 60/500  -  train loss : 0.117 /   test loss : 0.246
iteration : 70/500  -  train loss : 0.114 /   test loss : 0.249
iteration : 80/500  -  train loss : 0.111 /   test loss : 0.249
iteration : 90/500  -  train loss : 0.105 /   test loss : 0.25
iteration : 100/500  -  train loss : 0.102 /   test loss : 0.248
iteration : 110/500  -  train loss : 0.097 /   test loss : 0.246
iteration : 120/500  -  train loss : 0.091 /   test loss : 0.243
iteration : 130/500  -  train loss : 0.085 /   test loss : 0.243
iteration : 140/500  -  train loss : 0.082 /   test loss : 0.242
iteration : 150/500  -  train loss : 0.079 /   test loss : 0.242
iteration : 160/500  -  train loss : 0.078 /   test loss : 0.245
iteration : 170/500  -  train loss : 0.074 /   test loss : 0.241
iteration : 180/500  -  train loss : 0.074 /   test loss : 0.24
iteration : 190/500  -  train loss : 0.069 /   test loss : 0.241
iteration : 200/500  -  train loss : 0.066 /   test loss : 0.237
iteration : 210/500  -  train loss : 0.061 /   test loss : 0.235
iteration : 220/500  -  train loss : 0.063 /   test loss : 0.24
iteration : 230/500  -  train loss : 0.061 /   test loss : 0.237
iteration : 240/500  -  train loss : 0.056 /   test loss : 0.235
iteration : 250/500  -  train loss : 0.055 /   test loss : 0.235
iteration : 260/500  -  train loss : 0.054 /   test loss : 0.237
iteration : 270/500  -  train loss : 0.049 /   test loss : 0.233
iteration : 280/500  -  train loss : 0.047 /   test loss : 0.232
iteration : 290/500  -  train loss : 0.049 /   test loss : 0.235
iteration : 300/500  -  train loss : 0.049 /   test loss : 0.234
iteration : 310/500  -  train loss : 0.045 /   test loss : 0.232
iteration : 320/500  -  train loss : 0.044 /   test loss : 0.233
iteration : 330/500  -  train loss : 0.044 /   test loss : 0.231
iteration : 340/500  -  train loss : 0.045 /   test loss : 0.23
iteration : 350/500  -  train loss : 0.047 /   test loss : 0.231
iteration : 360/500  -  train loss : 0.048 /   test loss : 0.231
iteration : 370/500  -  train loss : 0.044 /   test loss : 0.229
iteration : 380/500  -  train loss : 0.04 /   test loss : 0.23
iteration : 390/500  -  train loss : 0.039 /   test loss : 0.23
iteration : 400/500  -  train loss : 0.041 /   test loss : 0.231
iteration : 410/500  -  train loss : 0.04 /   test loss : 0.23
iteration : 420/500  -  train loss : 0.038 /   test loss : 0.23
iteration : 430/500  -  train loss : 0.041 /   test loss : 0.231
iteration : 440/500  -  train loss : 0.039 /   test loss : 0.231
iteration : 450/500  -  train loss : 0.037 /   test loss : 0.229
iteration : 460/500  -  train loss : 0.038 /   test loss : 0.229
iteration : 470/500  -  train loss : 0.037 /   test loss : 0.228
iteration : 480/500  -  train loss : 0.04 /   test loss : 0.23
iteration : 490/500  -  train loss : 0.043 /   test loss : 0.233
iteration : 500/500  -  train loss : 0.041 /   test loss : 0.23

Training complete   //   Running time : 175  ------------


[Gene 8] Model 3 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 22963])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22963])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.292 /   test loss : 0.52
iteration : 10/500  -  train loss : 0.196 /   test loss : 0.418
iteration : 20/500  -  train loss : 0.154 /   test loss : 0.358
iteration : 30/500  -  train loss : 0.139 /   test loss : 0.347
iteration : 40/500  -  train loss : 0.136 /   test loss : 0.349
iteration : 50/500  -  train loss : 0.124 /   test loss : 0.34
iteration : 60/500  -  train loss : 0.119 /   test loss : 0.347
iteration : 70/500  -  train loss : 0.115 /   test loss : 0.348
iteration : 80/500  -  train loss : 0.112 /   test loss : 0.355
iteration : 90/500  -  train loss : 0.108 /   test loss : 0.353
iteration : 100/500  -  train loss : 0.104 /   test loss : 0.349
iteration : 110/500  -  train loss : 0.103 /   test loss : 0.353
iteration : 120/500  -  train loss : 0.101 /   test loss : 0.354
iteration : 130/500  -  train loss : 0.097 /   test loss : 0.351
iteration : 140/500  -  train loss : 0.094 /   test loss : 0.349
iteration : 150/500  -  train loss : 0.088 /   test loss : 0.344
iteration : 160/500  -  train loss : 0.082 /   test loss : 0.341
iteration : 170/500  -  train loss : 0.08 /   test loss : 0.34
iteration : 180/500  -  train loss : 0.078 /   test loss : 0.343
iteration : 190/500  -  train loss : 0.075 /   test loss : 0.34
iteration : 200/500  -  train loss : 0.07 /   test loss : 0.335
iteration : 210/500  -  train loss : 0.067 /   test loss : 0.333
iteration : 220/500  -  train loss : 0.065 /   test loss : 0.329
iteration : 230/500  -  train loss : 0.061 /   test loss : 0.323
iteration : 240/500  -  train loss : 0.059 /   test loss : 0.324
iteration : 250/500  -  train loss : 0.06 /   test loss : 0.33
iteration : 260/500  -  train loss : 0.061 /   test loss : 0.331
iteration : 270/500  -  train loss : 0.06 /   test loss : 0.332
iteration : 280/500  -  train loss : 0.057 /   test loss : 0.329
iteration : 290/500  -  train loss : 0.057 /   test loss : 0.333
iteration : 300/500  -  train loss : 0.056 /   test loss : 0.331
iteration : 310/500  -  train loss : 0.052 /   test loss : 0.325
iteration : 320/500  -  train loss : 0.049 /   test loss : 0.32
iteration : 330/500  -  train loss : 0.05 /   test loss : 0.324
iteration : 340/500  -  train loss : 0.049 /   test loss : 0.324
iteration : 350/500  -  train loss : 0.05 /   test loss : 0.327
iteration : 360/500  -  train loss : 0.05 /   test loss : 0.328
iteration : 370/500  -  train loss : 0.048 /   test loss : 0.327
iteration : 380/500  -  train loss : 0.047 /   test loss : 0.326
iteration : 390/500  -  train loss : 0.045 /   test loss : 0.324
iteration : 400/500  -  train loss : 0.045 /   test loss : 0.324
iteration : 410/500  -  train loss : 0.047 /   test loss : 0.329
iteration : 420/500  -  train loss : 0.047 /   test loss : 0.331
iteration : 430/500  -  train loss : 0.045 /   test loss : 0.33
iteration : 440/500  -  train loss : 0.044 /   test loss : 0.325
iteration : 450/500  -  train loss : 0.043 /   test loss : 0.326
iteration : 460/500  -  train loss : 0.043 /   test loss : 0.326
iteration : 470/500  -  train loss : 0.042 /   test loss : 0.326
iteration : 480/500  -  train loss : 0.043 /   test loss : 0.33
iteration : 490/500  -  train loss : 0.044 /   test loss : 0.331
iteration : 500/500  -  train loss : 0.043 /   test loss : 0.328

Training complete   //   Running time : 169  ------------


[Gene 8] Model 3 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 22963])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22963])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.355 /   test loss : 0.25
iteration : 10/500  -  train loss : 0.242 /   test loss : 0.194
iteration : 20/500  -  train loss : 0.183 /   test loss : 0.178
iteration : 30/500  -  train loss : 0.162 /   test loss : 0.174
iteration : 40/500  -  train loss : 0.157 /   test loss : 0.164
iteration : 50/500  -  train loss : 0.144 /   test loss : 0.166
iteration : 60/500  -  train loss : 0.135 /   test loss : 0.163
iteration : 70/500  -  train loss : 0.128 /   test loss : 0.161
iteration : 80/500  -  train loss : 0.124 /   test loss : 0.166
iteration : 90/500  -  train loss : 0.118 /   test loss : 0.162
iteration : 100/500  -  train loss : 0.109 /   test loss : 0.157
iteration : 110/500  -  train loss : 0.107 /   test loss : 0.155
iteration : 120/500  -  train loss : 0.103 /   test loss : 0.155
iteration : 130/500  -  train loss : 0.099 /   test loss : 0.159
iteration : 140/500  -  train loss : 0.094 /   test loss : 0.16
iteration : 150/500  -  train loss : 0.085 /   test loss : 0.156
iteration : 160/500  -  train loss : 0.083 /   test loss : 0.157
iteration : 170/500  -  train loss : 0.083 /   test loss : 0.16
iteration : 180/500  -  train loss : 0.081 /   test loss : 0.162
iteration : 190/500  -  train loss : 0.076 /   test loss : 0.158
iteration : 200/500  -  train loss : 0.072 /   test loss : 0.158
iteration : 210/500  -  train loss : 0.071 /   test loss : 0.158
iteration : 220/500  -  train loss : 0.067 /   test loss : 0.159
iteration : 230/500  -  train loss : 0.066 /   test loss : 0.159
iteration : 240/500  -  train loss : 0.062 /   test loss : 0.159
iteration : 250/500  -  train loss : 0.062 /   test loss : 0.16
iteration : 260/500  -  train loss : 0.064 /   test loss : 0.161
iteration : 270/500  -  train loss : 0.061 /   test loss : 0.162
iteration : 280/500  -  train loss : 0.058 /   test loss : 0.161
iteration : 290/500  -  train loss : 0.056 /   test loss : 0.16
iteration : 300/500  -  train loss : 0.054 /   test loss : 0.16
iteration : 310/500  -  train loss : 0.054 /   test loss : 0.16
iteration : 320/500  -  train loss : 0.052 /   test loss : 0.158
iteration : 330/500  -  train loss : 0.05 /   test loss : 0.158
iteration : 340/500  -  train loss : 0.048 /   test loss : 0.158
iteration : 350/500  -  train loss : 0.046 /   test loss : 0.156
iteration : 360/500  -  train loss : 0.048 /   test loss : 0.157
iteration : 370/500  -  train loss : 0.053 /   test loss : 0.159
iteration : 380/500  -  train loss : 0.047 /   test loss : 0.156
iteration : 390/500  -  train loss : 0.045 /   test loss : 0.156
iteration : 400/500  -  train loss : 0.043 /   test loss : 0.156
iteration : 410/500  -  train loss : 0.046 /   test loss : 0.158
iteration : 420/500  -  train loss : 0.043 /   test loss : 0.156
iteration : 430/500  -  train loss : 0.043 /   test loss : 0.157
iteration : 440/500  -  train loss : 0.046 /   test loss : 0.158
iteration : 450/500  -  train loss : 0.046 /   test loss : 0.16
iteration : 460/500  -  train loss : 0.043 /   test loss : 0.16
iteration : 470/500  -  train loss : 0.043 /   test loss : 0.157
iteration : 480/500  -  train loss : 0.044 /   test loss : 0.157
iteration : 490/500  -  train loss : 0.043 /   test loss : 0.157
iteration : 500/500  -  train loss : 0.043 /   test loss : 0.156

Training complete   //   Running time : 168  ------------


[Gene 8] Model 3 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 22963])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22963])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.356 /   test loss : 0.249
iteration : 10/500  -  train loss : 0.237 /   test loss : 0.186
iteration : 20/500  -  train loss : 0.185 /   test loss : 0.167
iteration : 30/500  -  train loss : 0.156 /   test loss : 0.171
iteration : 40/500  -  train loss : 0.14 /   test loss : 0.162
iteration : 50/500  -  train loss : 0.137 /   test loss : 0.177
iteration : 60/500  -  train loss : 0.13 /   test loss : 0.177
iteration : 70/500  -  train loss : 0.123 /   test loss : 0.179
iteration : 80/500  -  train loss : 0.118 /   test loss : 0.175
iteration : 90/500  -  train loss : 0.114 /   test loss : 0.175
iteration : 100/500  -  train loss : 0.111 /   test loss : 0.178
iteration : 110/500  -  train loss : 0.105 /   test loss : 0.174
iteration : 120/500  -  train loss : 0.098 /   test loss : 0.173
iteration : 130/500  -  train loss : 0.092 /   test loss : 0.174
iteration : 140/500  -  train loss : 0.088 /   test loss : 0.172
iteration : 150/500  -  train loss : 0.083 /   test loss : 0.175
iteration : 160/500  -  train loss : 0.08 /   test loss : 0.172
iteration : 170/500  -  train loss : 0.079 /   test loss : 0.171
iteration : 180/500  -  train loss : 0.075 /   test loss : 0.176
iteration : 190/500  -  train loss : 0.072 /   test loss : 0.173
iteration : 200/500  -  train loss : 0.069 /   test loss : 0.168
iteration : 210/500  -  train loss : 0.064 /   test loss : 0.172
iteration : 220/500  -  train loss : 0.064 /   test loss : 0.176
iteration : 230/500  -  train loss : 0.062 /   test loss : 0.173
iteration : 240/500  -  train loss : 0.058 /   test loss : 0.17
iteration : 250/500  -  train loss : 0.057 /   test loss : 0.172
iteration : 260/500  -  train loss : 0.058 /   test loss : 0.175
iteration : 270/500  -  train loss : 0.057 /   test loss : 0.174
iteration : 280/500  -  train loss : 0.056 /   test loss : 0.173
iteration : 290/500  -  train loss : 0.058 /   test loss : 0.172
iteration : 300/500  -  train loss : 0.057 /   test loss : 0.173
iteration : 310/500  -  train loss : 0.052 /   test loss : 0.172
iteration : 320/500  -  train loss : 0.049 /   test loss : 0.17
iteration : 330/500  -  train loss : 0.049 /   test loss : 0.174
iteration : 340/500  -  train loss : 0.047 /   test loss : 0.175
iteration : 350/500  -  train loss : 0.048 /   test loss : 0.177
iteration : 360/500  -  train loss : 0.046 /   test loss : 0.178
iteration : 370/500  -  train loss : 0.044 /   test loss : 0.176
iteration : 380/500  -  train loss : 0.042 /   test loss : 0.172
iteration : 390/500  -  train loss : 0.045 /   test loss : 0.175
iteration : 400/500  -  train loss : 0.044 /   test loss : 0.175
iteration : 410/500  -  train loss : 0.042 /   test loss : 0.175
iteration : 420/500  -  train loss : 0.042 /   test loss : 0.175
iteration : 430/500  -  train loss : 0.041 /   test loss : 0.176
iteration : 440/500  -  train loss : 0.042 /   test loss : 0.177
iteration : 450/500  -  train loss : 0.042 /   test loss : 0.178
iteration : 460/500  -  train loss : 0.041 /   test loss : 0.178
iteration : 470/500  -  train loss : 0.043 /   test loss : 0.175
iteration : 480/500  -  train loss : 0.042 /   test loss : 0.173
iteration : 490/500  -  train loss : 0.043 /   test loss : 0.177
iteration : 500/500  -  train loss : 0.044 /   test loss : 0.179

Training complete   //   Running time : 168  ------------


[Gene 8] Model 3 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([120, 22963])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 22963])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.329 /   test loss : 0.333
iteration : 10/500  -  train loss : 0.228 /   test loss : 0.285
iteration : 20/500  -  train loss : 0.174 /   test loss : 0.245
iteration : 30/500  -  train loss : 0.152 /   test loss : 0.236
iteration : 40/500  -  train loss : 0.15 /   test loss : 0.238
iteration : 50/500  -  train loss : 0.141 /   test loss : 0.223
iteration : 60/500  -  train loss : 0.134 /   test loss : 0.224
iteration : 70/500  -  train loss : 0.127 /   test loss : 0.223
iteration : 80/500  -  train loss : 0.121 /   test loss : 0.224
iteration : 90/500  -  train loss : 0.116 /   test loss : 0.226
iteration : 100/500  -  train loss : 0.112 /   test loss : 0.227
iteration : 110/500  -  train loss : 0.108 /   test loss : 0.227
iteration : 120/500  -  train loss : 0.105 /   test loss : 0.225
iteration : 130/500  -  train loss : 0.1 /   test loss : 0.222
iteration : 140/500  -  train loss : 0.097 /   test loss : 0.222
iteration : 150/500  -  train loss : 0.093 /   test loss : 0.222
iteration : 160/500  -  train loss : 0.088 /   test loss : 0.22
iteration : 170/500  -  train loss : 0.08 /   test loss : 0.22
iteration : 180/500  -  train loss : 0.081 /   test loss : 0.223
iteration : 190/500  -  train loss : 0.074 /   test loss : 0.22
iteration : 200/500  -  train loss : 0.072 /   test loss : 0.219
iteration : 210/500  -  train loss : 0.073 /   test loss : 0.22
iteration : 220/500  -  train loss : 0.07 /   test loss : 0.221
iteration : 230/500  -  train loss : 0.066 /   test loss : 0.218
iteration : 240/500  -  train loss : 0.065 /   test loss : 0.218
iteration : 250/500  -  train loss : 0.062 /   test loss : 0.217
iteration : 260/500  -  train loss : 0.06 /   test loss : 0.213
iteration : 270/500  -  train loss : 0.059 /   test loss : 0.216
iteration : 280/500  -  train loss : 0.057 /   test loss : 0.218
iteration : 290/500  -  train loss : 0.058 /   test loss : 0.218
iteration : 300/500  -  train loss : 0.057 /   test loss : 0.217
iteration : 310/500  -  train loss : 0.054 /   test loss : 0.215
iteration : 320/500  -  train loss : 0.052 /   test loss : 0.214
iteration : 330/500  -  train loss : 0.052 /   test loss : 0.217
iteration : 340/500  -  train loss : 0.049 /   test loss : 0.215
iteration : 350/500  -  train loss : 0.051 /   test loss : 0.219
iteration : 360/500  -  train loss : 0.051 /   test loss : 0.216
iteration : 370/500  -  train loss : 0.05 /   test loss : 0.216
iteration : 380/500  -  train loss : 0.049 /   test loss : 0.214
iteration : 390/500  -  train loss : 0.044 /   test loss : 0.21
iteration : 400/500  -  train loss : 0.043 /   test loss : 0.211
iteration : 410/500  -  train loss : 0.045 /   test loss : 0.214
iteration : 420/500  -  train loss : 0.046 /   test loss : 0.215
iteration : 430/500  -  train loss : 0.046 /   test loss : 0.215
iteration : 440/500  -  train loss : 0.049 /   test loss : 0.216
iteration : 450/500  -  train loss : 0.047 /   test loss : 0.212
iteration : 460/500  -  train loss : 0.044 /   test loss : 0.212
iteration : 470/500  -  train loss : 0.042 /   test loss : 0.213
iteration : 480/500  -  train loss : 0.042 /   test loss : 0.216
iteration : 490/500  -  train loss : 0.038 /   test loss : 0.211
iteration : 500/500  -  train loss : 0.042 /   test loss : 0.212

Training complete   //   Running time : 166  ------------


[Gene 9] Model 3 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 22048])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22048])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.929 /   test loss : 0.826
iteration : 10/500  -  train loss : 0.807 /   test loss : 0.814
iteration : 20/500  -  train loss : 0.717 /   test loss : 0.818
iteration : 30/500  -  train loss : 0.666 /   test loss : 0.814
iteration : 40/500  -  train loss : 0.619 /   test loss : 0.803
iteration : 50/500  -  train loss : 0.584 /   test loss : 0.79
iteration : 60/500  -  train loss : 0.556 /   test loss : 0.781
iteration : 70/500  -  train loss : 0.531 /   test loss : 0.789
iteration : 80/500  -  train loss : 0.505 /   test loss : 0.795
iteration : 90/500  -  train loss : 0.484 /   test loss : 0.804
iteration : 100/500  -  train loss : 0.462 /   test loss : 0.799
iteration : 110/500  -  train loss : 0.448 /   test loss : 0.783
iteration : 120/500  -  train loss : 0.433 /   test loss : 0.78
iteration : 130/500  -  train loss : 0.41 /   test loss : 0.789
iteration : 140/500  -  train loss : 0.393 /   test loss : 0.791
iteration : 150/500  -  train loss : 0.373 /   test loss : 0.775
iteration : 160/500  -  train loss : 0.356 /   test loss : 0.775
iteration : 170/500  -  train loss : 0.344 /   test loss : 0.786
iteration : 180/500  -  train loss : 0.328 /   test loss : 0.782
iteration : 190/500  -  train loss : 0.314 /   test loss : 0.77
iteration : 200/500  -  train loss : 0.298 /   test loss : 0.776
iteration : 210/500  -  train loss : 0.285 /   test loss : 0.781
iteration : 220/500  -  train loss : 0.272 /   test loss : 0.784
iteration : 230/500  -  train loss : 0.257 /   test loss : 0.774
iteration : 240/500  -  train loss : 0.243 /   test loss : 0.776
iteration : 250/500  -  train loss : 0.232 /   test loss : 0.776
iteration : 260/500  -  train loss : 0.226 /   test loss : 0.774
iteration : 270/500  -  train loss : 0.216 /   test loss : 0.776
iteration : 280/500  -  train loss : 0.208 /   test loss : 0.761
iteration : 290/500  -  train loss : 0.2 /   test loss : 0.772
iteration : 300/500  -  train loss : 0.192 /   test loss : 0.769
iteration : 310/500  -  train loss : 0.188 /   test loss : 0.767
iteration : 320/500  -  train loss : 0.179 /   test loss : 0.77
iteration : 330/500  -  train loss : 0.173 /   test loss : 0.764
iteration : 340/500  -  train loss : 0.163 /   test loss : 0.763
iteration : 350/500  -  train loss : 0.161 /   test loss : 0.759
iteration : 360/500  -  train loss : 0.155 /   test loss : 0.764
iteration : 370/500  -  train loss : 0.146 /   test loss : 0.754
iteration : 380/500  -  train loss : 0.14 /   test loss : 0.758
iteration : 390/500  -  train loss : 0.136 /   test loss : 0.751
iteration : 400/500  -  train loss : 0.133 /   test loss : 0.744
iteration : 410/500  -  train loss : 0.131 /   test loss : 0.744
iteration : 420/500  -  train loss : 0.131 /   test loss : 0.746
iteration : 430/500  -  train loss : 0.128 /   test loss : 0.748
iteration : 440/500  -  train loss : 0.125 /   test loss : 0.744
iteration : 450/500  -  train loss : 0.118 /   test loss : 0.741
iteration : 460/500  -  train loss : 0.115 /   test loss : 0.736
iteration : 470/500  -  train loss : 0.109 /   test loss : 0.744
iteration : 480/500  -  train loss : 0.107 /   test loss : 0.749
iteration : 490/500  -  train loss : 0.105 /   test loss : 0.737
iteration : 500/500  -  train loss : 0.103 /   test loss : 0.733

Training complete   //   Running time : 166  ------------


[Gene 9] Model 3 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 22048])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22048])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.97 /   test loss : 0.659
iteration : 10/500  -  train loss : 0.861 /   test loss : 0.619
iteration : 20/500  -  train loss : 0.764 /   test loss : 0.59
iteration : 30/500  -  train loss : 0.701 /   test loss : 0.591
iteration : 40/500  -  train loss : 0.649 /   test loss : 0.59
iteration : 50/500  -  train loss : 0.61 /   test loss : 0.599
iteration : 60/500  -  train loss : 0.576 /   test loss : 0.591
iteration : 70/500  -  train loss : 0.552 /   test loss : 0.597
iteration : 80/500  -  train loss : 0.526 /   test loss : 0.596
iteration : 90/500  -  train loss : 0.502 /   test loss : 0.597
iteration : 100/500  -  train loss : 0.479 /   test loss : 0.598
iteration : 110/500  -  train loss : 0.46 /   test loss : 0.593
iteration : 120/500  -  train loss : 0.439 /   test loss : 0.596
iteration : 130/500  -  train loss : 0.416 /   test loss : 0.597
iteration : 140/500  -  train loss : 0.396 /   test loss : 0.599
iteration : 150/500  -  train loss : 0.377 /   test loss : 0.599
iteration : 160/500  -  train loss : 0.359 /   test loss : 0.602
iteration : 170/500  -  train loss : 0.339 /   test loss : 0.598
iteration : 180/500  -  train loss : 0.323 /   test loss : 0.597
iteration : 190/500  -  train loss : 0.308 /   test loss : 0.597
iteration : 200/500  -  train loss : 0.289 /   test loss : 0.607
iteration : 210/500  -  train loss : 0.275 /   test loss : 0.612
iteration : 220/500  -  train loss : 0.259 /   test loss : 0.608
iteration : 230/500  -  train loss : 0.248 /   test loss : 0.611
iteration : 240/500  -  train loss : 0.235 /   test loss : 0.613
iteration : 250/500  -  train loss : 0.223 /   test loss : 0.61
iteration : 260/500  -  train loss : 0.215 /   test loss : 0.61
iteration : 270/500  -  train loss : 0.207 /   test loss : 0.61
iteration : 280/500  -  train loss : 0.204 /   test loss : 0.61
iteration : 290/500  -  train loss : 0.19 /   test loss : 0.615
iteration : 300/500  -  train loss : 0.178 /   test loss : 0.616
iteration : 310/500  -  train loss : 0.17 /   test loss : 0.615
iteration : 320/500  -  train loss : 0.159 /   test loss : 0.617
iteration : 330/500  -  train loss : 0.154 /   test loss : 0.621
iteration : 340/500  -  train loss : 0.143 /   test loss : 0.626
iteration : 350/500  -  train loss : 0.142 /   test loss : 0.625
iteration : 360/500  -  train loss : 0.141 /   test loss : 0.623
iteration : 370/500  -  train loss : 0.136 /   test loss : 0.624
iteration : 380/500  -  train loss : 0.128 /   test loss : 0.622
iteration : 390/500  -  train loss : 0.129 /   test loss : 0.617
iteration : 400/500  -  train loss : 0.125 /   test loss : 0.617
iteration : 410/500  -  train loss : 0.12 /   test loss : 0.619
iteration : 420/500  -  train loss : 0.116 /   test loss : 0.621
iteration : 430/500  -  train loss : 0.11 /   test loss : 0.618
iteration : 440/500  -  train loss : 0.106 /   test loss : 0.618
iteration : 450/500  -  train loss : 0.102 /   test loss : 0.62
iteration : 460/500  -  train loss : 0.101 /   test loss : 0.626
iteration : 470/500  -  train loss : 0.101 /   test loss : 0.624
iteration : 480/500  -  train loss : 0.096 /   test loss : 0.621
iteration : 490/500  -  train loss : 0.093 /   test loss : 0.624
iteration : 500/500  -  train loss : 0.091 /   test loss : 0.625

Training complete   //   Running time : 160  ------------


[Gene 9] Model 3 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 22048])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22048])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.778 /   test loss : 1.45
iteration : 10/500  -  train loss : 0.675 /   test loss : 1.426
iteration : 20/500  -  train loss : 0.589 /   test loss : 1.403
iteration : 30/500  -  train loss : 0.535 /   test loss : 1.387
iteration : 40/500  -  train loss : 0.494 /   test loss : 1.388
iteration : 50/500  -  train loss : 0.46 /   test loss : 1.388
iteration : 60/500  -  train loss : 0.433 /   test loss : 1.386
iteration : 70/500  -  train loss : 0.42 /   test loss : 1.378
iteration : 80/500  -  train loss : 0.408 /   test loss : 1.374
iteration : 90/500  -  train loss : 0.387 /   test loss : 1.374
iteration : 100/500  -  train loss : 0.367 /   test loss : 1.371
iteration : 110/500  -  train loss : 0.348 /   test loss : 1.375
iteration : 120/500  -  train loss : 0.33 /   test loss : 1.381
iteration : 130/500  -  train loss : 0.314 /   test loss : 1.379
iteration : 140/500  -  train loss : 0.299 /   test loss : 1.378
iteration : 150/500  -  train loss : 0.284 /   test loss : 1.382
iteration : 160/500  -  train loss : 0.272 /   test loss : 1.382
iteration : 170/500  -  train loss : 0.261 /   test loss : 1.382
iteration : 180/500  -  train loss : 0.249 /   test loss : 1.384
iteration : 190/500  -  train loss : 0.236 /   test loss : 1.387
iteration : 200/500  -  train loss : 0.228 /   test loss : 1.388
iteration : 210/500  -  train loss : 0.217 /   test loss : 1.387
iteration : 220/500  -  train loss : 0.209 /   test loss : 1.39
iteration : 230/500  -  train loss : 0.195 /   test loss : 1.387
iteration : 240/500  -  train loss : 0.183 /   test loss : 1.394
iteration : 250/500  -  train loss : 0.171 /   test loss : 1.385
iteration : 260/500  -  train loss : 0.164 /   test loss : 1.384
iteration : 270/500  -  train loss : 0.16 /   test loss : 1.385
iteration : 280/500  -  train loss : 0.158 /   test loss : 1.38
iteration : 290/500  -  train loss : 0.151 /   test loss : 1.381
iteration : 300/500  -  train loss : 0.139 /   test loss : 1.391
iteration : 310/500  -  train loss : 0.133 /   test loss : 1.385
iteration : 320/500  -  train loss : 0.13 /   test loss : 1.38
iteration : 330/500  -  train loss : 0.126 /   test loss : 1.376
iteration : 340/500  -  train loss : 0.123 /   test loss : 1.371
iteration : 350/500  -  train loss : 0.122 /   test loss : 1.377
iteration : 360/500  -  train loss : 0.116 /   test loss : 1.383
iteration : 370/500  -  train loss : 0.112 /   test loss : 1.381
iteration : 380/500  -  train loss : 0.105 /   test loss : 1.377
iteration : 390/500  -  train loss : 0.106 /   test loss : 1.372
iteration : 400/500  -  train loss : 0.103 /   test loss : 1.37
iteration : 410/500  -  train loss : 0.1 /   test loss : 1.374
iteration : 420/500  -  train loss : 0.095 /   test loss : 1.376
iteration : 430/500  -  train loss : 0.092 /   test loss : 1.383
iteration : 440/500  -  train loss : 0.092 /   test loss : 1.384
iteration : 450/500  -  train loss : 0.09 /   test loss : 1.381
iteration : 460/500  -  train loss : 0.09 /   test loss : 1.381
iteration : 470/500  -  train loss : 0.09 /   test loss : 1.383
iteration : 480/500  -  train loss : 0.088 /   test loss : 1.386
iteration : 490/500  -  train loss : 0.086 /   test loss : 1.384
iteration : 500/500  -  train loss : 0.082 /   test loss : 1.383

Training complete   //   Running time : 159  ------------


[Gene 9] Model 3 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 22048])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 22048])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.926 /   test loss : 0.841
iteration : 10/500  -  train loss : 0.823 /   test loss : 0.871
iteration : 20/500  -  train loss : 0.725 /   test loss : 0.815
iteration : 30/500  -  train loss : 0.666 /   test loss : 0.826
iteration : 40/500  -  train loss : 0.617 /   test loss : 0.821
iteration : 50/500  -  train loss : 0.571 /   test loss : 0.807
iteration : 60/500  -  train loss : 0.534 /   test loss : 0.793
iteration : 70/500  -  train loss : 0.512 /   test loss : 0.801
iteration : 80/500  -  train loss : 0.486 /   test loss : 0.793
iteration : 90/500  -  train loss : 0.46 /   test loss : 0.82
iteration : 100/500  -  train loss : 0.438 /   test loss : 0.832
iteration : 110/500  -  train loss : 0.418 /   test loss : 0.827
iteration : 120/500  -  train loss : 0.403 /   test loss : 0.831
iteration : 130/500  -  train loss : 0.384 /   test loss : 0.828
iteration : 140/500  -  train loss : 0.369 /   test loss : 0.825
iteration : 150/500  -  train loss : 0.351 /   test loss : 0.841
iteration : 160/500  -  train loss : 0.334 /   test loss : 0.835
iteration : 170/500  -  train loss : 0.319 /   test loss : 0.837
iteration : 180/500  -  train loss : 0.304 /   test loss : 0.85
iteration : 190/500  -  train loss : 0.289 /   test loss : 0.855
iteration : 200/500  -  train loss : 0.272 /   test loss : 0.849
iteration : 210/500  -  train loss : 0.26 /   test loss : 0.853
iteration : 220/500  -  train loss : 0.252 /   test loss : 0.848
iteration : 230/500  -  train loss : 0.237 /   test loss : 0.853
iteration : 240/500  -  train loss : 0.225 /   test loss : 0.853
iteration : 250/500  -  train loss : 0.214 /   test loss : 0.862
iteration : 260/500  -  train loss : 0.206 /   test loss : 0.867
iteration : 270/500  -  train loss : 0.199 /   test loss : 0.854
iteration : 280/500  -  train loss : 0.193 /   test loss : 0.85
iteration : 290/500  -  train loss : 0.182 /   test loss : 0.856
iteration : 300/500  -  train loss : 0.174 /   test loss : 0.861
iteration : 310/500  -  train loss : 0.164 /   test loss : 0.856
iteration : 320/500  -  train loss : 0.16 /   test loss : 0.859
iteration : 330/500  -  train loss : 0.155 /   test loss : 0.868
iteration : 340/500  -  train loss : 0.149 /   test loss : 0.874
iteration : 350/500  -  train loss : 0.148 /   test loss : 0.881
iteration : 360/500  -  train loss : 0.146 /   test loss : 0.88
iteration : 370/500  -  train loss : 0.144 /   test loss : 0.883
iteration : 380/500  -  train loss : 0.136 /   test loss : 0.881
iteration : 390/500  -  train loss : 0.132 /   test loss : 0.885
iteration : 400/500  -  train loss : 0.128 /   test loss : 0.882
iteration : 410/500  -  train loss : 0.128 /   test loss : 0.879
iteration : 420/500  -  train loss : 0.123 /   test loss : 0.885
iteration : 430/500  -  train loss : 0.117 /   test loss : 0.887
iteration : 440/500  -  train loss : 0.112 /   test loss : 0.893
iteration : 450/500  -  train loss : 0.106 /   test loss : 0.896
iteration : 460/500  -  train loss : 0.101 /   test loss : 0.898
iteration : 470/500  -  train loss : 0.1 /   test loss : 0.899
iteration : 480/500  -  train loss : 0.098 /   test loss : 0.896
iteration : 490/500  -  train loss : 0.093 /   test loss : 0.895
iteration : 500/500  -  train loss : 0.089 /   test loss : 0.904

Training complete   //   Running time : 159  ------------


[Gene 9] Model 3 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([120, 22048])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 22048])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.938 /   test loss : 0.8
iteration : 10/500  -  train loss : 0.826 /   test loss : 0.751
iteration : 20/500  -  train loss : 0.741 /   test loss : 0.718
iteration : 30/500  -  train loss : 0.682 /   test loss : 0.713
iteration : 40/500  -  train loss : 0.627 /   test loss : 0.703
iteration : 50/500  -  train loss : 0.588 /   test loss : 0.698
iteration : 60/500  -  train loss : 0.555 /   test loss : 0.688
iteration : 70/500  -  train loss : 0.53 /   test loss : 0.686
iteration : 80/500  -  train loss : 0.502 /   test loss : 0.683
iteration : 90/500  -  train loss : 0.476 /   test loss : 0.679
iteration : 100/500  -  train loss : 0.453 /   test loss : 0.685
iteration : 110/500  -  train loss : 0.438 /   test loss : 0.684
iteration : 120/500  -  train loss : 0.421 /   test loss : 0.677
iteration : 130/500  -  train loss : 0.402 /   test loss : 0.675
iteration : 140/500  -  train loss : 0.383 /   test loss : 0.673
iteration : 150/500  -  train loss : 0.367 /   test loss : 0.671
iteration : 160/500  -  train loss : 0.345 /   test loss : 0.672
iteration : 170/500  -  train loss : 0.329 /   test loss : 0.675
iteration : 180/500  -  train loss : 0.313 /   test loss : 0.672
iteration : 190/500  -  train loss : 0.297 /   test loss : 0.67
iteration : 200/500  -  train loss : 0.284 /   test loss : 0.668
iteration : 210/500  -  train loss : 0.274 /   test loss : 0.668
iteration : 220/500  -  train loss : 0.262 /   test loss : 0.67
iteration : 230/500  -  train loss : 0.25 /   test loss : 0.668
iteration : 240/500  -  train loss : 0.24 /   test loss : 0.67
iteration : 250/500  -  train loss : 0.228 /   test loss : 0.673
iteration : 260/500  -  train loss : 0.217 /   test loss : 0.67
iteration : 270/500  -  train loss : 0.208 /   test loss : 0.672
iteration : 280/500  -  train loss : 0.2 /   test loss : 0.676
iteration : 290/500  -  train loss : 0.19 /   test loss : 0.676
iteration : 300/500  -  train loss : 0.176 /   test loss : 0.675
iteration : 310/500  -  train loss : 0.169 /   test loss : 0.679
iteration : 320/500  -  train loss : 0.166 /   test loss : 0.68
iteration : 330/500  -  train loss : 0.164 /   test loss : 0.68
iteration : 340/500  -  train loss : 0.156 /   test loss : 0.677
iteration : 350/500  -  train loss : 0.147 /   test loss : 0.674
iteration : 360/500  -  train loss : 0.137 /   test loss : 0.676
iteration : 370/500  -  train loss : 0.135 /   test loss : 0.682
iteration : 380/500  -  train loss : 0.133 /   test loss : 0.681
iteration : 390/500  -  train loss : 0.127 /   test loss : 0.68
iteration : 400/500  -  train loss : 0.127 /   test loss : 0.681
iteration : 410/500  -  train loss : 0.123 /   test loss : 0.682
iteration : 420/500  -  train loss : 0.116 /   test loss : 0.684
iteration : 430/500  -  train loss : 0.111 /   test loss : 0.686
iteration : 440/500  -  train loss : 0.112 /   test loss : 0.688
iteration : 450/500  -  train loss : 0.105 /   test loss : 0.688
iteration : 460/500  -  train loss : 0.105 /   test loss : 0.691
iteration : 470/500  -  train loss : 0.101 /   test loss : 0.687
iteration : 480/500  -  train loss : 0.094 /   test loss : 0.688
iteration : 490/500  -  train loss : 0.099 /   test loss : 0.693
iteration : 500/500  -  train loss : 0.1 /   test loss : 0.692

Training complete   //   Running time : 159  ------------


[Gene 10] Model 3 ( tissue 27 ) - 1/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 12638])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 12638])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.223 /   test loss : 0.221
iteration : 10/500  -  train loss : 0.172 /   test loss : 0.215
iteration : 20/500  -  train loss : 0.134 /   test loss : 0.202
iteration : 30/500  -  train loss : 0.114 /   test loss : 0.195
iteration : 40/500  -  train loss : 0.1 /   test loss : 0.193
iteration : 50/500  -  train loss : 0.091 /   test loss : 0.189
iteration : 60/500  -  train loss : 0.085 /   test loss : 0.184
iteration : 70/500  -  train loss : 0.08 /   test loss : 0.182
iteration : 80/500  -  train loss : 0.074 /   test loss : 0.181
iteration : 90/500  -  train loss : 0.071 /   test loss : 0.179
iteration : 100/500  -  train loss : 0.069 /   test loss : 0.18
iteration : 110/500  -  train loss : 0.068 /   test loss : 0.181
iteration : 120/500  -  train loss : 0.064 /   test loss : 0.179
iteration : 130/500  -  train loss : 0.062 /   test loss : 0.178
iteration : 140/500  -  train loss : 0.059 /   test loss : 0.177
iteration : 150/500  -  train loss : 0.057 /   test loss : 0.177
iteration : 160/500  -  train loss : 0.054 /   test loss : 0.175
iteration : 170/500  -  train loss : 0.053 /   test loss : 0.176
iteration : 180/500  -  train loss : 0.05 /   test loss : 0.174
iteration : 190/500  -  train loss : 0.048 /   test loss : 0.173
iteration : 200/500  -  train loss : 0.046 /   test loss : 0.172
iteration : 210/500  -  train loss : 0.045 /   test loss : 0.173
iteration : 220/500  -  train loss : 0.043 /   test loss : 0.172
iteration : 230/500  -  train loss : 0.042 /   test loss : 0.174
iteration : 240/500  -  train loss : 0.039 /   test loss : 0.173
iteration : 250/500  -  train loss : 0.038 /   test loss : 0.174
iteration : 260/500  -  train loss : 0.036 /   test loss : 0.173
iteration : 270/500  -  train loss : 0.035 /   test loss : 0.174
iteration : 280/500  -  train loss : 0.034 /   test loss : 0.175
iteration : 290/500  -  train loss : 0.035 /   test loss : 0.174
iteration : 300/500  -  train loss : 0.034 /   test loss : 0.175
iteration : 310/500  -  train loss : 0.032 /   test loss : 0.174
iteration : 320/500  -  train loss : 0.031 /   test loss : 0.175
iteration : 330/500  -  train loss : 0.031 /   test loss : 0.175
iteration : 340/500  -  train loss : 0.03 /   test loss : 0.176
iteration : 350/500  -  train loss : 0.029 /   test loss : 0.175
iteration : 360/500  -  train loss : 0.029 /   test loss : 0.174
iteration : 370/500  -  train loss : 0.029 /   test loss : 0.174
iteration : 380/500  -  train loss : 0.029 /   test loss : 0.173
iteration : 390/500  -  train loss : 0.028 /   test loss : 0.173
iteration : 400/500  -  train loss : 0.027 /   test loss : 0.173
iteration : 410/500  -  train loss : 0.025 /   test loss : 0.173
iteration : 420/500  -  train loss : 0.024 /   test loss : 0.173
iteration : 430/500  -  train loss : 0.025 /   test loss : 0.174
iteration : 440/500  -  train loss : 0.026 /   test loss : 0.174
iteration : 450/500  -  train loss : 0.024 /   test loss : 0.173
iteration : 460/500  -  train loss : 0.024 /   test loss : 0.173
iteration : 470/500  -  train loss : 0.023 /   test loss : 0.173
iteration : 480/500  -  train loss : 0.023 /   test loss : 0.174
iteration : 490/500  -  train loss : 0.024 /   test loss : 0.174
iteration : 500/500  -  train loss : 0.023 /   test loss : 0.174

Training complete   //   Running time :  99  ------------


[Gene 10] Model 3 ( tissue 27 ) - 2/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 12638])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 12638])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.227 /   test loss : 0.204
iteration : 10/500  -  train loss : 0.179 /   test loss : 0.201
iteration : 20/500  -  train loss : 0.141 /   test loss : 0.169
iteration : 30/500  -  train loss : 0.12 /   test loss : 0.159
iteration : 40/500  -  train loss : 0.107 /   test loss : 0.158
iteration : 50/500  -  train loss : 0.098 /   test loss : 0.156
iteration : 60/500  -  train loss : 0.091 /   test loss : 0.154
iteration : 70/500  -  train loss : 0.085 /   test loss : 0.155
iteration : 80/500  -  train loss : 0.08 /   test loss : 0.155
iteration : 90/500  -  train loss : 0.078 /   test loss : 0.158
iteration : 100/500  -  train loss : 0.075 /   test loss : 0.159
iteration : 110/500  -  train loss : 0.072 /   test loss : 0.162
iteration : 120/500  -  train loss : 0.069 /   test loss : 0.156
iteration : 130/500  -  train loss : 0.066 /   test loss : 0.155
iteration : 140/500  -  train loss : 0.064 /   test loss : 0.157
iteration : 150/500  -  train loss : 0.06 /   test loss : 0.159
iteration : 160/500  -  train loss : 0.058 /   test loss : 0.159
iteration : 170/500  -  train loss : 0.057 /   test loss : 0.157
iteration : 180/500  -  train loss : 0.055 /   test loss : 0.157
iteration : 190/500  -  train loss : 0.053 /   test loss : 0.158
iteration : 200/500  -  train loss : 0.052 /   test loss : 0.158
iteration : 210/500  -  train loss : 0.051 /   test loss : 0.158
iteration : 220/500  -  train loss : 0.048 /   test loss : 0.158
iteration : 230/500  -  train loss : 0.046 /   test loss : 0.157
iteration : 240/500  -  train loss : 0.045 /   test loss : 0.155
iteration : 250/500  -  train loss : 0.043 /   test loss : 0.153
iteration : 260/500  -  train loss : 0.041 /   test loss : 0.154
iteration : 270/500  -  train loss : 0.039 /   test loss : 0.154
iteration : 280/500  -  train loss : 0.039 /   test loss : 0.154
iteration : 290/500  -  train loss : 0.039 /   test loss : 0.153
iteration : 300/500  -  train loss : 0.038 /   test loss : 0.153
iteration : 310/500  -  train loss : 0.036 /   test loss : 0.156
iteration : 320/500  -  train loss : 0.035 /   test loss : 0.155
iteration : 330/500  -  train loss : 0.035 /   test loss : 0.155
iteration : 340/500  -  train loss : 0.035 /   test loss : 0.156
iteration : 350/500  -  train loss : 0.034 /   test loss : 0.156
iteration : 360/500  -  train loss : 0.033 /   test loss : 0.156
iteration : 370/500  -  train loss : 0.033 /   test loss : 0.153
iteration : 380/500  -  train loss : 0.032 /   test loss : 0.155
iteration : 390/500  -  train loss : 0.032 /   test loss : 0.155
iteration : 400/500  -  train loss : 0.032 /   test loss : 0.155
iteration : 410/500  -  train loss : 0.032 /   test loss : 0.156
iteration : 420/500  -  train loss : 0.031 /   test loss : 0.156
iteration : 430/500  -  train loss : 0.031 /   test loss : 0.155
iteration : 440/500  -  train loss : 0.03 /   test loss : 0.154
iteration : 450/500  -  train loss : 0.029 /   test loss : 0.154
iteration : 460/500  -  train loss : 0.029 /   test loss : 0.155
iteration : 470/500  -  train loss : 0.028 /   test loss : 0.153
iteration : 480/500  -  train loss : 0.027 /   test loss : 0.152
iteration : 490/500  -  train loss : 0.027 /   test loss : 0.154
iteration : 500/500  -  train loss : 0.027 /   test loss : 0.154

Training complete   //   Running time :  95  ------------


[Gene 10] Model 3 ( tissue 27 ) - 3/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 12638])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 12638])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.208 /   test loss : 0.285
iteration : 10/500  -  train loss : 0.167 /   test loss : 0.245
iteration : 20/500  -  train loss : 0.134 /   test loss : 0.22
iteration : 30/500  -  train loss : 0.114 /   test loss : 0.208
iteration : 40/500  -  train loss : 0.103 /   test loss : 0.2
iteration : 50/500  -  train loss : 0.092 /   test loss : 0.199
iteration : 60/500  -  train loss : 0.086 /   test loss : 0.198
iteration : 70/500  -  train loss : 0.08 /   test loss : 0.2
iteration : 80/500  -  train loss : 0.077 /   test loss : 0.197
iteration : 90/500  -  train loss : 0.074 /   test loss : 0.193
iteration : 100/500  -  train loss : 0.072 /   test loss : 0.191
iteration : 110/500  -  train loss : 0.068 /   test loss : 0.195
iteration : 120/500  -  train loss : 0.065 /   test loss : 0.194
iteration : 130/500  -  train loss : 0.062 /   test loss : 0.195
iteration : 140/500  -  train loss : 0.061 /   test loss : 0.194
iteration : 150/500  -  train loss : 0.058 /   test loss : 0.193
iteration : 160/500  -  train loss : 0.056 /   test loss : 0.191
iteration : 170/500  -  train loss : 0.054 /   test loss : 0.19
iteration : 180/500  -  train loss : 0.052 /   test loss : 0.19
iteration : 190/500  -  train loss : 0.05 /   test loss : 0.188
iteration : 200/500  -  train loss : 0.048 /   test loss : 0.188
iteration : 210/500  -  train loss : 0.047 /   test loss : 0.186
iteration : 220/500  -  train loss : 0.045 /   test loss : 0.184
iteration : 230/500  -  train loss : 0.044 /   test loss : 0.183
iteration : 240/500  -  train loss : 0.041 /   test loss : 0.184
iteration : 250/500  -  train loss : 0.039 /   test loss : 0.185
iteration : 260/500  -  train loss : 0.038 /   test loss : 0.182
iteration : 270/500  -  train loss : 0.037 /   test loss : 0.181
iteration : 280/500  -  train loss : 0.036 /   test loss : 0.183
iteration : 290/500  -  train loss : 0.036 /   test loss : 0.183
iteration : 300/500  -  train loss : 0.034 /   test loss : 0.184
iteration : 310/500  -  train loss : 0.034 /   test loss : 0.181
iteration : 320/500  -  train loss : 0.033 /   test loss : 0.179
iteration : 330/500  -  train loss : 0.032 /   test loss : 0.18
iteration : 340/500  -  train loss : 0.032 /   test loss : 0.181
iteration : 350/500  -  train loss : 0.031 /   test loss : 0.18
iteration : 360/500  -  train loss : 0.03 /   test loss : 0.179
iteration : 370/500  -  train loss : 0.031 /   test loss : 0.181
iteration : 380/500  -  train loss : 0.03 /   test loss : 0.18
iteration : 390/500  -  train loss : 0.028 /   test loss : 0.179
iteration : 400/500  -  train loss : 0.028 /   test loss : 0.18
iteration : 410/500  -  train loss : 0.03 /   test loss : 0.182
iteration : 420/500  -  train loss : 0.029 /   test loss : 0.181
iteration : 430/500  -  train loss : 0.028 /   test loss : 0.179
iteration : 440/500  -  train loss : 0.027 /   test loss : 0.179
iteration : 450/500  -  train loss : 0.026 /   test loss : 0.178
iteration : 460/500  -  train loss : 0.026 /   test loss : 0.179
iteration : 470/500  -  train loss : 0.025 /   test loss : 0.178
iteration : 480/500  -  train loss : 0.024 /   test loss : 0.177
iteration : 490/500  -  train loss : 0.024 /   test loss : 0.177
iteration : 500/500  -  train loss : 0.024 /   test loss : 0.177

Training complete   //   Running time :  95  ------------


[Gene 10] Model 3 ( tissue 27 ) - 4/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([123, 12638])  /  torch.Size([123, 1])
Test data :  torch.Size([30, 12638])  /  torch.Size([30, 1])


iteration : 0/500  -  train loss : 0.226 /   test loss : 0.204
iteration : 10/500  -  train loss : 0.18 /   test loss : 0.181
iteration : 20/500  -  train loss : 0.143 /   test loss : 0.17
iteration : 30/500  -  train loss : 0.118 /   test loss : 0.167
iteration : 40/500  -  train loss : 0.104 /   test loss : 0.165
iteration : 50/500  -  train loss : 0.095 /   test loss : 0.165
iteration : 60/500  -  train loss : 0.09 /   test loss : 0.164
iteration : 70/500  -  train loss : 0.085 /   test loss : 0.164
iteration : 80/500  -  train loss : 0.081 /   test loss : 0.166
iteration : 90/500  -  train loss : 0.078 /   test loss : 0.167
iteration : 100/500  -  train loss : 0.074 /   test loss : 0.167
iteration : 110/500  -  train loss : 0.07 /   test loss : 0.164
iteration : 120/500  -  train loss : 0.066 /   test loss : 0.164
iteration : 130/500  -  train loss : 0.064 /   test loss : 0.162
iteration : 140/500  -  train loss : 0.062 /   test loss : 0.163
iteration : 150/500  -  train loss : 0.059 /   test loss : 0.164
iteration : 160/500  -  train loss : 0.056 /   test loss : 0.163
iteration : 170/500  -  train loss : 0.053 /   test loss : 0.16
iteration : 180/500  -  train loss : 0.051 /   test loss : 0.159
iteration : 190/500  -  train loss : 0.048 /   test loss : 0.159
iteration : 200/500  -  train loss : 0.046 /   test loss : 0.159
iteration : 210/500  -  train loss : 0.045 /   test loss : 0.16
iteration : 220/500  -  train loss : 0.043 /   test loss : 0.161
iteration : 230/500  -  train loss : 0.043 /   test loss : 0.159
iteration : 240/500  -  train loss : 0.041 /   test loss : 0.16
iteration : 250/500  -  train loss : 0.039 /   test loss : 0.161
iteration : 260/500  -  train loss : 0.039 /   test loss : 0.162
iteration : 270/500  -  train loss : 0.037 /   test loss : 0.16
iteration : 280/500  -  train loss : 0.036 /   test loss : 0.158
iteration : 290/500  -  train loss : 0.037 /   test loss : 0.16
iteration : 300/500  -  train loss : 0.036 /   test loss : 0.162
iteration : 310/500  -  train loss : 0.036 /   test loss : 0.161
iteration : 320/500  -  train loss : 0.035 /   test loss : 0.161
iteration : 330/500  -  train loss : 0.034 /   test loss : 0.16
iteration : 340/500  -  train loss : 0.033 /   test loss : 0.161
iteration : 350/500  -  train loss : 0.032 /   test loss : 0.161
iteration : 360/500  -  train loss : 0.032 /   test loss : 0.161
iteration : 370/500  -  train loss : 0.031 /   test loss : 0.161
iteration : 380/500  -  train loss : 0.03 /   test loss : 0.162
iteration : 390/500  -  train loss : 0.03 /   test loss : 0.163
iteration : 400/500  -  train loss : 0.03 /   test loss : 0.163
iteration : 410/500  -  train loss : 0.029 /   test loss : 0.165
iteration : 420/500  -  train loss : 0.028 /   test loss : 0.164
iteration : 430/500  -  train loss : 0.027 /   test loss : 0.163
iteration : 440/500  -  train loss : 0.027 /   test loss : 0.163
iteration : 450/500  -  train loss : 0.027 /   test loss : 0.164
iteration : 460/500  -  train loss : 0.026 /   test loss : 0.163
iteration : 470/500  -  train loss : 0.025 /   test loss : 0.162
iteration : 480/500  -  train loss : 0.025 /   test loss : 0.162
iteration : 490/500  -  train loss : 0.025 /   test loss : 0.162
iteration : 500/500  -  train loss : 0.025 /   test loss : 0.163

Training complete   //   Running time :  95  ------------


[Gene 10] Model 3 ( tissue 27 ) - 5/5 fold data
Option : # of base nodes / Drop prob : 4096  / 0.99

Data shape @@@@@@
Train data :  torch.Size([120, 12638])  /  torch.Size([120, 1])
Test data :  torch.Size([33, 12638])  /  torch.Size([33, 1])


iteration : 0/500  -  train loss : 0.227 /   test loss : 0.207
iteration : 10/500  -  train loss : 0.185 /   test loss : 0.185
iteration : 20/500  -  train loss : 0.148 /   test loss : 0.167
iteration : 30/500  -  train loss : 0.126 /   test loss : 0.157
iteration : 40/500  -  train loss : 0.112 /   test loss : 0.15
iteration : 50/500  -  train loss : 0.103 /   test loss : 0.141
iteration : 60/500  -  train loss : 0.095 /   test loss : 0.139
iteration : 70/500  -  train loss : 0.088 /   test loss : 0.138
iteration : 80/500  -  train loss : 0.083 /   test loss : 0.141
iteration : 90/500  -  train loss : 0.079 /   test loss : 0.141
iteration : 100/500  -  train loss : 0.075 /   test loss : 0.139
iteration : 110/500  -  train loss : 0.071 /   test loss : 0.137
iteration : 120/500  -  train loss : 0.069 /   test loss : 0.135
iteration : 130/500  -  train loss : 0.067 /   test loss : 0.134
iteration : 140/500  -  train loss : 0.065 /   test loss : 0.134
iteration : 150/500  -  train loss : 0.063 /   test loss : 0.134
iteration : 160/500  -  train loss : 0.06 /   test loss : 0.13
iteration : 170/500  -  train loss : 0.056 /   test loss : 0.129
iteration : 180/500  -  train loss : 0.054 /   test loss : 0.128
iteration : 190/500  -  train loss : 0.051 /   test loss : 0.128
iteration : 200/500  -  train loss : 0.05 /   test loss : 0.13
iteration : 210/500  -  train loss : 0.048 /   test loss : 0.128
iteration : 220/500  -  train loss : 0.047 /   test loss : 0.128
iteration : 230/500  -  train loss : 0.046 /   test loss : 0.129
iteration : 240/500  -  train loss : 0.044 /   test loss : 0.129
iteration : 250/500  -  train loss : 0.043 /   test loss : 0.13
iteration : 260/500  -  train loss : 0.042 /   test loss : 0.128
iteration : 270/500  -  train loss : 0.041 /   test loss : 0.126
iteration : 280/500  -  train loss : 0.04 /   test loss : 0.125
iteration : 290/500  -  train loss : 0.039 /   test loss : 0.126
iteration : 300/500  -  train loss : 0.037 /   test loss : 0.124
iteration : 310/500  -  train loss : 0.035 /   test loss : 0.125
iteration : 320/500  -  train loss : 0.034 /   test loss : 0.126
iteration : 330/500  -  train loss : 0.035 /   test loss : 0.126
iteration : 340/500  -  train loss : 0.035 /   test loss : 0.124
iteration : 350/500  -  train loss : 0.034 /   test loss : 0.123
iteration : 360/500  -  train loss : 0.034 /   test loss : 0.124
iteration : 370/500  -  train loss : 0.032 /   test loss : 0.124
iteration : 380/500  -  train loss : 0.032 /   test loss : 0.123
iteration : 390/500  -  train loss : 0.031 /   test loss : 0.126
iteration : 400/500  -  train loss : 0.031 /   test loss : 0.126
iteration : 410/500  -  train loss : 0.031 /   test loss : 0.126
iteration : 420/500  -  train loss : 0.029 /   test loss : 0.126
iteration : 430/500  -  train loss : 0.028 /   test loss : 0.126
iteration : 440/500  -  train loss : 0.029 /   test loss : 0.126
iteration : 450/500  -  train loss : 0.028 /   test loss : 0.127
iteration : 460/500  -  train loss : 0.027 /   test loss : 0.126
iteration : 470/500  -  train loss : 0.026 /   test loss : 0.125
iteration : 480/500  -  train loss : 0.025 /   test loss : 0.124
iteration : 490/500  -  train loss : 0.026 /   test loss : 0.125
iteration : 500/500  -  train loss : 0.025 /   test loss : 0.124

Training complete   //   Running time :  94  ------------
