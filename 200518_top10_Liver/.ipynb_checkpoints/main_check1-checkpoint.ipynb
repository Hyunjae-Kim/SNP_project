{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import module\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from model1 import Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as utils\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Gene 1] Model 1 ( tissue 27 ) - 1/5 fold data\n",
      "Option : 500 input length   //  50 hidden length  //  2 layers\n"
     ]
    }
   ],
   "source": [
    "trial_num = 1\n",
    "gene_num = 1\n",
    "model_num = 1\n",
    "tissue_num = 27\n",
    "k_num = 1\n",
    "\n",
    "m_count = 0\n",
    "hidden_size = 50\n",
    "for p1 in [500, 100]:\n",
    "    for p2 in [0.0002, 0.00005]:\n",
    "        for p3 in [2,3]:\n",
    "            m_count += 1\n",
    "            input_size = p1\n",
    "            learning_rate = p2\n",
    "            num_layers = p3\n",
    "            if m_count==model_num:\n",
    "                break\n",
    "        if m_count==model_num:\n",
    "            break\n",
    "    if m_count==model_num:\n",
    "        break\n",
    "\n",
    "gene_data_name = 'UTMOST_top10_Liver'\n",
    "gene_list = os.listdir('../%s/'%gene_data_name)\n",
    "gene_name = gene_list[gene_num-1]\n",
    "\n",
    "print('\\n\\n[Gene %d] Model %d ( tissue %d ) - %d/5 fold data'%(gene_num, model_num, tissue_num, k_num))\n",
    "print('Option : %d input length   //  %d hidden length  //  %d layers'%(input_size, hidden_size, num_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153, 23049) (153, 1)\n",
      "ENSG00000184674.8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "start_time = time.time()\n",
    "np.random.seed(37)\n",
    "torch.manual_seed(37)\n",
    "torch.cuda.manual_seed_all(37)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "snp, gx = module.load_data(gene_data_name, gene_name, tissue_num, proc=True)\n",
    "print(np.shape(snp), np.shape(gx))\n",
    "print(gene_name)\n",
    "\n",
    "snp_len = np.shape(snp)[-1]\n",
    "len_dif = snp_len%input_size\n",
    "snp = snp[:, int(len_dif/2):int(len_dif/2)+snp_len-len_dif]\n",
    "\n",
    "snp_train, snp_test, gx_train, gx_test = module.k_fold_data(snp, gx, 5, k_num)\n",
    "\n",
    "snp_train = torch.Tensor(snp_train).to(device)\n",
    "snp_test = torch.Tensor(snp_test).to(device)\n",
    "gx_train = torch.Tensor(gx_train).to(device)\n",
    "gx_test = torch.Tensor(gx_test).to(device)\n",
    "\n",
    "snp_train = snp_train.view(snp_train.size()[0], -1, input_size)\n",
    "snp_test = snp_test.view(snp_test.size()[0], -1, input_size)\n",
    "\n",
    "print('\\nData shape @@@@@@')\n",
    "print('Train data : ', np.shape(snp_train),' / ', np.shape(gx_train))\n",
    "print('Test data : ', np.shape(snp_test), ' / ', np.shape(gx_test))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([41, 40, 500]) torch.Size([41, 1])\n",
      "torch.Size([41, 40, 500]) torch.Size([41, 1])\n",
      "torch.Size([41, 40, 500]) torch.Size([41, 1])\n",
      "torch.Size([41, 40, 500]) torch.Size([41, 1])\n",
      "torch.Size([41, 40, 500]) torch.Size([41, 1])\n",
      "torch.Size([41, 40, 500]) torch.Size([41, 1])\n",
      "torch.Size([41, 40, 500]) torch.Size([41, 1])\n",
      "torch.Size([41, 40, 500]) torch.Size([41, 1])\n",
      "torch.Size([41, 40, 500]) torch.Size([41, 1])\n"
     ]
    }
   ],
   "source": [
    "model = Model(input_size, hidden_size, num_layers, snp_train.size()[1]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "tr_loss_list = []\n",
    "te_loss_list = []\n",
    "\n",
    "tr_loss_buff = 0\n",
    "te_loss_buff = 0\n",
    "min_iter = 0\n",
    "\n",
    "mb_div = 3\n",
    "mb_idx = int(len(snp_train)/mb_div)\n",
    "s = np.arange(len(snp_train))\n",
    "\n",
    "for i in range(3):\n",
    "    np.random.shuffle(s)\n",
    "    snp_train = snp_train[s]\n",
    "    gx_train = gx_train[s]\n",
    "    for mb in range(mb_div):\n",
    "        dsnp_train = snp_train[mb*mb_idx:(mb+1)*mb_idx]\n",
    "        dgx_train = gx_train[mb*mb_idx:(mb+1)*mb_idx]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        tr_loss, output = model(dsnp_train, dgx_train)\n",
    "        tr_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "#     if i%100==0:\n",
    "#         te_loss, out_test = model(snp_test, gx_test)\n",
    "        \n",
    "#         tr_loss_list.append(tr_loss.cpu().item())\n",
    "#         te_loss_list.append(te_loss.cpu().item())\n",
    "        \n",
    "#     if i%100==0:\n",
    "#         print('iteration :', '%d/2000'%i, ' -  train loss :', \\\n",
    "#               np.round(tr_loss.cpu().item(),3), '/  ', \\\n",
    "#               'test loss :', np.round(te_loss.cpu().item(), 3))\n",
    "        \n",
    "#         if te_loss_buff==0: te_loss_buff = te_loss.cpu().item(); continue\n",
    "        \n",
    "#         if te_loss_buff>=te_loss.cpu().item():\n",
    "#             min_iter = i\n",
    "#             te_loss_buff = te_loss.cpu().item()\n",
    "#             tr_loss_buff = tr_loss.cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
